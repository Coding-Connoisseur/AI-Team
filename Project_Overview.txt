

--- File: Dockerfile ---

FROM python:3.9-slim
WORKDIR /usr/src/app
COPY . .
RUN pip install --no-cache-dir -r requirements.txt
CMD ["python", "main.py"]



--- File: agents.py ---

import os
import subprocess
import sqlite3
import ast
import inspect

class BaseAgent:
    def __init__(self, name, knowledge_base):
        self.name = name
        self.knowledge_base = knowledge_base
        self.memory = {}

    def can_handle(self, task_name):
        raise NotImplementedError("Subclasses should implement this method.")

    def execute_task(self, task_name):
        raise NotImplementedError("Subclasses should implement this method.")

    def learn(self, task, outcome):
        if task not in self.memory:
            self.memory[task] = {"successes": 0, "failures": 0}
        
        if outcome == "success":
            self.memory[task]["successes"] += 1
        else:
            self.memory[task]["failures"] += 1

        print(f"{self.name} has learned from task {task}. Successes: {self.memory[task]['successes']}, Failures: {self.memory[task]['failures']}")

    def adjust_behavior(self, task):
        if task in self.memory and self.memory[task]["failures"] > self.memory[task]["successes"]:
            print(f"{self.name} adjusting behavior for task {task}")


class ProjectArchitectAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Project Architect AI", knowledge_base)
    
    def can_handle(self, task):
        return task == "architecture design"
    
    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is creating the project architecture...")
        
        project_structure = {
            "src": {
                "main.py": "# Main entry point",
                "utils.py": "# Utility functions",
                "tests": {
                    "test_main.py": "# Test cases for main"
                }
            },
            "docs": {
                "README.md": "# Project documentation"
            },
            "db": {},
            "logs": {},
        }
        base_path = "./real_project"
        os.makedirs(base_path, exist_ok=True)
        
        for folder, contents in project_structure.items():
            folder_path = os.path.join(base_path, folder)
            os.makedirs(folder_path, exist_ok=True)
            for file_name, file_content in contents.items():
                if isinstance(file_content, dict):
                    subdir_path = os.path.join(folder_path, file_name)
                    os.makedirs(subdir_path, exist_ok=True)
                    for subfile_name, subfile_content in file_content.items():
                        with open(os.path.join(subdir_path, subfile_name), 'w') as f:
                            f.write(subfile_content)
                else:
                    with open(os.path.join(folder_path, file_name), 'w') as f:
                        f.write(file_content)
        
        print(f"Real-world project structure created by {self.name}.")
        self.learn(task, "success")
        return "success"


class CodeGeneratorAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Code Generator AI", knowledge_base)
    
    def can_handle(self, task):
        return task == "code generation"
    
    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is generating advanced real-world code...")

        base_path = "./real_project/src/"
        advanced_code = '''
import logging
from flask import Flask, request, jsonify

app = Flask(__name__)

# Set up logging
logging.basicConfig(level=logging.INFO)

@app.before_request
def log_request_info():
    logging.info(f"Handling request: {request.method} {request.url}")

@app.errorhandler(404)
def not_found_error(error):
    return jsonify({"error": "Resource not found"}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({"error": "Internal server error"}), 500

@app.route('/api/v1/data', methods=['GET'])
def get_data():
    data = {"status": "success", "data": [i for i in range(100)]}
    logging.info("Data successfully fetched.")
    return jsonify(data)

if __name__ == "__main__":
    app.run(debug=True)
'''

        with open(os.path.join(base_path, "main.py"), 'w') as f:
            f.write(advanced_code)
        
        print(f"Advanced code generated by {self.name} and written to main.py.")
        self.learn(task, "success")
        return "success"


class TestAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Test AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "testing"

    def execute_task(self, task_name):
        if task_name == "testing":
            return self.run_tests()

    def run_tests(self):
        """
        Attempt to run real tests. Logs detailed test output and retries up to 3 times if tests fail.
        """
        test_dir = os.path.join(self.knowledge_base.get("project_structure", {}), "tests")
        if not os.path.exists(test_dir):
            print(f"No tests directory found at {test_dir}.")
            return "failure"
        
        try:
            result = subprocess.run(["pytest", test_dir], capture_output=True, text=True)
            print(result.stdout)
            if result.returncode == 0:
                print("All tests passed successfully.")
                return "success"
            else:
                print("Some tests failed.")
                return "failure"
        except Exception as e:
            print(f"Error while running tests: {str(e)}")
            return "failure"
class DebuggingAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Debugging AI", knowledge_base)

    def can_handle(self, task):
        return task == "debugging"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is performing real-world debugging...")

        try:
            print(f"Debugging task performed by {self.name}.")
            self.learn(task, "success")
            return "success"
        except Exception as e:
            print(f"Debugging failed with error: {e}")
            self.learn(task, "failure")
            return "failure"


class EnhancerAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Enhancer AI", knowledge_base)

    def can_handle(self, task):
        return task == "enhancement"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is enhancing the project...")

        enhancement_code = '''
def advanced_feature():
    print("Advanced feature implemented.")
'''

        base_path = "./real_project/src/utils.py"
        with open(base_path, 'a') as f:
            f.write(enhancement_code)

        print(f"Enhancement added to utils.py by {self.name}.")
        self.learn(task, "success")
        return "success"


class DocumentationAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Documentation AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "documentation"

    def execute_task(self, task_name):
        if task_name == "documentation":
            return self.generate_detailed_documentation()

    def generate_detailed_documentation(self):
        """
        Generates advanced documentation including:
        1. API Documentation (function signatures)
        2. Code Annotations (detailed explanations of code blocks)
        3. Workflow Diagrams (general flow of the project components)
        """
        print(f"{self.name} is generating detailed documentation...")

        # Step 1: Generate API Documentation
        self.generate_api_docs()

        # Step 2: Generate Code Annotations
        self.generate_code_annotations()

        # Step 3: Generate Workflow Diagrams (Simplified as textual representation for now)
        self.generate_workflow_diagrams()

        print(f"Detailed documentation generated by {self.name}.")
        self.learn("documentation", "success")
        return "success"

    def generate_api_docs(self):
        """
        Generate API documentation for all Python files by extracting function definitions and signatures.
        """
        print("Generating API documentation...")
        for module_name, module_ref in self.knowledge_base.get("modules", {}).items():
            print(f"\nModule: {module_name}")
            functions = inspect.getmembers(module_ref, inspect.isfunction)
            for function_name, function_ref in functions:
                signature = inspect.signature(function_ref)
                print(f"  Function: {function_name}{signature}")

    def generate_code_annotations(self):
        """
        Generate code annotations by analyzing the AST (Abstract Syntax Tree) and adding comments where appropriate.
        """
        print("Generating code annotations using AST...")
        for module_name, module_ref in self.knowledge_base.get("modules", {}).items():
            source_code = inspect.getsource(module_ref)
            root = ast.parse(source_code)

            print(f"\nAnnotations for {module_name}:")
            for node in ast.walk(root):
                if isinstance(node, ast.FunctionDef):
                    print(f"  Function {node.name} is defined at line {node.lineno}.")
                elif isinstance(node, ast.ClassDef):
                    print(f"  Class {node.name} found at line {node.lineno}.")

    def generate_workflow_diagrams(self):
        """
        Generate a simplified diagram of workflow/processes in the system. 
        This is a mockup and can later be improved with tools like graphviz or UML generators.
        """
        print("Generating workflow diagram...\n")

        # Simulating the generation of a workflow diagram (text-based for now)
        workflow = """
        [Team Leader AI] --> Assign Tasks
        [Load Balancer] --> Distribute Tasks to Agents
        [Agents] --> Perform Tasks (e.g., Code Generation, Testing, Debugging)
        [Documentation AI] --> Generate Reports on Project State
        """
        print(workflow)


class DeploymentAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Deployment AI", knowledge_base)

    def can_handle(self, task):
        return task == "deployment"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is deploying the project...")

        dockerfile_content = '''
FROM python:3.9-slim

WORKDIR /app

COPY . /app

RUN pip install -r requirements.txt

CMD ["python", "main.py"]
'''

        with open("./real_project/Dockerfile", 'w') as f:
            f.write(dockerfile_content)

        print(f"Dockerfile created by {self.name}.")
        self.learn(task, "success")
        return "success"


class SecurityAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Security AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "security audit"

    def execute_task(self, task_name):
        if task_name == "security audit":
            return self.perform_security_audit()

    def perform_security_audit(self):
        """
        Perform a security audit, detect vulnerabilities, and attempt to fix them.
        """
        print("Security AI is performing a security audit...")
        vulnerabilities = ["Insecure default configuration", "Weak encryption algorithm"]
        print("Vulnerabilities detected:\n" + "\n".join(vulnerabilities))

        try:
            self.fix_vulnerabilities(vulnerabilities)
            return "success"
        except Exception as e:
            print(f"Failed to fix vulnerabilities: {str(e)}")
            return "failure"

    def fix_vulnerabilities(self, vulnerabilities):
        """
        Fixes known vulnerabilities. For example, update configs, replace weak encryption algorithms, etc.
        """
        for vulnerability in vulnerabilities:
            if "Insecure default configuration" in vulnerability:
                config_file = os.path.join(self.knowledge_base.get("project_structure", {}), "config.yml")
                if os.path.exists(config_file):
                    with open(config_file, 'a') as f:
                        f.write("secure: true\n")
                    print("Insecure default configuration fixed.")
            elif "Weak encryption algorithm" in vulnerability:
                code_file = os.path.join(self.knowledge_base.get("project_structure", {}), "encryption.py")
                if os.path.exists(code_file):
                    with open(code_file, 'r') as f:
                        content = f.read()
                    updated_content = content.replace("AES256", "AES512")
                    with open(code_file, 'w') as f:
                        f.write(updated_content)
                    print("Weak encryption algorithm fixed.")


class DatabaseAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Database AI", knowledge_base)

    def can_handle(self, task):
        return task == "database setup"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is setting up the database...")

        db_path = "./real_project/db/project.db"
        os.makedirs(os.path.dirname(db_path), exist_ok=True)

        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()

            cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY,
                username TEXT NOT NULL,
                email TEXT NOT NULL UNIQUE
            )
            ''')

            conn.commit()
            conn.close()
            print(f"Database created by {self.name}.")
            self.learn(task, "success")
            return "success"
        except sqlite3.Error as e:
            print(f"Database setup failed: {e}")
            self.learn(task, "failure")
            return "failure"


class LoggingAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Logging AI", knowledge_base)

    def can_handle(self, task):
        return task == "logging setup"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is setting up logging for the project...")

        logging_config = '''
import logging

logging.basicConfig(filename='./real_project/logs/app.log', level=logging.INFO,
                    format='%(asctime)s %(levelname)s: %(message)s')

logging.info("Logging is set up.")
'''

        with open("./real_project/src/logging_setup.py", 'w') as f:
            f.write(logging_config)

        print(f"Logging setup complete by {self.name}.")
        self.learn(task, "success")
        return "success"


class VersionControlAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Version Control AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "version control"

    def execute_task(self, task_name):
        if task_name == "version control":
            return self.handle_version_control()

    def handle_version_control(self):
        """
        Main method which handles version control tasks, like branch management and merging.
        """
        print(f"{self.name} is managing version control...")

        # Step 1: Ensure branch management
        self.manage_branches()

        # Step 2: Optimize merge strategies based on task status
        self.suggest_merge_strategy()

        self.learn("version control", "success")
        return "success"

    def manage_branches(self):
        """
        Automatically manage branches by checking the current progress and ensuring branch strategy.
        For now, this involves checking out to the correct branches based on priority tasks.
        """
        print("Managing branches...")

        # Example: Check for active branches and automatically create or switch between them
        branches = self.get_branches()
        if 'main' not in branches:
            self.create_branch('main')

        current_branch = self.get_current_branch() 
        if current_branch != 'main':
            print(f"Switching to 'main' branch from '{current_branch}'...")
            self.checkout_branch('main')

    def suggest_merge_strategy(self):
        """
        Suggests merge strategies based on the progress of tasks by different agents.
        For example, fast-forward merges for simple changes and rebase or squash strategies for complex histories.
        """
        print("Analyzing for merge strategy suggestions...")

        # Analyze branch status and decide merge strategy
        pending_merges = self.check_pending_merges()
        
        if pending_merges:
            for branch in pending_merges:
                if branch in ['feature', 'enhancement']:
                    print(f"Suggesting 'fast-forward' merge for '{branch}' branch.")
                else:
                    print(f"Suggesting 'squash' merge for complex commits on branch '{branch}'.")
        else:
            print("No pending merges detected.")

    def get_branches(self):
        """
        Returns a list of branches in the current repository.
        """
        branches = subprocess.run(['git', 'branch'], text=True, capture_output=True).stdout.splitlines()
        branch_names = [branch.strip('* ') for branch in branches]
        print(f"Available branches: {branch_names}")
        return branch_names

    def get_current_branch(self):
        """
        Returns the name of the current active branch.
        """
        current_branch = subprocess.run(['git', 'branch', '--show-current'], text=True, capture_output=True).stdout.strip()
        print(f"Current branch: {current_branch}")
        return current_branch

    def create_branch(self, branch_name):
        """
        Creates a new branch if it doesn't exist.
        """
        print(f"Creating new branch '{branch_name}'.")
        subprocess.run(['git', 'checkout', '-b', branch_name])

    def checkout_branch(self, branch_name):
        """
        Checkout to the specified branch.
        """
        subprocess.run(['git', 'checkout', branch_name])

    def check_pending_merges(self):
        """
        Mock function to simulate pending branches needing merging.
        This would be extended to dynamically check branches that are behind or ahead of the main branch.
        """
        # Simulating pending branches that need merging. You can further develop this logic as necessary.
        return ["feature", "enhancement"]


class FrontendGeneratorAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Frontend Generator AI", knowledge_base)

    def can_handle(self, task):
        return task == "frontend generation"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is generating frontend for the project...")

        frontend_code = '''
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Frontend</title>
</head>
<body>
    <h1>Welcome to the Project</h1>
    <p>This is an advanced frontend page generated by the AI team.</p>
</body>
</html>
'''

        with open("./real_project/src/frontend.html", 'w') as f:
            f.write(frontend_code)

        print(f"Frontend generated by {self.name}.")
        self.learn(task, "success")
        return "success"



--- File: dynamic_thread_pool.py ---

import psutil
from concurrent.futures import ThreadPoolExecutor

class DynamicThreadPoolExecutor:
    def __init__(self, max_workers):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)

    def adjust_workers(self, cpu_usage, memory_usage, io_usage, network_usage):
        """
        Adjust worker count based on system's resource usage, including disk I/O and network bandwidth.
        """
        # Reduce the number of workers if CPU, memory, disk I/O, or network usage is too high
        if cpu_usage > 80 or memory_usage > 80 or io_usage > 80 or network_usage > 75:
            new_worker_count = max(1, self.max_workers // 2)  # Reduce workers to alleviate load
            self.executor = ThreadPoolExecutor(max_workers=new_worker_count)
            print(f"Reducing worker count to {new_worker_count} due to high resource usage: CPU({cpu_usage}%), Memory({memory_usage}%), IO({io_usage}%), Network({network_usage}%)")
        # Increase workers if the system is underutilized
        elif cpu_usage < 40 and memory_usage < 40 and io_usage < 40 and network_usage < 30:
            new_worker_count = min(self.max_workers * 2, 10)  # Increase workers to better utilize capacity
            self.executor = ThreadPoolExecutor(max_workers=new_worker_count)
            print(f"Increasing worker count to {new_worker_count} due to low resource usage: CPU({cpu_usage}%), Memory({memory_usage}%), IO({io_usage}%), Network({network_usage}%)")

    def monitor_resource_usage(self):
        """
        Fetch system resource usage: CPU, memory, disk I/O, and network IO.
        """
        cpu_usage = psutil.cpu_percent(interval=1)
        memory_usage = psutil.virtual_memory().percent
        io_usage = psutil.disk_io_counters().write_time   # Monitoring disk write time in milliseconds
        network_usage = psutil.net_io_counters().bytes_sent  # Monitoring network bytes sent
        # Normalize IO and network data
        normalized_io_usage = min(100, (io_usage / 1000) * 10)  # Simple normalization (adjust as necessary)
        normalized_network_usage = min(100, (network_usage / (1024 * 1024)) * 10)  # Convert bytes to MB and normalize
        return cpu_usage, memory_usage, normalized_io_usage, normalized_network_usage

    def submit_task(self, fn, *args, **kwargs):
        """
        Submit a task to the executor, dynamically adjusting the worker count based on system resources.
        """
        cpu_usage, memory_usage, io_usage, network_usage = self.monitor_resource_usage()
        self.adjust_workers(cpu_usage, memory_usage, io_usage, network_usage)
        return self.executor.submit(fn, *args, **kwargs)



--- File: health_check_manager.py ---

class HealthCheckManager:
    def __init__(self, system_monitor, agent_health_monitor):
        self.system_monitor = system_monitor
        self.agent_health_monitor = agent_health_monitor

    def perform_health_check(self, agent_name):
        cpu_usage, memory_usage = self.system_monitor.monitor_resources()
        self.agent_health_monitor.monitor_agent_health(agent_name)
        if cpu_usage > 85 or memory_usage > 85:
            print(f"System overload detected. Rebalancing tasks.")



--- File: knowledge_base.py ---

class SharedKnowledgeBase:
    def __init__(self):
        self.data = {}

    def store(self, key, value):
        self.data[key] = value

    def get(self, key, default=None):
        return self.data.get(key, default)

    def delete(self, key):
        if key in self.data:
            del self.data[key]

    def list_contents(self):
        """
        Lists all content currently stored in the knowledge base.
        """
        if not self.data:
            print("Shared knowledge base is empty.")
        else:
            print("Shared Knowledge Base Contents:")
            for key, value in self.data.items():
                print(f"  - {key}: {value}")

        return self.data



--- File: load_balancer.py ---

class LoadBalancer:
    """
    Distributes tasks evenly across available agents to avoid bottlenecks.
    Now considers agent expertise when assigning tasks.
    """
    def __init__(self, agents):
        self.agents = agents
        self.agent_loads = {agent.name: 0 for agent in agents}
        self.agent_expertises = {  # Identifying the best agent for each type of task
            "architecture design": "Project Architect AI",
            "code generation": "Code Generator AI",
            "debugging": "Debugging AI",
            "testing": "Test AI",
            "enhancement": "Enhancer AI",
            "documentation": "Documentation AI",
            "deployment": "Deployment AI",
            "security audit": "Security AI",
            "database setup": "Database AI",
            "logging setup": "Logging AI",
            "version control": "Version Control AI",
            "frontend generation": "Frontend Generator AI"
        }

    def assign_task(self, task):
        """
        Assigns the task to the least busy agent, while also prioritizing agents who are experts at this task.
        """
        # Identify the expert agent for the task
        expert_agent_name = self.agent_expertises.get(task)

        if expert_agent_name:
            # Ensure the expert agent still exists in the system
            if expert_agent_name in self.agent_loads:
                least_busy_expert = expert_agent_name
            else:
                # Fallback to least busy agent if expertise agent is not found
                least_busy_expert = min(self.agent_loads, key=self.agent_loads.get)
            
            print(f"Assigning task '{task}' to the expert agent: {least_busy_expert}.")
        else:
            # No specific expertise available, assign to the least busy agent
            least_busy_expert = min(self.agent_loads, key=self.agent_loads.get)
            print(f"Assigning task '{task}' to {least_busy_expert}, no specific expertise required.")
        
        assigned_agent = next(agent for agent in self.agents if agent.name == least_busy_expert)
        self.agent_loads[least_busy_expert] += 1
        return assigned_agent

    def task_completed(self, agent_name):
        """
        Marks a task as completed by the given agent, reducing their current load.
        """
        if agent_name in self.agent_loads:
            self.agent_loads[agent_name] = max(0, self.agent_loads[agent_name] - 1)

# Example agents list to simulate load balancer functioning:
"""
agents = {
    "Project Architect AI": ProjectArchitectAI(knowledge_base),
    "Code Generator AI": CodeGeneratorAI(knowledge_base),
    "Debugging AI": DebuggingAI(knowledge_base),
    "Test AI": TestAI(knowledge_base),
    "Enhancer AI": EnhancerAI(knowledge_base),
    "Documentation AI": DocumentationAI(knowledge_base),
    "Deployment AI": DeploymentAI(knowledge_base),
    "Security AI": SecurityAI(knowledge_base),
    "Database AI": DatabaseAI(knowledge_base),
    "Logging AI": LoggingAI(knowledge_base),
    "Version Control AI": VersionControlAI(knowledge_base),
    "Frontend Generator AI": FrontendGeneratorAI(knowledge_base)
}
"""



--- File: main.py ---

from system import TeamLeaderAI
from knowledge_base import SharedKnowledgeBase
from agents import ProjectArchitectAI, CodeGeneratorAI, TestAI, EnhancerAI, DocumentationAI, DeploymentAI, SecurityAI, DatabaseAI, LoggingAI, VersionControlAI, FrontendGeneratorAI, DebuggingAI

# Initialize the shared knowledge base
knowledge_base = SharedKnowledgeBase()

# Define collaborative agents and pass the shared knowledge base
agents = {
    "Project Architect AI": ProjectArchitectAI(knowledge_base),
    "Code Generator AI": CodeGeneratorAI(knowledge_base),
    "Test AI": TestAI(knowledge_base),
    "Enhancer AI": EnhancerAI(knowledge_base),
    "Documentation AI": DocumentationAI(knowledge_base),
    "Deployment AI": DeploymentAI(knowledge_base),
    "Security AI": SecurityAI(knowledge_base),
    "Database AI": DatabaseAI(knowledge_base),
    "Logging AI": LoggingAI(knowledge_base),
    "Version Control AI": VersionControlAI(knowledge_base),
    "Frontend Generator AI": FrontendGeneratorAI(knowledge_base),
    "Debugging AI": DebuggingAI(knowledge_base)
}

# Initialize the Team Leader AI
team_leader = TeamLeaderAI(agents)

# Ask the user what they want the team to do
team_leader.receive_user_input()

# Print the task progress
team_leader.report_progress()

# Store some knowledge in the knowledge base
knowledge_base.store("key1", "This is some knowledge about task1.")
knowledge_base.store("key2", "This is some knowledge about task2.")

# List the shared knowledge base contents:
knowledge_base.list_contents()

# Retrieve specific knowledge
task1_knowledge = knowledge_base.get("key1")
print(f"Retrieved knowledge for task1: {task1_knowledge}")

task2_knowledge = knowledge_base.get("key2")
print(f"Retrieved knowledge for task2: {task2_knowledge}")



--- File: requirements.txt ---

psutil



--- File: system.py ---

from task_priority_queue import TaskPriorityQueue
from task_monitor import TaskMonitor
from agent_health_monitor import AgentHealthMonitor
from system_monitor import SystemMonitor
from health_check_manager import HealthCheckManager
from dynamic_thread_pool import DynamicThreadPoolExecutor
from load_balancer import LoadBalancer
import os

class TeamLeaderAI:
    def __init__(self, agents, retry_limit=3):
        self.agents = agents
        self.task_priority_queue = TaskPriorityQueue(SystemMonitor())  # Using SystemMonitor to help with task scheduling
        self.task_progress = {}  # Track task states: {'task_name': {'status': 'queued/active/completed', 'agent': <agent_name>, 'start_time': <timestamp>}}
        self.task_completion_data = {}  # Track the details of completed tasks
        self.retry_limit = retry_limit
        self.task_retries = {}
        self.thread_pool = DynamicThreadPoolExecutor(max_workers=3)
        self.load_balancer = LoadBalancer(self.agents.values())  # Reference to LoadBalancer
        self.task_monitor = TaskMonitor()  # Task monitor for tracking task execution time
        self.agent_health_monitor = AgentHealthMonitor(self.agents.values(), self.load_balancer)
        self.system_monitor = SystemMonitor()  # Monitor system resources
        self.health_check_manager = HealthCheckManager(self.system_monitor, self.agent_health_monitor)
        self.project_path = None

    def get_user_input(self):
        """
        Asks the user what they want the AI team to do.
        """
        print("What do you want the AI team to do? Choose from the following options:")
        print("1. Create a whole project")
        print("2. Enhance an existing project")
        print("3. Debug a project")
        print("4. Add new features and capabilities to a project")
        print("5. Test a project")
        choice = input("Enter the number of your choice: ")

        return int(choice)

    def ask_for_project_path(self):
        """
        Ask the user for the project path and ensure it exists.
        """
        self.project_path = input("Please enter the path to the project you want to work on: ")
        if not os.path.exists(self.project_path):
            print(f"Error: The specified path {self.project_path} does not exist.")
            return False
        return True

    def receive_user_input(self):
        """
        Determines what the user wants based on input.
        """
        choice = self.get_user_input()
        if choice == 1:
            print("You selected to create a whole project.")
            project_type = input("Enter the type of project (e.g., web app, API, machine learning, etc.): ")
            self.decompose_project(f"Create a {project_type}")
        elif choice in [2, 3, 4, 5]:
            if not self.ask_for_project_path():
                return
            if choice == 2:
                print("You selected to enhance an existing project.")
                self.decompose_project("Enhance project")
            elif choice == 3:
                print("You selected to debug a project.")
                self.decompose_project("Debug project")
            elif choice == 4:
                print("You selected to add new features and capabilities.")
                self.decompose_project("Add features and capabilities")
            elif choice == 5:
                print("You selected to test a project.")
                self.decompose_project("Test project")
        else:
            print("Invalid choice.")
    
    def decompose_project(self, overview):
        tasks = [
            (1, "architecture design"),
            (2, "code generation"),
            (3, "debugging"),
            (4, "testing"),
            (5, "enhancement"),
            (6, "documentation"),
            (7, "deployment"),
            (8, "security audit"),
            (9, "database setup"),
            (10, "logging setup"),
            (11, "version control"),
            (12, "frontend generation")
        ]
        for priority, task in tasks:
            self.task_priority_queue.add_task(priority, task)
        self.assign_tasks()

    def assign_tasks(self):
        """
        Assign tasks from the task priority queue to agents.
        """
        while task_name := self.task_priority_queue.get_next_task():
            agent = self.load_balancer.assign_task(task_name)
            self.thread_pool.submit_task(self.execute_task, agent, task_name)
            self.update_task_status(task_name, 'active', agent.name)  # Mark task as active

    def find_agent_for_task(self, task_name):
        for agent in self.agents.values():
            if agent.can_handle(task_name):
                return agent
        return None

    def execute_task(self, agent, task_name):
        """
        Executes the task using the assigned agent.
        """
        try:
            start_time = time.time()  # Track the starting time of the task
            self.task_monitor.start_task(task_name)

            # Execute the task and record its outcome
            outcome = agent.execute_task(task_name)
            elapsed_time = self.task_monitor.end_task(task_name)  # Track task completion time

            self.task_completion_data[task_name] = {
                'status': 'completed',
                'agent': agent.name,
                'duration': elapsed_time,
                'outcome': outcome
            }

            print(f"Task '{task_name}' completed by {agent.name} with outcome: {outcome}")
        except Exception as e:
            print(f"Error in executing task '{task_name}' by {agent.name}: {e}")
            self.record_failure(task_name, agent)

    def handle_agent_feedback(self, task_name, result):
        if result == "success":
            self.task_progress[task_name] = "completed"
        else:
            self.recover_from_failure(task_name)

    def recover_from_failure(self, task):
        if self.task_retries[task] < self.retry_limit:
            self.task_retries[task] += 1
            agent = self.find_agent_for_task(task)
            if agent:
                self.execute_task(agent, task)
        else:
            print(f"Task {task} has exceeded the retry limit.")

    def update_task_status(self, task_name, status, agent_name):
        """
        Updates the task progress status (active, completed, etc.) and records the agent assigned to the task.
        """
        self.task_progress[task_name] = {
            'status': status,
            'agent': agent_name
        }

    def report_progress(self):
        """
        Displays a real-time dashboard showing task progress.
        """
        print("\n--- Task Progress Dashboard ---")
        print("Queued Tasks:")
        queued_tasks = [task for task, status in self.task_progress.items() if status['status'] == 'queued']
        if queued_tasks:
            for task in queued_tasks:
                print(f"  {task} (Agent: {self.task_progress[task]['agent']})")
        else:
            print("  No queued tasks.")

        print("\nActive Tasks:")
        active_tasks = [task for task, status in self.task_progress.items() if status['status'] == 'active']
        if active_tasks:
            for task in active_tasks:
                print(f"  {task} (Agent: {self.task_progress[task]['agent']})")
        else:
            print("  No active tasks.")

        print("\nCompleted Tasks:")
        completed_tasks = [task for task, status in self.task_progress.items() if status['status'] == 'completed']
        if completed_tasks:
            for task in completed_tasks:
                print(f"  {task} (Agent: {self.task_progress[task]['agent']}, Duration: {self.task_completion_data[task]['duration']:.2f} seconds, Outcome: {self.task_completion_data[task]['outcome']})")
        else:
            print("  No completed tasks.")

        print("\n--- End of Dashboard Report ---")

    def report_overall_progress(self):
        """
        Summarizes overall task progress, including completion rates.
        """
        total_tasks = len(self.task_progress)
        completed_tasks = len([task for task in self.task_progress if self.task_progress[task]['status'] == 'completed'])
        success_tasks = len([task for task in self.task_completion_data if self.task_completion_data[task]['outcome'] == 'success'])

        print("\n--- Overall Task Completion Summary ---")
        print(f"Total Tasks: {total_tasks}")
        print(f"Completed Tasks: {completed_tasks}")
        print(f"Successful Tasks: {success_tasks}")
        print(f"Completion Rate: {(completed_tasks / total_tasks) * 100:.2f}%")
        print(f"Success Rate: {(success_tasks / completed_tasks) * 100:.2f}% (for completed tasks)")
        print("\n--- End of Summary ---")

    def retry_task(self, task_name, agent_name):
        """
        Attempts to retry a failed task a limited number of times.
        """
        retries = self.task_retries.get(task_name, 0)
        if retries < self.retry_limit:
            print(f"Retrying task '{task_name}' (Attempt {retries + 1}/{self.retry_limit})...")
            self.task_retries[task_name] = retries + 1
            self.assign_tasks()
        else:
            print(f"Task '{task_name}' failed after {self.retry_limit} retries.")
    
    def record_failure(self, task_name, agent):
        """
        Record task failure and decide whether to retry based on retry limit.
        """
        if task_name not in self.task_retries:
            self.task_retries[task_name] = 0

        if self.task_retries[task_name] < self.retry_limit:
            print(f"Task '{task_name}' failed. Retrying...")
            self.retry_task(task_name, agent.name)
        else:
            print(f"Task '{task_name}' exceeded retry limit. Marked as failed.")




--- File: system_monitor.py ---

import psutil

class SystemMonitor:
    def __init__(self):
        self.alert_thresholds = {
            'cpu': 85,  # Alert if CPU usage exceeds 85%
            'memory': 85,  # Alert if memory usage exceeds 85%
            'disk': 80,  # Alert if disk usage exceeds 80%
            'network_sent': 75,  # Alert if network outgoing exceeds 75% of bandwidth (mock)
        }

    def monitor_resources(self):
        """
        Monitors the system's resource usage.
        """
        cpu_usage = psutil.cpu_percent(interval=1)
        memory_usage = psutil.virtual_memory().percent
        disk_usage = psutil.disk_usage('/').percent
        network_usage_sent = self.get_network_sent_usage()

        print(f"CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage}%, Disk Usage: {disk_usage}%, Network Outgoing: {network_usage_sent}%")
        
        # Trigger alerts if any usage exceeds pre-defined thresholds
        self.check_alerts(cpu_usage, memory_usage, disk_usage, network_usage_sent)

        return cpu_usage, memory_usage, disk_usage, network_usage_sent

    def check_alerts(self, cpu_usage, memory_usage, disk_usage, network_usage_sent):
        """
        Checks system metrics against pre-defined threshold limits and issues alerts if exceeded.
        """
        if cpu_usage > self.alert_thresholds['cpu']:
            print(f"ALERT: CPU Usage exceeds {self.alert_thresholds['cpu']}% (Current: {cpu_usage}%)")

        if memory_usage > self.alert_thresholds['memory']:
            print(f"ALERT: Memory Usage exceeds {self.alert_thresholds['memory']}% (Current: {memory_usage}%)")

        if disk_usage > self.alert_thresholds['disk']:
            print(f"ALERT: Disk Usage exceeds {self.alert_thresholds['disk']}% (Current: {disk_usage}%)")

        if network_usage_sent > self.alert_thresholds['network_sent']:
            print(f"ALERT: Network Outgoing exceeds {self.alert_thresholds['network_sent']}% (Current: {network_usage_sent}%)")

    def get_network_sent_usage(self):
        """
        Simulate network usage monitoring. You could modify this part to reflect real network usage.
        """
        net_io = psutil.net_io_counters()
        sent = net_io.bytes_sent / (1024 * 1024)  # Convert the sent bytes to megabytes
        # For now, we'll return a mock "percentage", just scale bytes sent arbitrarily
        return min(100, (sent / 5) * 10)  # This is a mock calculation assuming 5MB threshold.
    
    def trigger_alert(self, alert_message):
        """
        Optional: Hook this up with a notification/alerting system (e.g., email, logging, etc.).
        """
        # Notifies via print for now; can change as needed (e.g., hook with logging service).
        print(f"Triggering Alert: {alert_message}")



--- File: task_monitor.py ---

import time

class TaskMonitor:
    def __init__(self):
        self.task_times = {}
        self.task_history = {}  # New dictionary to track task completion times
    
    def start_task(self, task_name):
        """
        Starts tracking the task's start time.
        """
        self.task_times[task_name] = time.time()
        print(f"Started task '{task_name}' at {self.task_times[task_name]}")

    def end_task(self, task_name):
        """
        Stops tracking the task's time and records the duration for analytics.
        """
        if task_name in self.task_times:
            elapsed_time = time.time() - self.task_times[task_name]
            print(f"Task '{task_name}' completed in {elapsed_time:.2f} seconds.")
            
            # Store the elapsed time in task history for tracking multiple runs
            if task_name not in self.task_history:
                self.task_history[task_name] = []
            self.task_history[task_name].append(elapsed_time)

            del self.task_times[task_name]
            return elapsed_time
        return None

    def get_average_time(self, task_name):
        """
        Calculates the average completion time for a given task, based on historical data.
        """
        if task_name in self.task_history and self.task_history[task_name]:
            avg_time = sum(self.task_history[task_name]) / len(self.task_history[task_name])
            print(f"Average time for task '{task_name}': {avg_time:.2f} seconds.")
            return avg_time
        else:
            print(f"No historical data for task '{task_name}'.")
            return None

    def display_task_statistics(self):
        """
        Displays a summary of task performance statistics, including average and total run times.
        """
        if self.task_history:
            print("\nTask Performance Summary:")
            for task_name, times in self.task_history.items():
                total_runs = len(times)
                total_time = sum(times)
                average_time = total_time / total_runs if total_runs > 0 else 0
                print(f"Task: {task_name}, Total Runs: {total_runs}, Average Time: {average_time:.2f} seconds, Total Time: {total_time:.2f} seconds.")
        else:
            print("No tasks have been completed yet to show statistics.")



--- File: task_priority_queue.py ---

import heapq

class TaskPriorityQueue:
    def __init__(self, system_monitor):
        self.queue = []
        self.system_monitor = system_monitor  # Allow access to system resource data

    def add_task(self, priority, task_name, resource_intensity):
        """
        Add task to priority queue with priority and an estimated resource intensity (e.g., high, medium, low).
        """
        heapq.heappush(self.queue, (priority, task_name, resource_intensity))

    def get_next_task(self):
        """
        Fetch the next task, prioritizing based on system resource availability.
        """
        if not self.queue:
            return None

        # Get system's current resources utilization
        cpu_usage, memory_usage, _, _ = self.system_monitor.monitor_resources()

        # Try to prioritize tasks that match the current system conditions
        best_match = None
        for i in range(len(self.queue)):
            priority, task_name, resource_intensity = self.queue[i]

            if resource_intensity == 'low' or (cpu_usage < 50 and memory_usage < 50):
                best_match = heapq.heappop(self.queue)
                break
            elif resource_intensity == 'medium' and (cpu_usage < 70 and memory_usage < 70):
                best_match = heapq.heappop(self.queue)
                break
            elif resource_intensity == 'high' and (cpu_usage < 90 and memory_usage < 90):
                best_match = heapq.heappop(self.queue)
                break

        if best_match:
            return best_match[1]  # Return the task_name after finding the best match
        else:
            print("System is too overloaded; delaying resource-heavy tasks.")
            return None

    def display_pending_tasks(self):
        """
        Display tasks currently pending in the queue, sorted by priority.
        """
        if not self.queue:
            print("No pending tasks.")
            return
        
        print("Pending tasks:")
        for priority, task_name, resource_intensity in sorted(self.queue):
            print(f"Priority {priority}: Task '{task_name}' (Resource Intensity: {resource_intensity})")




--- File: agent_health_monitor.py ---

class AgentHealthMonitor:
    """
    Monitors the health and performance of agents.
    """
    def __init__(self, agents, load_balancer):
        self.agent_health = {agent.name: {"tasks_handled": 0, "successes": 0, "failures": 0} for agent in agents}
        self.load_balancer = load_balancer  # Adding load balancer reference to rebalance tasks
    
    def record_task(self, agent_name, outcome):
        """
        Records the outcome of a task handled by an agent.
        Expects 'outcome' to be either 'success' or 'failure' and updates the agent's health accordingly.
        """
        self.agent_health[agent_name]["tasks_handled"] += 1
        if outcome == "success":
            self.agent_health[agent_name]["successes"] += 1
        elif outcome == "failure":
            self.agent_health[agent_name]["failures"] += 1
        else:
            raise ValueError(f"Unknown task outcome: {outcome}")
        
        self.display_health(agent_name)    # Displaying health after every record.
        self.monitor_agent_health(agent_name)   # Triggering health monitoring after each task
    
    def display_health(self, agent_name):
        """
        Displays the current health of an agent.
        """
        health = self.agent_health[agent_name]
        print(f"{agent_name} Health: Tasks Handled: {health['tasks_handled']}, Successes: {health['successes']}, Failures: {health['failures']}")
    
    def monitor_agent_health(self, agent_name):
        """
        Checks if the agent is failing too often and triggers rebalancing if necessary.
        """
        health = self.agent_health[agent_name]
        if health['failures'] > health['successes']:
            print(f"Warning: {agent_name} is experiencing frequent failures.")
            self.trigger_rebalance(agent_name)   # Automatically rebalance if failure rate exceeds success rate.
    
    def trigger_rebalance(self, failing_agent_name):
        """
        Automatically reassigns tasks if an agent is failing too often.
        """
        print(f"Reassigning tasks from {failing_agent_name} due to frequent failures.")
        # Rebalance logic: Transfer some tasks away from the failing agent to the least busy agent.
        rebalanced_agent = self.load_balancer.assign_task("Rebalance Task")  
        print(f"Tasks reassigned from {failing_agent_name} to {rebalanced_agent.name}.")

class LoadBalancer:
    """
    Distributes tasks evenly across available agents to avoid bottlenecks.
    """
    def __init__(self, agents):
        self.agents = agents
        self.agent_loads = {agent.name: 0 for agent in agents}

    def assign_task(self, task):
        """
        Assigns the task to the least busy agent.
        """
        least_busy_agent = min(self.agent_loads, key=self.agent_loads.get)
        print(f"Assigning task '{task}' to {least_busy_agent}.")
        return [agent for agent in self.agents if agent.name == least_busy_agent][0]

    def task_completed(self, agent_name):
        """
        Marks a task as completed by the given agent.
        """
        self.agent_loads[agent_name] -= 1

class HealthCheckManager:
    def __init__(self, system_monitor, agent_health_monitor):
        self.system_monitor = system_monitor
        self.agent_health_monitor = agent_health_monitor

    def perform_health_check(self, agent_name):
        cpu_usage, memory_usage = self.system_monitor.monitor_resources()
        self.agent_health_monitor.monitor_agent_health(agent_name)
        if cpu_usage > 85 or memory_usage > 85:
            print(f"System overload detected. Rebalancing tasks.")
            self.agent_health_monitor.trigger_rebalance(agent_name)



--- File: docmentation_ai.py ---

import ast
import inspect

class DocumentationAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Documentation AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "documentation"

    def execute_task(self, task_name):
        if task_name == "documentation":
            return self.generate_detailed_documentation()

    def generate_detailed_documentation(self):
        """
        Generates advanced documentation including:
        1. API Documentation (function signatures)
        2. Code Annotations (detailed explanations of code blocks)
        3. Workflow Diagrams (general flow of the project components)
        """
        print(f"{self.name} is generating detailed documentation...")

        # Step 1: Generate API Documentation
        self.generate_api_docs()

        # Step 2: Generate Code Annotations
        self.generate_code_annotations()

        # Step 3: Generate Workflow Diagrams (Simplified as textual representation for now)
        self.generate_workflow_diagrams()

        print(f"Detailed documentation generated by {self.name}.")
        self.learn("documentation", "success")
        return "success"

    def generate_api_docs(self):
        """
        Generate API documentation for all Python files by extracting function definitions and signatures.
        """
        print("Generating API documentation...")
        for module_name, module_ref in self.knowledge_base.get("modules", {}).items():
            print(f"\nModule: {module_name}")
            functions = inspect.getmembers(module_ref, inspect.isfunction)
            for function_name, function_ref in functions:
                signature = inspect.signature(function_ref)
                print(f"  Function: {function_name}{signature}")

    def generate_code_annotations(self):
        """
        Generate code annotations by analyzing the AST (Abstract Syntax Tree) and adding comments where appropriate.
        """
        print("Generating code annotations using AST...")
        for module_name, module_ref in self.knowledge_base.get("modules", {}).items():
            source_code = inspect.getsource(module_ref)
            root = ast.parse(source_code)

            print(f"\nAnnotations for {module_name}:")
            for node in ast.walk(root):
                if isinstance(node, ast.FunctionDef):
                    print(f"  Function {node.name} is defined at line {node.lineno}.")
                elif isinstance(node, ast.ClassDef):
                    print(f"  Class {node.name} found at line {node.lineno}.")

    def generate_workflow_diagrams(self):
        """
        Generate a simplified diagram of workflow/processes in the system. 
        This is a mockup and can later be improved with tools like graphviz or UML generators.
        """
        print("Generating workflow diagram...\n")

        # Simulating the generation of a workflow diagram (text-based for now)
        workflow = """
        [Team Leader AI] --> Assign Tasks
        [Load Balancer] --> Distribute Tasks to Agents
        [Agents] --> Perform Tasks (e.g., Code Generation, Testing, Debugging)
        [Documentation AI] --> Generate Reports on Project State
        """
        print(workflow)



--- File: createOverview.py ---

import os

def combine_files_in_directory(directory, output_file):
    with open(output_file, 'w') as outfile:
        # Traverse the directory recursively
        for root, dirs, files in os.walk(directory):
            # Ignore directories that start with '__' or are hidden (dot directories)
            dirs[:] = [d for d in dirs if not d.startswith('__') and not d.startswith('.')]
            
            for file in files:
                # Ignore dot files (hidden files)
                if file.startswith('.'):
                    continue

                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, directory)

                try:
                    with open(file_path, 'r') as infile:
                        # Write the relative file path as a header
                        outfile.write(f"\n\n--- File: {relative_path} ---\n\n")
                        outfile.write(infile.read())
                        outfile.write("\n")  # Add a newline after file content
                except Exception as e:
                    print(f"Could not read {file_path}: {e}")

if __name__ == "__main__":
    directory = input("Enter the directory to combine files from: ")
    output_file = "Project_Overview.txt"
    combine_files_in_directory(directory, output_file)
    print(f"All files have been combined into {output_file}.")



--- File: Project_Overview.txt ---



--- File: Dockerfile ---

FROM python:3.9-slim
WORKDIR /usr/src/app
COPY . .
RUN pip install --no-cache-dir -r requirements.txt
CMD ["python", "main.py"]



--- File: agents.py ---

import os
import subprocess
import sqlite3
import ast
import inspect

class BaseAgent:
    def __init__(self, name, knowledge_base):
        self.name = name
        self.knowledge_base = knowledge_base
        self.memory = {}

    def can_handle(self, task_name):
        raise NotImplementedError("Subclasses should implement this method.")

    def execute_task(self, task_name):
        raise NotImplementedError("Subclasses should implement this method.")

    def learn(self, task, outcome):
        if task not in self.memory:
            self.memory[task] = {"successes": 0, "failures": 0}
        
        if outcome == "success":
            self.memory[task]["successes"] += 1
        else:
            self.memory[task]["failures"] += 1

        print(f"{self.name} has learned from task {task}. Successes: {self.memory[task]['successes']}, Failures: {self.memory[task]['failures']}")

    def adjust_behavior(self, task):
        if task in self.memory and self.memory[task]["failures"] > self.memory[task]["successes"]:
            print(f"{self.name} adjusting behavior for task {task}")


class ProjectArchitectAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Project Architect AI", knowledge_base)
    
    def can_handle(self, task):
        return task == "architecture design"
    
    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is creating the project architecture...")
        
        project_structure = {
            "src": {
                "main.py": "# Main entry point",
                "utils.py": "# Utility functions",
                "tests": {
                    "test_main.py": "# Test cases for main"
                }
            },
            "docs": {
                "README.md": "# Project documentation"
            },
            "db": {},
            "logs": {},
        }
        base_path = "./real_project"
        os.makedirs(base_path, exist_ok=True)
        
        for folder, contents in project_structure.items():
            folder_path = os.path.join(base_path, folder)
            os.makedirs(folder_path, exist_ok=True)
            for file_name, file_content in contents.items():
                if isinstance(file_content, dict):
                    subdir_path = os.path.join(folder_path, file_name)
                    os.makedirs(subdir_path, exist_ok=True)
                    for subfile_name, subfile_content in file_content.items():
                        with open(os.path.join(subdir_path, subfile_name), 'w') as f:
                            f.write(subfile_content)
                else:
                    with open(os.path.join(folder_path, file_name), 'w') as f:
                        f.write(file_content)
        
        print(f"Real-world project structure created by {self.name}.")
        self.learn(task, "success")
        return "success"


class CodeGeneratorAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Code Generator AI", knowledge_base)
    
    def can_handle(self, task):
        return task == "code generation"
    
    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is generating advanced real-world code...")

        base_path = "./real_project/src/"
        advanced_code = '''
import logging
from flask import Flask, request, jsonify

app = Flask(__name__)

# Set up logging
logging.basicConfig(level=logging.INFO)

@app.before_request
def log_request_info():
    logging.info(f"Handling request: {request.method} {request.url}")

@app.errorhandler(404)
def not_found_error(error):
    return jsonify({"error": "Resource not found"}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({"error": "Internal server error"}), 500

@app.route('/api/v1/data', methods=['GET'])
def get_data():
    data = {"status": "success", "data": [i for i in range(100)]}
    logging.info("Data successfully fetched.")
    return jsonify(data)

if __name__ == "__main__":
    app.run(debug=True)
'''

        with open(os.path.join(base_path, "main.py"), 'w') as f:
            f.write(advanced_code)
        
        print(f"Advanced code generated by {self.name} and written to main.py.")
        self.learn(task, "success")
        return "success"


class TestAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Test AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "testing"

    def execute_task(self, task_name):
        if task_name == "testing":
            return self.run_tests()

    def run_tests(self):
        """
        Attempt to run real tests. Logs detailed test output and retries up to 3 times if tests fail.
        """
        test_dir = os.path.join(self.knowledge_base.get("project_structure", {}), "tests")
        if not os.path.exists(test_dir):
            print(f"No tests directory found at {test_dir}.")
            return "failure"
        
        try:
            result = subprocess.run(["pytest", test_dir], capture_output=True, text=True)
            print(result.stdout)
            if result.returncode == 0:
                print("All tests passed successfully.")
                return "success"
            else:
                print("Some tests failed.")
                return "failure"
        except Exception as e:
            print(f"Error while running tests: {str(e)}")
            return "failure"
class DebuggingAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Debugging AI", knowledge_base)

    def can_handle(self, task):
        return task == "debugging"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is performing real-world debugging...")

        try:
            print(f"Debugging task performed by {self.name}.")
            self.learn(task, "success")
            return "success"
        except Exception as e:
            print(f"Debugging failed with error: {e}")
            self.learn(task, "failure")
            return "failure"


class EnhancerAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Enhancer AI", knowledge_base)

    def can_handle(self, task):
        return task == "enhancement"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is enhancing the project...")

        enhancement_code = '''
def advanced_feature():
    print("Advanced feature implemented.")
'''

        base_path = "./real_project/src/utils.py"
        with open(base_path, 'a') as f:
            f.write(enhancement_code)

        print(f"Enhancement added to utils.py by {self.name}.")
        self.learn(task, "success")
        return "success"


class DocumentationAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Documentation AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "documentation"

    def execute_task(self, task_name):
        if task_name == "documentation":
            return self.generate_detailed_documentation()

    def generate_detailed_documentation(self):
        """
        Generates advanced documentation including:
        1. API Documentation (function signatures)
        2. Code Annotations (detailed explanations of code blocks)
        3. Workflow Diagrams (general flow of the project components)
        """
        print(f"{self.name} is generating detailed documentation...")

        # Step 1: Generate API Documentation
        self.generate_api_docs()

        # Step 2: Generate Code Annotations
        self.generate_code_annotations()

        # Step 3: Generate Workflow Diagrams (Simplified as textual representation for now)
        self.generate_workflow_diagrams()

        print(f"Detailed documentation generated by {self.name}.")
        self.learn("documentation", "success")
        return "success"

    def generate_api_docs(self):
        """
        Generate API documentation for all Python files by extracting function definitions and signatures.
        """
        print("Generating API documentation...")
        for module_name, module_ref in self.knowledge_base.get("modules", {}).items():
            print(f"\nModule: {module_name}")
            functions = inspect.getmembers(module_ref, inspect.isfunction)
            for function_name, function_ref in functions:
                signature = inspect.signature(function_ref)
                print(f"  Function: {function_name}{signature}")

    def generate_code_annotations(self):
        """
        Generate code annotations by analyzing the AST (Abstract Syntax Tree) and adding comments where appropriate.
        """
        print("Generating code annotations using AST...")
        for module_name, module_ref in self.knowledge_base.get("modules", {}).items():
            source_code = inspect.getsource(module_ref)
            root = ast.parse(source_code)

            print(f"\nAnnotations for {module_name}:")
            for node in ast.walk(root):
                if isinstance(node, ast.FunctionDef):
                    print(f"  Function {node.name} is defined at line {node.lineno}.")
                elif isinstance(node, ast.ClassDef):
                    print(f"  Class {node.name} found at line {node.lineno}.")

    def generate_workflow_diagrams(self):
        """
        Generate a simplified diagram of workflow/processes in the system. 
        This is a mockup and can later be improved with tools like graphviz or UML generators.
        """
        print("Generating workflow diagram...\n")

        # Simulating the generation of a workflow diagram (text-based for now)
        workflow = """
        [Team Leader AI] --> Assign Tasks
        [Load Balancer] --> Distribute Tasks to Agents
        [Agents] --> Perform Tasks (e.g., Code Generation, Testing, Debugging)
        [Documentation AI] --> Generate Reports on Project State
        """
        print(workflow)


class DeploymentAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Deployment AI", knowledge_base)

    def can_handle(self, task):
        return task == "deployment"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is deploying the project...")

        dockerfile_content = '''
FROM python:3.9-slim

WORKDIR /app

COPY . /app

RUN pip install -r requirements.txt

CMD ["python", "main.py"]
'''

        with open("./real_project/Dockerfile", 'w') as f:
            f.write(dockerfile_content)

        print(f"Dockerfile created by {self.name}.")
        self.learn(task, "success")
        return "success"


class SecurityAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Security AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "security audit"

    def execute_task(self, task_name):
        if task_name == "security audit":
            return self.perform_security_audit()

    def perform_security_audit(self):
        """
        Perform a security audit, detect vulnerabilities, and attempt to fix them.
        """
        print("Security AI is performing a security audit...")
        vulnerabilities = ["Insecure default configuration", "Weak encryption algorithm"]
        print("Vulnerabilities detected:\n" + "\n".join(vulnerabilities))

        try:
            self.fix_vulnerabilities(vulnerabilities)
            return "success"
        except Exception as e:
            print(f"Failed to fix vulnerabilities: {str(e)}")
            return "failure"

    def fix_vulnerabilities(self, vulnerabilities):
        """
        Fixes known vulnerabilities. For example, update configs, replace weak encryption algorithms, etc.
        """
        for vulnerability in vulnerabilities:
            if "Insecure default configuration" in vulnerability:
                config_file = os.path.join(self.knowledge_base.get("project_structure", {}), "config.yml")
                if os.path.exists(config_file):
                    with open(config_file, 'a') as f:
                        f.write("secure: true\n")
                    print("Insecure default configuration fixed.")
            elif "Weak encryption algorithm" in vulnerability:
                code_file = os.path.join(self.knowledge_base.get("project_structure", {}), "encryption.py")
                if os.path.exists(code_file):
                    with open(code_file, 'r') as f:
                        content = f.read()
                    updated_content = content.replace("AES256", "AES512")
                    with open(code_file, 'w') as f:
                        f.write(updated_content)
                    print("Weak encryption algorithm fixed.")


class DatabaseAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Database AI", knowledge_base)

    def can_handle(self, task):
        return task == "database setup"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is setting up the database...")

        db_path = "./real_project/db/project.db"
        os.makedirs(os.path.dirname(db_path), exist_ok=True)

        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()

            cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY,
                username TEXT NOT NULL,
                email TEXT NOT NULL UNIQUE
            )
            ''')

            conn.commit()
            conn.close()
            print(f"Database created by {self.name}.")
            self.learn(task, "success")
            return "success"
        except sqlite3.Error as e:
            print(f"Database setup failed: {e}")
            self.learn(task, "failure")
            return "failure"


class LoggingAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Logging AI", knowledge_base)

    def can_handle(self, task):
        return task == "logging setup"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is setting up logging for the project...")

        logging_config = '''
import logging

logging.basicConfig(filename='./real_project/logs/app.log', level=logging.INFO,
                    format='%(asctime)s %(levelname)s: %(message)s')

logging.info("Logging is set up.")
'''

        with open("./real_project/src/logging_setup.py", 'w') as f:
            f.write(logging_config)

        print(f"Logging setup complete by {self.name}.")
        self.learn(task, "success")
        return "success"


class VersionControlAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Version Control AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "version control"

    def execute_task(self, task_name):
        if task_name == "version control":
            return self.handle_version_control()

    def handle_version_control(self):
        """
        Main method which handles version control tasks, like branch management and merging.
        """
        print(f"{self.name} is managing version control...")

        # Step 1: Ensure branch management
        self.manage_branches()

        # Step 2: Optimize merge strategies based on task status
        self.suggest_merge_strategy()

        self.learn("version control", "success")
        return "success"

    def manage_branches(self):
        """
        Automatically manage branches by checking the current progress and ensuring branch strategy.
        For now, this involves checking out to the correct branches based on priority tasks.
        """
        print("Managing branches...")

        # Example: Check for active branches and automatically create or switch between them
        branches = self.get_branches()
        if 'main' not in branches:
            self.create_branch('main')

        current_branch = self.get_current_branch() 
        if current_branch != 'main':
            print(f"Switching to 'main' branch from '{current_branch}'...")
            self.checkout_branch('main')

    def suggest_merge_strategy(self):
        """
        Suggests merge strategies based on the progress of tasks by different agents.
        For example, fast-forward merges for simple changes and rebase or squash strategies for complex histories.
        """
        print("Analyzing for merge strategy suggestions...")

        # Analyze branch status and decide merge strategy
        pending_merges = self.check_pending_merges()
        
        if pending_merges:
            for branch in pending_merges:
                if branch in ['feature', 'enhancement']:
                    print(f"Suggesting 'fast-forward' merge for '{branch}' branch.")
                else:
                    print(f"Suggesting 'squash' merge for complex commits on branch '{branch}'.")
        else:
            print("No pending merges detected.")

    def get_branches(self):
        """
        Returns a list of branches in the current repository.
        """
        branches = subprocess.run(['git', 'branch'], text=True, capture_output=True).stdout.splitlines()
        branch_names = [branch.strip('* ') for branch in branches]
        print(f"Available branches: {branch_names}")
        return branch_names

    def get_current_branch(self):
        """
        Returns the name of the current active branch.
        """
        current_branch = subprocess.run(['git', 'branch', '--show-current'], text=True, capture_output=True).stdout.strip()
        print(f"Current branch: {current_branch}")
        return current_branch

    def create_branch(self, branch_name):
        """
        Creates a new branch if it doesn't exist.
        """
        print(f"Creating new branch '{branch_name}'.")
        subprocess.run(['git', 'checkout', '-b', branch_name])

    def checkout_branch(self, branch_name):
        """
        Checkout to the specified branch.
        """
        subprocess.run(['git', 'checkout', branch_name])

    def check_pending_merges(self):
        """
        Mock function to simulate pending branches needing merging.
        This would be extended to dynamically check branches that are behind or ahead of the main branch.
        """
        # Simulating pending branches that need merging. You can further develop this logic as necessary.
        return ["feature", "enhancement"]


class FrontendGeneratorAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Frontend Generator AI", knowledge_base)

    def can_handle(self, task):
        return task == "frontend generation"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is generating frontend for the project...")

        frontend_code = '''
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Frontend</title>
</head>
<body>
    <h1>Welcome to the Project</h1>
    <p>This is an advanced frontend page generated by the AI team.</p>
</body>
</html>
'''

        with open("./real_project/src/frontend.html", 'w') as f:
            f.write(frontend_code)

        print(f"Frontend generated by {self.name}.")
        self.learn(task, "success")
        return "success"



--- File: dynamic_thread_pool.py ---

import psutil
from concurrent.futures import ThreadPoolExecutor

class DynamicThreadPoolExecutor:
    def __init__(self, max_workers):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)

    def adjust_workers(self, cpu_usage, memory_usage, io_usage, network_usage):
        """
        Adjust worker count based on system's resource usage, including disk I/O and network bandwidth.
        """
        # Reduce the number of workers if CPU, memory, disk I/O, or network usage is too high
        if cpu_usage > 80 or memory_usage > 80 or io_usage > 80 or network_usage > 75:
            new_worker_count = max(1, self.max_workers // 2)  # Reduce workers to alleviate load
            self.executor = ThreadPoolExecutor(max_workers=new_worker_count)
            print(f"Reducing worker count to {new_worker_count} due to high resource usage: CPU({cpu_usage}%), Memory({memory_usage}%), IO({io_usage}%), Network({network_usage}%)")
        # Increase workers if the system is underutilized
        elif cpu_usage < 40 and memory_usage < 40 and io_usage < 40 and network_usage < 30:
            new_worker_count = min(self.max_workers * 2, 10)  # Increase workers to better utilize capacity
            self.executor = ThreadPoolExecutor(max_workers=new_worker_count)
            print(f"Increasing worker count to {new_worker_count} due to low resource usage: CPU({cpu_usage}%), Memory({memory_usage}%), IO({io_usage}%), Network({network_usage}%)")

    def monitor_resource_usage(self):
        """
        Fetch system resource usage: CPU, memory, disk I/O, and network IO.
        """
        cpu_usage = psutil.cpu_percent(interval=1)
        memory_usage = psutil.virtual_memory().percent
        io_usage = psutil.disk_io_counters().write_time   # Monitoring disk write time in milliseconds
        network_usage = psutil.net_io_counters().bytes_sent  # Monitoring network bytes sent
        # Normalize IO and network data
        normalized_io_usage = min(100, (io_usage / 1000) * 10)  # Simple normalization (adjust as necessary)
        normalized_network_usage = min(100, (network_usage / (1024 * 1024)) * 10)  # Convert bytes to MB and normalize
        return cpu_usage, memory_usage, normalized_io_usage, normalized_network_usage

    def submit_task(self, fn, *args, **kwargs):
        """
        Submit a task to the executor, dynamically adjusting the worker count based on system resources.
        """
        cpu_usage, memory_usage, io_usage, network_usage = self.monitor_resource_usage()
        self.adjust_workers(cpu_usage, memory_usage, io_usage, network_usage)
        return self.executor.submit(fn, *args, **kwargs)



--- File: health_check_manager.py ---

class HealthCheckManager:
    def __init__(self, system_monitor, agent_health_monitor):
        self.system_monitor = system_monitor
        self.agent_health_monitor = agent_health_monitor

    def perform_health_check(self, agent_name):
        cpu_usage, memory_usage = self.system_monitor.monitor_resources()
        self.agent_health_monitor.monitor_agent_health(agent_name)
        if cpu_usage > 85 or memory_usage > 85:
            print(f"System overload detected. Rebalancing tasks.")



--- File: knowledge_base.py ---

class SharedKnowledgeBase:
    def __init__(self):
        self.data = {}

    def store(self, key, value):
        self.data[key] = value

    def get(self, key, default=None):
        return self.data.get(key, default)

    def delete(self, key):
        if key in self.data:
            del self.data[key]

    def list_contents(self):
        """
        Lists all content currently stored in the knowledge base.
        """
        if not self.data:
            print("Shared knowledge base is empty.")
        else:
            print("Shared Knowledge Base Contents:")
            for key, value in self.data.items():
                print(f"  - {key}: {value}")

        return self.data



--- File: load_balancer.py ---

class LoadBalancer:
    """
    Distributes tasks evenly across available agents to avoid bottlenecks.
    Now considers agent expertise when assigning tasks.
    """
    def __init__(self, agents):
        self.agents = agents
        self.agent_loads = {agent.name: 0 for agent in agents}
        self.agent_expertises = {  # Identifying the best agent for each type of task
            "architecture design": "Project Architect AI",
            "code generation": "Code Generator AI",
            "debugging": "Debugging AI",
            "testing": "Test AI",
            "enhancement": "Enhancer AI",
            "documentation": "Documentation AI",
            "deployment": "Deployment AI",
            "security audit": "Security AI",
            "database setup": "Database AI",
            "logging setup": "Logging AI",
            "version control": "Version Control AI",
            "frontend generation": "Frontend Generator AI"
        }

    def assign_task(self, task):
        """
        Assigns the task to the least busy agent, while also prioritizing agents who are experts at this task.
        """
        # Identify the expert agent for the task
        expert_agent_name = self.agent_expertises.get(task)

        if expert_agent_name:
            # Ensure the expert agent still exists in the system
            if expert_agent_name in self.agent_loads:
                least_busy_expert = expert_agent_name
            else:
                # Fallback to least busy agent if expertise agent is not found
                least_busy_expert = min(self.agent_loads, key=self.agent_loads.get)
            
            print(f"Assigning task '{task}' to the expert agent: {least_busy_expert}.")
        else:
            # No specific expertise available, assign to the least busy agent
            least_busy_expert = min(self.agent_loads, key=self.agent_loads.get)
            print(f"Assigning task '{task}' to {least_busy_expert}, no specific expertise required.")
        
        assigned_agent = next(agent for agent in self.agents if agent.name == least_busy_expert)
        self.agent_loads[least_busy_expert] += 1
        return assigned_agent

    def task_completed(self, agent_name):
        """
        Marks a task as completed by the given agent, reducing their current load.
        """
        if agent_name in self.agent_loads:
            self.agent_loads[agent_name] = max(0, self.agent_loads[agent_name] - 1)

# Example agents list to simulate load balancer functioning:
"""
agents = {
    "Project Architect AI": ProjectArchitectAI(knowledge_base),
    "Code Generator AI": CodeGeneratorAI(knowledge_base),
    "Debugging AI": DebuggingAI(knowledge_base),
    "Test AI": TestAI(knowledge_base),
    "Enhancer AI": EnhancerAI(knowledge_base),
    "Documentation AI": DocumentationAI(knowledge_base),
    "Deployment AI": DeploymentAI(knowledge_base),
    "Security AI": SecurityAI(knowledge_base),
    "Database AI": DatabaseAI(knowledge_base),
    "Logging AI": LoggingAI(knowledge_base),
    "Version Control AI": VersionControlAI(knowledge_base),
    "Frontend Generator AI": FrontendGeneratorAI(knowledge_base)
}
"""



--- File: main.py ---

from system import TeamLeaderAI
from knowledge_base import SharedKnowledgeBase
from agents import ProjectArchitectAI, CodeGeneratorAI, TestAI, EnhancerAI, DocumentationAI, DeploymentAI, SecurityAI, DatabaseAI, LoggingAI, VersionControlAI, FrontendGeneratorAI, DebuggingAI

# Initialize the shared knowledge base
knowledge_base = SharedKnowledgeBase()

# Define collaborative agents and pass the shared knowledge base
agents = {
    "Project Architect AI": ProjectArchitectAI(knowledge_base),
    "Code Generator AI": CodeGeneratorAI(knowledge_base),
    "Test AI": TestAI(knowledge_base),
    "Enhancer AI": EnhancerAI(knowledge_base),
    "Documentation AI": DocumentationAI(knowledge_base),
    "Deployment AI": DeploymentAI(knowledge_base),
    "Security AI": SecurityAI(knowledge_base),
    "Database AI": DatabaseAI(knowledge_base),
    "Logging AI": LoggingAI(knowledge_base),
    "Version Control AI": VersionControlAI(knowledge_base),
    "Frontend Generator AI": FrontendGeneratorAI(knowledge_base),
    "Debugging AI": DebuggingAI(knowledge_base)
}

# Initialize the Team Leader AI
team_leader = TeamLeaderAI(agents)

# Ask the user what they want the team to do
team_leader.receive_user_input()

# Print the task progress
team_leader.report_progress()

# Store some knowledge in the knowledge base
knowledge_base.store("key1", "This is some knowledge about task1.")
knowledge_base.store("key2", "This is some knowledge about task2.")

# List the shared knowledge base contents:
knowledge_base.list_contents()

# Retrieve specific knowledge
task1_knowledge = knowledge_base.get("key1")
print(f"Retrieved knowledge for task1: {task1_knowledge}")

task2_knowledge = knowledge_base.get("key2")
print(f"Retrieved knowledge for task2: {task2_knowledge}")



--- File: requirements.txt ---

psutil



--- File: system.py ---

from task_priority_queue import TaskPriorityQueue
from task_monitor import TaskMonitor
from agent_health_monitor import AgentHealthMonitor
from system_monitor import SystemMonitor
from health_check_manager import HealthCheckManager
from dynamic_thread_pool import DynamicThreadPoolExecutor
from load_balancer import LoadBalancer
import os

class TeamLeaderAI:
    def __init__(self, agents, retry_limit=3):
        self.agents = agents
        self.task_priority_queue = TaskPriorityQueue(SystemMonitor())  # Using SystemMonitor to help with task scheduling
        self.task_progress = {}  # Track task states: {'task_name': {'status': 'queued/active/completed', 'agent': <agent_name>, 'start_time': <timestamp>}}
        self.task_completion_data = {}  # Track the details of completed tasks
        self.retry_limit = retry_limit
        self.task_retries = {}
        self.thread_pool = DynamicThreadPoolExecutor(max_workers=3)
        self.load_balancer = LoadBalancer(self.agents.values())  # Reference to LoadBalancer
        self.task_monitor = TaskMonitor()  # Task monitor for tracking task execution time
        self.agent_health_monitor = AgentHealthMonitor(self.agents.values(), self.load_balancer)
        self.system_monitor = SystemMonitor()  # Monitor system resources
        self.health_check_manager = HealthCheckManager(self.system_monitor, self.agent_health_monitor)
        self.project_path = None

    def get_user_input(self):
        """
        Asks the user what they want the AI team to do.
        """
        print("What do you want the AI team to do? Choose from the following options:")
        print("1. Create a whole project")
        print("2. Enhance an existing project")
        print("3. Debug a project")
        print("4. Add new features and capabilities to a project")
        print("5. Test a project")
        choice = input("Enter the number of your choice: ")

        return int(choice)

    def ask_for_project_path(self):
        """
        Ask the user for the project path and ensure it exists.
        """
        self.project_path = input("Please enter the path to the project you want to work on: ")
        if not os.path.exists(self.project_path):
            print(f"Error: The specified path {self.project_path} does not exist.")
            return False
        return True

    def receive_user_input(self):
        """
        Determines what the user wants based on input.
        """
        choice = self.get_user_input()
        if choice == 1:
            print("You selected to create a whole project.")
            project_type = input("Enter the type of project (e.g., web app, API, machine learning, etc.): ")
            self.decompose_project(f"Create a {project_type}")
        elif choice in [2, 3, 4, 5]:
            if not self.ask_for_project_path():
                return
            if choice == 2:
                print("You selected to enhance an existing project.")
                self.decompose_project("Enhance project")
            elif choice == 3:
                print("You selected to debug a project.")
                self.decompose_project("Debug project")
            elif choice == 4:
                print("You selected to add new features and capabilities.")
                self.decompose_project("Add features and capabilities")
            elif choice == 5:
                print("You selected to test a project.")
                self.decompose_project("Test project")
        else:
            print("Invalid choice.")
    
    def decompose_project(self, overview):
        tasks = [
            (1, "architecture design"),
            (2, "code generation"),
            (3, "debugging"),
            (4, "testing"),
            (5, "enhancement"),
            (6, "documentation"),
            (7, "deployment"),
            (8, "security audit"),
            (9, "database setup"),
            (10, "logging setup"),
            (11, "version control"),
            (12, "frontend generation")
        ]
        for priority, task in tasks:
            self.task_priority_queue.add_task(priority, task)
        self.assign_tasks()

    def assign_tasks(self):
        """
        Assign tasks from the task priority queue to agents.
        """
        while task_name := self.task_priority_queue.get_next_task():
            agent = self.load_balancer.assign_task(task_name)
            self.thread_pool.submit_task(self.execute_task, agent, task_name)
            self.update_task_status(task_name, 'active', agent.name)  # Mark task as active

    def find_agent_for_task(self, task_name):
        for agent in self.agents.values():
            if agent.can_handle(task_name):
                return agent
        return None

    def execute_task(self, agent, task_name):
        """
        Executes the task using the assigned agent.
        """
        try:
            start_time = time.time()  # Track the starting time of the task
            self.task_monitor.start_task(task_name)

            # Execute the task and record its outcome
            outcome = agent.execute_task(task_name)
            elapsed_time = self.task_monitor.end_task(task_name)  # Track task completion time

            self.task_completion_data[task_name] = {
                'status': 'completed',
                'agent': agent.name,
                'duration': elapsed_time,
                'outcome': outcome
            }

            print(f"Task '{task_name}' completed by {agent.name} with outcome: {outcome}")
        except Exception as e:
            print(f"Error in executing task '{task_name}' by {agent.name}: {e}")
            self.record_failure(task_name, agent)

    def handle_agent_feedback(self, task_name, result):
        if result == "success":
            self.task_progress[task_name] = "completed"
        else:
            self.recover_from_failure(task_name)

    def recover_from_failure(self, task):
        if self.task_retries[task] < self.retry_limit:
            self.task_retries[task] += 1
            agent = self.find_agent_for_task(task)
            if agent:
                self.execute_task(agent, task)
        else:
            print(f"Task {task} has exceeded the retry limit.")

    def update_task_status(self, task_name, status, agent_name):
        """
        Updates the task progress status (active, completed, etc.) and records the agent assigned to the task.
        """
        self.task_progress[task_name] = {
            'status': status,
            'agent': agent_name
        }

    def report_progress(self):
        """
        Displays a real-time dashboard showing task progress.
        """
        print("\n--- Task Progress Dashboard ---")
        print("Queued Tasks:")
        queued_tasks = [task for task, status in self.task_progress.items() if status['status'] == 'queued']
        if queued_tasks:
            for task in queued_tasks:
                print(f"  {task} (Agent: {self.task_progress[task]['agent']})")
        else:
            print("  No queued tasks.")

        print("\nActive Tasks:")
        active_tasks = [task for task, status in self.task_progress.items() if status['status'] == 'active']
        if active_tasks:
            for task in active_tasks:
                print(f"  {task} (Agent: {self.task_progress[task]['agent']})")
        else:
            print("  No active tasks.")

        print("\nCompleted Tasks:")
        completed_tasks = [task for task, status in self.task_progress.items() if status['status'] == 'completed']
        if completed_tasks:
            for task in completed_tasks:
                print(f"  {task} (Agent: {self.task_progress[task]['agent']}, Duration: {self.task_completion_data[task]['duration']:.2f} seconds, Outcome: {self.task_completion_data[task]['outcome']})")
        else:
            print("  No completed tasks.")

        print("\n--- End of Dashboard Report ---")

    def report_overall_progress(self):
        """
        Summarizes overall task progress, including completion rates.
        """
        total_tasks = len(self.task_progress)
        completed_tasks = len([task for task in self.task_progress if self.task_progress[task]['status'] == 'completed'])
        success_tasks = len([task for task in self.task_completion_data if self.task_completion_data[task]['outcome'] == 'success'])

        print("\n--- Overall Task Completion Summary ---")
        print(f"Total Tasks: {total_tasks}")
        print(f"Completed Tasks: {completed_tasks}")
        print(f"Successful Tasks: {success_tasks}")
        print(f"Completion Rate: {(completed_tasks / total_tasks) * 100:.2f}%")
        print(f"Success Rate: {(success_tasks / completed_tasks) * 100:.2f}% (for completed tasks)")
        print("\n--- End of Summary ---")

    def retry_task(self, task_name, agent_name):
        """
        Attempts to retry a failed task a limited number of times.
        """
        retries = self.task_retries.get(task_name, 0)
        if retries < self.retry_limit:
            print(f"Retrying task '{task_name}' (Attempt {retries + 1}/{self.retry_limit})...")
            self.task_retries[task_name] = retries + 1
            self.assign_tasks()
        else:
            print(f"Task '{task_name}' failed after {self.retry_limit} retries.")
    
    def record_failure(self, task_name, agent):
        """
        Record task failure and decide whether to retry based on retry limit.
        """
        if task_name not in self.task_retries:
            self.task_retries[task_name] = 0

        if self.task_retries[task_name] < self.retry_limit:
            print(f"Task '{task_name}' failed. Retrying...")
            self.retry_task(task_name, agent.name)
        else:
            print(f"Task '{task_name}' exceeded retry limit. Marked as failed.")




--- File: system_monitor.py ---

import psutil

class SystemMonitor:
    def __init__(self):
        self.alert_thresholds = {
            'cpu': 85,  # Alert if CPU usage exceeds 85%
            'memory': 85,  # Alert if memory usage exceeds 85%
            'disk': 80,  # Alert if disk usage exceeds 80%
            'network_sent': 75,  # Alert if network outgoing exceeds 75% of bandwidth (mock)
        }

    def monitor_resources(self):
        """
        Monitors the system's resource usage.
        """
        cpu_usage = psutil.cpu_percent(interval=1)
        memory_usage = psutil.virtual_memory().percent
        disk_usage = psutil.disk_usage('/').percent
        network_usage_sent = self.get_network_sent_usage()

        print(f"CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage}%, Disk Usage: {disk_usage}%, Network Outgoing: {network_usage_sent}%")
        
        # Trigger alerts if any usage exceeds pre-defined thresholds
        self.check_alerts(cpu_usage, memory_usage, disk_usage, network_usage_sent)

        return cpu_usage, memory_usage, disk_usage, network_usage_sent

    def check_alerts(self, cpu_usage, memory_usage, disk_usage, network_usage_sent):
        """
        Checks system metrics against pre-defined threshold limits and issues alerts if exceeded.
        """
        if cpu_usage > self.alert_thresholds['cpu']:
            print(f"ALERT: CPU Usage exceeds {self.alert_thresholds['cpu']}% (Current: {cpu_usage}%)")

        if memory_usage > self.alert_thresholds['memory']:
            print(f"ALERT: Memory Usage exceeds {self.alert_thresholds['memory']}% (Current: {memory_usage}%)")

        if disk_usage > self.alert_thresholds['disk']:
            print(f"ALERT: Disk Usage exceeds {self.alert_thresholds['disk']}% (Current: {disk_usage}%)")

        if network_usage_sent > self.alert_thresholds['network_sent']:
            print(f"ALERT: Network Outgoing exceeds {self.alert_thresholds['network_sent']}% (Current: {network_usage_sent}%)")

    def get_network_sent_usage(self):
        """
        Simulate network usage monitoring. You could modify this part to reflect real network usage.
        """
        net_io = psutil.net_io_counters()
        sent = net_io.bytes_sent / (1024 * 1024)  # Convert the sent bytes to megabytes
        # For now, we'll return a mock "percentage", just scale bytes sent arbitrarily
        return min(100, (sent / 5) * 10)  # This is a mock calculation assuming 5MB threshold.
    
    def trigger_alert(self, alert_message):
        """
        Optional: Hook this up with a notification/alerting system (e.g., email, logging, etc.).
        """
        # Notifies via print for now; can change as needed (e.g., hook with logging service).
        print(f"Triggering Alert: {alert_message}")



--- File: task_monitor.py ---

import time

class TaskMonitor:
    def __init__(self):
        self.task_times = {}
        self.task_history = {}  # New dictionary to track task completion times
    
    def start_task(self, task_name):
        """
        Starts tracking the task's start time.
        """
        self.task_times[task_name] = time.time()
        print(f"Started task '{task_name}' at {self.task_times[task_name]}")

    def end_task(self, task_name):
        """
        Stops tracking the task's time and records the duration for analytics.
        """
        if task_name in self.task_times:
            elapsed_time = time.time() - self.task_times[task_name]
            print(f"Task '{task_name}' completed in {elapsed_time:.2f} seconds.")
            
            # Store the elapsed time in task history for tracking multiple runs
            if task_name not in self.task_history:
                self.task_history[task_name] = []
            self.task_history[task_name].append(elapsed_time)

            del self.task_times[task_name]
            return elapsed_time
        return None

    def get_average_time(self, task_name):
        """
        Calculates the average completion time for a given task, based on historical data.
        """
        if task_name in self.task_history and self.task_history[task_name]:
            avg_time = sum(self.task_history[task_name]) / len(self.task_history[task_name])
            print(f"Average time for task '{task_name}': {avg_time:.2f} seconds.")
            return avg_time
        else:
            print(f"No historical data for task '{task_name}'.")
            return None

    def display_task_statistics(self):
        """
        Displays a summary of task performance statistics, including average and total run times.
        """
        if self.task_history:
            print("\nTask Performance Summary:")
            for task_name, times in self.task_history.items():
                total_runs = len(times)
                total_time = sum(times)
                average_time = total_time / total_runs if total_runs > 0 else 0
                print(f"Task: {task_name}, Total Runs: {total_runs}, Average Time: {average_time:.2f} seconds, Total Time: {total_time:.2f} seconds.")
        else:
            print("No tasks have been completed yet to show statistics.")



--- File: task_priority_queue.py ---

import heapq

class TaskPriorityQueue:
    def __init__(self, system_monitor):
        self.queue = []
        self.system_monitor = system_monitor  # Allow access to system resource data

    def add_task(self, priority, task_name, resource_intensity):
        """
        Add task to priority queue with priority and an estimated resource intensity (e.g., high, medium, low).
        """
        heapq.heappush(self.queue, (priority, task_name, resource_intensity))

    def get_next_task(self):
        """
        Fetch the next task, prioritizing based on system resource availability.
        """
        if not self.queue:
            return None

        # Get system's current resources utilization
        cpu_usage, memory_usage, _, _ = self.system_monitor.monitor_resources()

        # Try to prioritize tasks that match the current system conditions
        best_match = None
        for i in range(len(self.queue)):
            priority, task_name, resource_intensity = self.queue[i]

            if resource_intensity == 'low' or (cpu_usage < 50 and memory_usage < 50):
                best_match = heapq.heappop(self.queue)
                break
            elif resource_intensity == 'medium' and (cpu_usage < 70 and memory_usage < 70):
                best_match = heapq.heappop(self.queue)
                break
            elif resource_intensity == 'high' and (cpu_usage < 90 and memory_usage < 90):
                best_match = heapq.heappop(self.queue)
                break

        if best_match:
            return best_match[1]  # Return the task_name after finding the best match
        else:
            print("System is too overloaded; delaying resource-heavy tasks.")
            return None

    def display_pending_tasks(self):
        """
        Display tasks currently pending in the queue, sorted by priority.
        """
        if not self.queue:
            print("No pending tasks.")
            return
        
        print("Pending tasks:")
        for priority, task_name, resource_intensity in sorted(self.queue):
            print(f"Priority {priority}: Task '{task_name}' (Resource Intensity: {resource_intensity})")




--- File: agent_health_monitor.py ---

class AgentHealthMonitor:
    """
    Monitors the health and performance of agents.
    """
    def __init__(self, agents, load_balancer):
        self.agent_health = {agent.name: {"tasks_handled": 0, "successes": 0, "failures": 0} for agent in agents}
        self.load_balancer = load_balancer  # Adding load balancer reference to rebalance tasks
    
    def record_task(self, agent_name, outcome):
        """
        Records the outcome of a task handled by an agent.
        Expects 'outcome' to be either 'success' or 'failure' and updates the agent's health accordingly.
        """
        self.agent_health[agent_name]["tasks_handled"] += 1
        if outcome == "success":
            self.agent_health[agent_name]["successes"] += 1
        elif outcome == "failure":
            self.agent_health[agent_name]["failures"] += 1
        else:
            raise ValueError(f"Unknown task outcome: {outcome}")
        
        self.display_health(agent_name)    # Displaying health after every record.
        self.monitor_agent_health(agent_name)   # Triggering health monitoring after each task
    
    def display_health(self, agent_name):
        """
        Displays the current health of an agent.
        """
        health = self.agent_health[agent_name]
        print(f"{agent_name} Health: Tasks Handled: {health['tasks_handled']}, Successes: {health['successes']}, Failures: {health['failures']}")
    
    def monitor_agent_health(self, agent_name):
        """
        Checks if the agent is failing too often and triggers rebalancing if necessary.
        """
        health = self.agent_health[agent_name]
        if health['failures'] > health['successes']:
            print(f"Warning: {agent_name} is experiencing frequent failures.")
            self.trigger_rebalance(agent_name)   # Automatically rebalance if failure rate exceeds success rate.
    
    def trigger_rebalance(self, failing_agent_name):
        """
        Automatically reassigns tasks if an agent is failing too often.
        """
        print(f"Reassigning tasks from {failing_agent_name} due to frequent failures.")
        # Rebalance logic: Transfer some tasks away from the failing agent to the least busy agent.
        rebalanced_agent = self.load_balancer.assign_task("Rebalance Task")  
        print(f"Tasks reassigned from {failing_agent_name} to {rebalanced_agent.name}.")

class LoadBalancer:
    """
    Distributes tasks evenly across available agents to avoid bottlenecks.
    """
    def __init__(self, agents):
        self.agents = agents
        self.agent_loads = {agent.name: 0 for agent in agents}

    def assign_task(self, task):
        """
        Assigns the task to the least busy agent.
        """
        least_busy_agent = min(self.agent_loads, key=self.agent_loads.get)
        print(f"Assigning task '{task}' to {least_busy_agent}.")
        return [agent for agent in self.agents if agent.name == least_busy_agent][0]

    def task_completed(self, agent_name):
        """
        Marks a task as completed by the given agent.
        """
        self.agent_loads[agent_name] -= 1

class HealthCheckManager:
    def __init__(self, system_monitor, agent_health_monitor):
        self.system_monitor = system_monitor
        self.agent_health_monitor = agent_health_monitor

    def perform_health_check(self, agent_name):
        cpu_usage, memory_usage = self.system_monitor.monitor_resources()
        self.agent_health_monitor.monitor_agent_health(agent_name)
        if cpu_usage > 85 or memory_usage > 85:
            print(f"System overload detected. Rebalancing tasks.")
            self.agent_health_monitor.trigger_rebalance(agent_name)

