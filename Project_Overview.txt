

--- File: Project_Overview.txt ---




--- File: test_task_priority_queue.py ---

# test_task_priority_queue.py
import unittest
from task_priority_queue import TaskPriorityQueue
class TestTaskPriorityQueue(unittest.TestCase):
    def setUp(self):
        self.priority_queue = TaskPriorityQueue()
    def test_enqueue_task(self):
        self.priority_queue.enqueue("task1", priority=1)
        self.priority_queue.enqueue("task2", priority=3)
        self.priority_queue.enqueue("task3", priority=2)
        self.assertEqual(len(self.priority_queue.queue), 3)
    def test_dequeue_task(self):
        self.priority_queue.enqueue("task1", priority=1)
        self.priority_queue.enqueue("task2", priority=3)
        task = self.priority_queue.dequeue()
        self.assertEqual(task, "task1")
    def test_queue_emptiness(self):
        self.priority_queue.enqueue("task1", priority=1)
        self.priority_queue.dequeue()
        self.assertTrue(self.priority_queue.is_empty())
    def test_peek_task(self):
        self.priority_queue.enqueue("task1", priority=1)
        self.priority_queue.enqueue("task2", priority=3)
        task = self.priority_queue.peek()
        self.assertEqual(task, "task1")
if __name__ == '__main__':
    unittest.main()



--- File: system.py ---

from task_priority_queue import TaskPriorityQueue
from task_monitor import TaskMonitor
from agent_health_monitor import AgentHealthMonitor
from system_monitor import SystemMonitor
from health_check_manager import HealthCheckManager
from dynamic_thread_pool import DynamicThreadPoolExecutor
from load_balancer import LoadBalancer
import os
import time

class TeamLeaderAI:
    def __init__(self, agents, knowledge_base, retry_limit=3):
        self.agents = agents
        self.knowledge_base = knowledge_base
        self.task_priority_queue = TaskPriorityQueue(SystemMonitor())
        self.task_progress = {}  # Track task states
        self.task_completion_data = {}  # Track completed task details
        self.retry_limit = retry_limit
        self.task_retries = {}
        self.thread_pool = DynamicThreadPoolExecutor(max_workers=3)
        self.load_balancer = LoadBalancer(self.agents.values(), self.knowledge_base)
        self.task_monitor = TaskMonitor()
        self.agent_health_monitor = AgentHealthMonitor(self.agents.values(), self.load_balancer)
        self.system_monitor = SystemMonitor()
        self.health_check_manager = HealthCheckManager(self.system_monitor, self.agent_health_monitor)
        self.project_path = None
        self.active_tasks = {}
        self.completed_tasks = []
        self.project_type = None

    def get_user_input(self):
        print("What do you want the AI team to do? Choose from the following options:")
        print("1. Create a whole project")
        print("2. Enhance an existing project")
        print("3. Debug a project")
        print("4. Add new features and capabilities to a project")
        print("5. Test a project")
        choice = input("Enter the number of your choice: ")
        return int(choice)
    
    def ask_for_project_path(self):
        while True:
            path = input("Enter the full path to your project directory: ")
            if os.path.isdir(path):
                return path
            else:
                print("Invalid directory path. Please enter a valid path.")
    
    def receive_user_input(self):
        choice = self.get_user_input()
        if choice == 1:
            print("You selected to create a whole project.")
            self.project_type = input("Enter the type of project (e.g., web app, API, machine learning, etc.): ")
            self.decompose_project(f"Create a {self.project_type}")
        elif choice in [2, 3, 4, 5]:
            if not self.ask_for_project_path():
                return
            task_overview = {
                2: "Enhance project",
                3: "Debug project",
                4: "Add features and capabilities",
                5: "Test project"
            }
            print(f"You selected to {task_overview[choice].lower()}.")
            self.decompose_project(task_overview[choice])
        else:
            print("Invalid choice.")

    def decompose_project(self, overview):
        tasks = [
            (1, "architecture design"),
            (2, "code generation"),
            (3, "debugging"),
            (4, "testing"),
            (5, "enhancement"),
            (6, "documentation"),
            (7, "deployment"),
            (8, "security audit"),
            (9, "database setup"),
            (10, "logging setup"),
            (11, "version control"),
            (12, "frontend generation")
        ]
        for priority, task in tasks:
            self.task_priority_queue.add_task(priority, task, "medium")
        self.assign_tasks()

    def assign_tasks(self):
        """
        Assigns tasks to agents based on priority and dependency resolution.
        """
        while task_name := self.task_priority_queue.get_next_task():
            # Check if all dependencies are met for the task
            dependencies = self.task_priority_queue.task_dependencies.get(task_name, set())
            if not dependencies:  # No dependencies or all resolved
                agent = self.load_balancer.assign_task(task_name)
                self.thread_pool.submit_task(self.execute_task, agent, task_name)
                self.update_task_status(task_name, 'active', agent.name)
            else:
                print(f"Task '{task_name}' is waiting for dependencies: {dependencies}")
    
    def find_agent_for_task(self, task_name):
        for agent in self.agents.values():
            if agent.can_handle(task_name):
                return agent
        return None
    
    def execute_task(self, agent, task_name):
        try:
            start_time = time.time()
            self.task_monitor.start_task(task_name)
            outcome = agent.execute_task(task_name)
            elapsed_time = self.task_monitor.end_task(task_name)
            self.task_completion_data[task_name] = {
                'status': 'completed',
                'agent': agent.name,
                'duration': elapsed_time,
                'outcome': outcome
            }
            
            # Mark the task as complete and resolve dependencies
            self.task_priority_queue.mark_task_complete(task_name)
            self.update_task_status(task_name, 'completed', agent.name)
            print(f"Task '{task_name}' completed by {agent.name} with outcome: {outcome}")

        except Exception as e:
            print(f"Error in executing task '{task_name}' by {agent.name}: {e}")
            self.record_failure(task_name, agent)
            self.task_priority_queue.update_task_priority(task_name, priority=0)  # Escalate priority on failure

    def handle_agent_feedback(self, task_name, result):
        if result == "success":
            self.task_progress[task_name] = "completed"
        else:
            self.recover_from_failure(task_name)

    def recover_from_failure(self, task):
        if self.task_retries.get(task, 0) < self.retry_limit:
            self.task_retries[task] = self.task_retries.get(task, 0) + 1
            agent = self.find_agent_for_task(task)
            if agent:
                self.execute_task(agent, task)
        else:
            print(f"Task {task} has exceeded the retry limit.")

    def update_task_status(self, task_name, status, agent_name):
        self.task_progress[task_name] = {'status': status, 'agent': agent_name}

    def mark_task_completed(self, task_name, agent):
        if task_name in self.active_tasks:
            del self.active_tasks[task_name]
        self.completed_tasks.append({
            'task': task_name,
            'agent': agent.name,
            'status': 'completed'
        })
        self.update_dashboard()

    def report_progress(self):
        print("\n--- Task Progress Dashboard ---")
        print("Queued Tasks:")
        print("  No queued tasks.")
        print("\nActive Tasks:")
        for task, agent in self.active_tasks.items():
            print(f"  {task} (Agent: {agent.name})")
        print("\nCompleted Tasks:")
        if not self.completed_tasks:
            print("  No completed tasks.")
        else:
            for task in self.completed_tasks:
                print(f"  {task['task']} completed by {task['agent']} with status: {task['status']}")
        print("--- End of Dashboard Report ---")

    def report_overall_progress(self):
        total_tasks = len(self.task_progress)
        completed_tasks = len([task for task in self.task_progress if self.task_progress[task]['status'] == 'completed'])
        success_tasks = len([task for task in self.task_completion_data if self.task_completion_data[task]['outcome'] == 'success'])
        print("\n--- Overall Task Completion Summary ---")
        print(f"Total Tasks: {total_tasks}")
        print(f"Completed Tasks: {completed_tasks}")
        print(f"Successful Tasks: {success_tasks}")
        print(f"Completion Rate: {(completed_tasks / total_tasks) * 100:.2f}%")
        print(f"Success Rate: {(success_tasks / completed_tasks) * 100:.2f}% (for completed tasks)")
        print("\n--- End of Summary ---")

    def retry_task(self, task_name, agent_name):
        retries = self.task_retries.get(task_name, 0)
        if retries < self.retry_limit:
            print(f"Retrying task '{task_name}' (Attempt {retries + 1}/{self.retry_limit})...")
            self.task_retries[task_name] = retries + 1
            self.assign_tasks()
        else:
            print(f"Task '{task_name}' failed after {self.retry_limit} retries.")

    def record_failure(self, task_name, agent):
        self.task_retries[task_name] = self.task_retries.get(task_name, 0)
        if self.task_retries[task_name] < self.retry_limit:
            print(f"Task '{task_name}' failed. Retrying...")
            self.retry_task(task_name, agent.name)
        else:
            print(f"Task '{task_name}' exceeded retry limit. Marked as failed.")



--- File: knowledge_base.py ---

class SharedKnowledgeBase:
    def __init__(self):
        self.data = {}
        self.task_metadata = {}

    def store(self, key, value):
        """
        Stores a key-value pair in the knowledge base.
        """
        self.data[key] = value

    def get(self, key, default=None):
        """
        Retrieves a value from the knowledge base by key.
        Returns the default value if the key is not found.
        """
        return self.data.get(key, default)

    def delete(self, key):
        """
        Deletes a key-value pair from the knowledge base by key.
        """
        if key in self.data:
            del self.data[key]

    def list_contents(self):
        """
        Lists all content currently stored in the knowledge base.
        """
        if not self.data:
            print("Shared knowledge base is empty.")
        else:
            print("Shared Knowledge Base Contents:")
            for key, value in self.data.items():
                print(f"  - {key}: {value}")
        return self.data

    def store_task_metadata(self, task_name, metadata):
        """
        Stores metadata for a specific task. Metadata can include details such as task difficulty,
        execution time, and success rate.
        """
        if task_name not in self.task_metadata:
            self.task_metadata[task_name] = []
        self.task_metadata[task_name].append(metadata)
        print(f"Stored metadata for task '{task_name}': {metadata}")

    def get_task_metadata(self, task_name):
        """
        Retrieves metadata for a specific task. Returns a list of metadata entries.
        """
        return self.task_metadata.get(task_name, [])

    def list_all_task_metadata(self):
        """
        Lists all metadata stored for tasks.
        """
        if not self.task_metadata:
            print("No task metadata stored.")
        else:
            print("Task Metadata Contents:")
            for task_name, metadata_list in self.task_metadata.items():
                print(f"Task '{task_name}':")
                for metadata in metadata_list:
                    print(f"  - {metadata}")
        return self.task_metadata



--- File: test_load_balancer.py ---

# test_load_balancer.py
import unittest
from load_balancer import LoadBalancer
from agents import BaseAgent
class TestLoadBalancer(unittest.TestCase):
    def setUp(self):
        self.mock_agents = [BaseAgent("Agent1", {}), BaseAgent("Agent2", {})]
        self.load_balancer = LoadBalancer(self.mock_agents)
    def test_distribute_task_evenly(self):
        tasks = ["task1", "task2", "task3", "task4"]
        assignments = self.load_balancer.distribute_tasks(tasks)
        self.assertEqual(len(assignments), len(tasks))
    def test_assign_task_to_least_loaded_agent(self):
        task = "new_task"
        agent = self.load_balancer.assign_task(task)
        self.assertIn(agent, self.mock_agents)
    def test_update_agent_load(self):
        self.load_balancer.update_agent_load("Agent1", 5)
        self.assertEqual(self.load_balancer.agent_load["Agent1"], 5)
if __name__ == '__main__':
    unittest.main()



--- File: requirements.txt ---

psutil



--- File: unpackStructure.py ---

import os

# Function to parse the Project_Overview.txt file and extract the structure
def parse_project_overview(file_path):
    project_structure = {}
    current_path = []
    
    with open(file_path, 'r') as file:
        for line in file:
            # Skip empty lines
            if line.strip() == "":
                continue
            
            # Detect file header and extract file name correctly
            if line.startswith("--- File: "):
                # Extract and clean file name, removing extra spaces and dashes
                file_name = line.split("--- File: ")[1].strip().strip("-").strip()
                file_parts = file_name.split("/")
                current_path = file_parts[:-1]
                current_file = file_parts[-1].strip()  # Strip any trailing whitespace
                
                # Traverse into the path and initialize structure
                current_dir = project_structure
                for folder in current_path:
                    current_dir = current_dir.setdefault(folder, {})
                current_dir[current_file] = ""
            
            # Otherwise, it's content of the current file
            else:
                # Append content to the current file
                current_dir[current_file] += line

    return project_structure

# Function to create directories and files based on the parsed structure
def create_project_structure(base_path, structure):
    for name, content in structure.items():
        path = os.path.join(base_path, name.strip())  # Ensure the name is stripped of whitespace
        if isinstance(content, dict):
            # Create directory if it's a dictionary
            os.makedirs(path, exist_ok=True)
            create_project_structure(path, content)
        else:
            # Create and write to file if it's not a dictionary
            os.makedirs(os.path.dirname(path), exist_ok=True)
            with open(path, 'w') as f:
                f.write(content)

# Main function to process the Project_Overview.txt and create the project
def main(project_overview_path, base_path="./project"):
    # Parse the project structure from Project_Overview.txt
    project_structure = parse_project_overview(project_overview_path)
    
    # Create directories and files according to the parsed structure
    create_project_structure(base_path, project_structure)
    
    print(f"Project structure created at '{base_path}' based on '{project_overview_path}'.")

# Example usage
main("Project_Overview.txt", ".")



--- File: agent_health_monitor.py ---

class AgentHealthMonitor:
    """
    Monitors the health and performance of agents.
    """
    def __init__(self, agents, load_balancer):
        self.agent_health = {agent.name: {"tasks_handled": 0, "successes": 0, "failures": 0} for agent in agents}
        self.load_balancer = load_balancer  # Adding load balancer reference to rebalance tasks
    def record_task(self, agent_name, outcome):
        """
        Records the outcome of a task handled by an agent.
        Expects 'outcome' to be either 'success' or 'failure' and updates the agent's health accordingly.
        """
        self.agent_health[agent_name]["tasks_handled"] += 1
        if outcome == "success":
            self.agent_health[agent_name]["successes"] += 1
        elif outcome == "failure":
            self.agent_health[agent_name]["failures"] += 1
        else:
            raise ValueError(f"Unknown task outcome: {outcome}")
        self.display_health(agent_name)    # Displaying health after every record.
        self.monitor_agent_health(agent_name)   # Triggering health monitoring after each task
    def display_health(self, agent_name):
        """
        Displays the current health of an agent.
        """
        health = self.agent_health[agent_name]
        print(f"{agent_name} Health: Tasks Handled: {health['tasks_handled']}, Successes: {health['successes']}, Failures: {health['failures']}")
    def monitor_agent_health(self, agent_name):
        """
        Checks if the agent is failing too often and triggers rebalancing if necessary.
        """
        health = self.agent_health[agent_name]
        if health['failures'] > health['successes']:
            print(f"Warning: {agent_name} is experiencing frequent failures.")
            self.trigger_rebalance(agent_name)   # Automatically rebalance if failure rate exceeds success rate.
    def trigger_rebalance(self, failing_agent_name):
        """
        Automatically reassigns tasks if an agent is failing too often.
        """
        print(f"Reassigning tasks from {failing_agent_name} due to frequent failures.")
        # Rebalance logic: Transfer some tasks away from the failing agent to the least busy agent.
        rebalanced_agent = self.load_balancer.assign_task("Rebalance Task")  
        print(f"Tasks reassigned from {failing_agent_name} to {rebalanced_agent.name}.")
class LoadBalancer:
    """
    Distributes tasks evenly across available agents to avoid bottlenecks.
    """
    def __init__(self, agents):
        self.agents = agents
        self.agent_loads = {agent.name: 0 for agent in agents}
    def assign_task(self, task):
        """
        Assigns the task to the least busy agent.
        """
        least_busy_agent = min(self.agent_loads, key=self.agent_loads.get)
        print(f"Assigning task '{task}' to {least_busy_agent}.")
        return [agent for agent in self.agents if agent.name == least_busy_agent][0]
    def task_completed(self, agent_name):
        """
        Marks a task as completed by the given agent.
        """
        self.agent_loads[agent_name] -= 1
class HealthCheckManager:
    def __init__(self, system_monitor, agent_health_monitor):
        self.system_monitor = system_monitor
        self.agent_health_monitor = agent_health_monitor
    def perform_health_check(self, agent_name):
        cpu_usage, memory_usage = self.system_monitor.monitor_resources()
        self.agent_health_monitor.monitor_agent_health(agent_name)
        if cpu_usage > 85 or memory_usage > 85:
            print(f"System overload detected. Rebalancing tasks.")
            self.agent_health_monitor.trigger_rebalance(agent_name)



--- File: agents.py ---

import os
import subprocess
import sqlite3
import ast
import inspect
import openai
from openai import OpenAI
from system import TeamLeaderAI

client = OpenAI(api_key='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')

class BaseAgent:
    def __init__(self, name, knowledge_base):
        self.name = name
        self.knowledge_base = knowledge_base
        self.memory = {}
        self.success_rate = 0.0  # Track the success rate for self-learning
          # Replace with your actual OpenAI API key

    def can_handle(self, task_name):
        raise NotImplementedError("Subclasses should implement this method.")

    def execute_task(self, task_name):
        raise NotImplementedError("Subclasses should implement this method.")

    def learn(self, task, outcome):
        """
        Records the task outcome and adjusts the agent's success rate.
        """
        if task not in self.memory:
            self.memory[task] = {"successes": 0, "failures": 0}

        # Update memory based on task outcome
        if outcome == "success":
            self.memory[task]["successes"] += 1
        else:
            self.memory[task]["failures"] += 1

        # Calculate success rate
        total_attempts = self.memory[task]["successes"] + self.memory[task]["failures"]
        self.success_rate = self.memory[task]["successes"] / total_attempts

        # Log the learning outcome
        print(f"{self.name} has learned from task '{task}'. Success Rate: {self.success_rate:.2%}")

        # Store the metadata in the knowledge base
        metadata = {
            "task": task,
            "outcome": outcome,
            "success_rate": self.success_rate,
            "total_attempts": total_attempts
        }
        self.knowledge_base.store_task_metadata(task, metadata)

    def query_improvements(self, task_name):
        """
        Queries an AI model for suggestions on how to improve the task handling process.
        """
        prompt = f"{self.name} just completed a task: {task_name}. How can I improve my approach for this type of task?"

        try:
            response = client.chat.completions.create(model="gpt-4",
            messages=[
                {"role": "system", "content": "You are an AI assistant helping to improve task handling processes."},
                {"role": "user", "content": prompt}
            ])
            improvement_suggestions = response.choices[0].message.content.strip()
            print(f"Improvement suggestions for {task_name}: {improvement_suggestions}")
            return improvement_suggestions
        except Exception as e:
            print(f"Error querying AI for improvements: {e}")
            return None
    def adjust_behavior(self, task):
        """
        Adjusts the agent's behavior based on its success rate for the given task.
        """
        # If the success rate is low, try to adjust behavior
        if task in self.memory and self.memory[task]["failures"] > self.memory[task]["successes"]:
            print(f"{self.name} adjusting behavior for task '{task}' due to low success rate.")
            # Example adjustment: change task strategy (e.g., increase resource allocation)
            self.change_strategy(task)

    def change_strategy(self, task):
        """
        Implement a strategy change, such as increasing resource allocation or modifying the task approach.
        This function can be customized per agent's requirements.
        """
        print(f"{self.name} is changing strategy for task '{task}' to improve performance.")

class EnhancedAgent(BaseAgent):
    def learn(self, task, outcome):
        # Enhanced learning method with AI suggestions
        super().learn(task, outcome)

        if outcome == "failure":
            self.adjust_strategy(task)

    def adjust_strategy(self, task):
        print(f"{self.name} is adjusting strategy for task '{task}' due to low success rate.")
        # Fetch suggestions from an AI model for improvement
        feedback = self.query_improvements(task)
        if feedback:
            # Implement suggestions or log them for human review
            print(f"Feedback for {task}: {feedback}")


class ProjectArchitectAI(EnhancedAgent):
    def __init__(self, knowledge_base):
        super().__init__("Project Architect AI", knowledge_base)

    def can_handle(self, task):
        return task == "architecture design"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is creating the project architecture...")

        # Use AI to dynamically generate the project architecture
        project_structure = self.generate_project_structure()

        # Base path for project
        base_path = "./real_project"
        os.makedirs(base_path, exist_ok=True)

        # Create directories and files based on AI suggestions
        self.create_structure(base_path, project_structure)

        print(f"Real-world project structure created by {self.name}.")
        outcome = "success"
        self.learn(task, outcome)
        return outcome

    def generate_project_structure(self):
        """
        Generates a project structure using AI.
        """
        # Prompt AI to design a comprehensive project architecture
        prompt = "Generate a project architecture for a complex {TeamLeaderAI.project_type}, including directories and essential files for code, tests, documentation, configuration, and deployment."

        try:
            response = client.chat.completions.create(model="gpt-4",
            messages=[
                {"role": "system", "content": "You are an AI assistant helping to generate a project architecture for a complex web application, including directories and essential files for code, tests, documentation, configuration, and deployment."},
                {"role": "user", "content": prompt}
            ])
            # Extract structure as a dictionary
            ai_structure = eval(response.choices[0].text.strip())  # Caution: Only use eval with trusted sources
            return ai_structure

        except openai.OpenAIError as e:
            print(f"Error querying OpenAI for project structure: {e}")
            # Default fallback structure if AI call fails
            return {
                "src": {
                    "main.py": "# Main entry point",
                    "utils.py": "# Utility functions",
                    "tests": {
                        "test_main.py": "# Test cases for main"
                    }
                },
                "docs": {
                    "README.md": "# Project documentation"
                },
                "db": {},
                "logs": {},
            }

    def create_structure(self, base_path, structure):
        """
        Recursively creates directories and files based on the provided structure.
        """
        for folder, contents in structure.items():
            folder_path = os.path.join(base_path, folder)
            os.makedirs(folder_path, exist_ok=True)
            for file_name, file_content in contents.items():
                if isinstance(file_content, dict):
                    # Recursively create subdirectories and files
                    self.create_structure(folder_path, {file_name: file_content})
                else:
                    # Create files with content
                    with open(os.path.join(folder_path, file_name), 'w') as f:
                        f.write(file_content)

class CodeGeneratorAI(EnhancedAgent):
    def __init__(self, knowledge_base):
        super().__init__("Code Generator AI", knowledge_base)

    def can_handle(self, task):
        return task == "code generation"

    def execute_task(self, task, project_details=None):
        """
        Executes the code generation task with a dynamic, advanced prompt based on project details.
        
        Args:
            task (str): The task to be performed.
            project_details (dict, optional): Specific details for the project, such as the type of app, features, or required technologies.
        """
        # Ensure project_details has default values if not provided
        if project_details is None:
            project_details = {
                "type": "web app",
                "architecture": "microservices",
                "features": ["authentication", "data processing", "API handling"],
                "technologies": ["Flask", "Redis", "Docker"]
            }

        self.adjust_behavior(task)
        print(f"{self.name} is generating an extremely advanced real-world code...")

        try:
            # Generate advanced code based on detailed project requirements
            code_content = self.generate_advanced_code(project_details)

            # Define the path for the generated code
            base_path = "./real_project/src/"
            os.makedirs(base_path, exist_ok=True)
            file_path = os.path.join(base_path, "main.py")

            # Write the AI-generated code to a file
            with open(file_path, 'w') as f:
                f.write(code_content)

            print(f"Extremely advanced code generation completed for task: {task}")

            # Query for improvement suggestions after completing the task
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except Exception as e:
            print(f"Error during code generation: {e}")
            self.learn(task, "failure")
            return "failure"

    def generate_advanced_code(self, project_details):
        """
        Generates highly advanced, AI-driven code for a real-world application.
        
        Args:
            project_details (dict): Specific requirements or features for the project.
        
        Returns:
            str: Generated code content.
        """
        # Dynamic prompt generation for an extremely advanced implementation
        project_type = project_details.get("type", "distributed web application")
        architecture_style = project_details.get("architecture", "microservices with event-driven communication")
        main_features = project_details.get("features", ["authentication", "real-time data streaming", "state management"])
        technologies = project_details.get("technologies", ["Flask", "Redis", "GraphQL", "Kafka", "Docker"])

        prompt = f"""
Design and implement a sophisticated {TeamLeaderAI.project_type} with an {architecture_style} architecture.
The application should include:
1. {main_features[0]} using JWT and OAuth for secure user authentication.
2. {main_features[1]} leveraging Kafka for data streaming and Redis for caching.
3. {main_features[2]} managed via Redux or a similar state management tool for complex UI interactions.
4. Use advanced programming patterns such as Dependency Injection, Factory Pattern, and Repository Pattern.
5. Implement with {', '.join(technologies)}, and ensure the application is containerized with Docker.
6. Code should follow modular design principles, support scalability, and include error handling, logging, and monitoring.
7. Include comprehensive comments, structured documentation, and necessary tests for all modules.
        """
        try:
            response = client.chat.completions.create(model="gpt-4",
            messages=[
                {"role": "system", "content": "You are an AI assistant helping to generate advanced code for a real-world application."},
                {"role": "user", "content": prompt}
            ])
            advanced_code = response.choices[0].text.strip()
            return advanced_code

        except openai.OpenAIError as e:
            print(f"Error querying OpenAI for advanced code generation: {e}")
            # Provide fallback code if API fails
            return '''
# Fallback advanced API setup with Microservices and Kafka for data streaming

import logging
import os
from flask import Flask, jsonify, request
from kafka import KafkaProducer
import redis
import jwt

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your_secret_key'
producer = KafkaProducer(bootstrap_servers='localhost:9092')
cache = redis.StrictRedis(host='localhost', port=6379, db=0)

# Dependency Injection example
class ServiceInjector:
    def __init__(self, service):
        self._service = service

    def perform_action(self):
        self._service.execute()

@app.route('/data', methods=['POST'])
def send_data():
    data = request.json
    producer.send('data-topic', bytes(str(data), 'utf-8'))
    logging.info("Data sent to Kafka")
    return jsonify({"status": "Data sent successfully"})

@app.route('/cache', methods=['GET'])
def get_cache():
    value = cache.get('key')
    return jsonify({"cached_value": value})

if __name__ == '__main__':
    app.run(debug=True)
            '''

class TestAI(EnhancedAgent):
    def __init__(self, knowledge_base):
        super().__init__("Test AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "testing"

    def execute_task(self, task_name):
        if task_name == "testing":
            return self.run_tests()

    def run_tests(self):
        """
        Attempt to run tests. Logs detailed test output and retries up to 3 times if tests fail.
        """
        test_dir = os.path.join(self.knowledge_base.get("project_path", "./real_project/src"), "tests")
        if not os.path.exists(test_dir):
            print(f"No tests directory found at {test_dir}.")
            return "failure"

        try:
            result = subprocess.run(["pytest", test_dir], capture_output=True, text=True)
            print(result.stdout)

            if result.returncode == 0:
                print("All tests passed successfully.")

                # Query for improvement suggestions after successful testing
                improvement_suggestions = self.query_improvements("testing")

                # Optionally store the suggestions in the knowledge base
                if improvement_suggestions:
                    self.knowledge_base.store("testing_improvements", improvement_suggestions)

                return "success"
            else:
                print("Some tests failed.")
                return "failure"

        except Exception as e:
            print(f"Error while running tests: {str(e)}")
            return "failure"

class DebuggingAI(EnhancedAgent):
    def __init__(self, knowledge_base):
        super().__init__("Debugging AI", knowledge_base)

    def can_handle(self, task):
        return task == "debugging"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Apply any behavior adjustments before debugging
        print(f"{self.name} is performing debugging on the project...")

        try:
            # Debugging logic goes here
            # Example debugging process
            print(f"Debugging task performed by {self.name}.")

            # After debugging, query for improvement suggestions
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except Exception as e:
            print(f"Error during debugging: {e}")
            self.learn(task, "failure")
            return "failure"

class EnhancerAI(EnhancedAgent):
    def __init__(self, knowledge_base):
        super().__init__("Enhancer AI", knowledge_base)

    def can_handle(self, task):
        return task == "enhancement"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Adjust behavior based on prior success/failure rates
        print(f"{self.name} is enhancing the project...")

        try:
            # Enhancement logic goes here
            enhancement_code = '''
def advanced_feature():
    print("Advanced feature implemented.")
'''
            base_path = "./real_project/src/utils.py"
            with open(base_path, 'a') as f:
                f.write(enhancement_code)

            print(f"Enhancement added to utils.py by {self.name}.")

            # Query for improvement suggestions after enhancement
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except Exception as e:
            print(f"Error during enhancement: {e}")
            self.learn(task, "failure")
            return "failure"

class DocumentationAI(EnhancedAgent):
    def __init__(self, knowledge_base):
        super().__init__("Documentation AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "documentation"

    def execute_task(self, task_name):
        if task_name == "documentation":
            return self.generate_detailed_documentation()

    def generate_detailed_documentation(self):
        """
        Generates detailed documentation including:
        1. API Documentation (function signatures)
        2. Code Annotations (detailed explanations of code blocks)
        3. Workflow Diagrams (general flow of the project components)
        """
        print(f"{self.name} is generating detailed documentation...")

        # Step 1: Generate API Documentation
        self.generate_api_docs()

        # Step 2: Generate Code Annotations
        self.generate_code_annotations()

        # Step 3: Generate Workflow Diagrams (Simplified as textual representation for now)
        self.generate_workflow_diagrams()

        # Query for improvement suggestions after generating documentation
        improvement_suggestions = self.query_improvements("documentation")

        # Optionally store the suggestions in the knowledge base
        if improvement_suggestions:
            self.knowledge_base.store("documentation_improvements", improvement_suggestions)

        self.learn("documentation", "success")
        return "success"

    def generate_api_docs(self):
        """
        Generate API documentation for all Python files by extracting function definitions and signatures.
        """
        print("Generating API documentation...")
        for module_name, module_ref in self.knowledge_base.get("modules", {}).items():
            print(f"\nModule: {module_name}")
            functions = inspect.getmembers(module_ref, inspect.isfunction)
            for function_name, function_ref in functions:
                signature = inspect.signature(function_ref)
                print(f"  Function: {function_name}{signature}")

    def generate_code_annotations(self):
        """
        Generate code annotations by analyzing the AST (Abstract Syntax Tree) and adding comments where appropriate.
        """
        print("Generating code annotations using AST...")
        for module_name, module_ref in self.knowledge_base.get("modules", {}).items():
            source_code = inspect.getsource(module_ref)
            root = ast.parse(source_code)
            print(f"\nAnnotations for {module_name}:")
            for node in ast.walk(root):
                if isinstance(node, ast.FunctionDef):
                    print(f"  Function {node.name} is defined at line {node.lineno}.")
                elif isinstance(node, ast.ClassDef):
                    print(f"  Class {node.name} found at line {node.lineno}.")

    def generate_workflow_diagrams(self):
        """
        Generate a simplified diagram of workflow/processes in the system.
        """
        print("Generating workflow diagram...\n")
        workflow = """
        [Team Leader AI] --> Assign Tasks
        [Load Balancer] --> Distribute Tasks to Agents
        [Agents] --> Perform Tasks (e.g., Code Generation, Testing, Debugging)
        [Documentation AI] --> Generate Reports on Project State
        """
        print(workflow)

class DeploymentAI(EnhancedAgent):
    def __init__(self, knowledge_base):
        super().__init__("Deployment AI", knowledge_base)

    def can_handle(self, task):
        return task == "deployment"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Adjust behavior based on previous task outcomes
        print(f"{self.name} is deploying the project...")

        try:
            # Deployment logic goes here
            dockerfile_content = '''
FROM python:3.9-slim
WORKDIR /app
COPY . /app
RUN pip install -r requirements.txt
CMD ["python", "main.py"]
'''
            with open("./real_project/Dockerfile", 'w') as f:
                f.write(dockerfile_content)

            print(f"Dockerfile created by {self.name}.")

            # Query for improvement suggestions after deployment
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except Exception as e:
            print(f"Error during deployment: {e}")
            self.learn(task, "failure")
            return "failure"

class SecurityAI(EnhancedAgent):
    def __init__(self, knowledge_base):
        super().__init__("Security AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "security audit"

    def execute_task(self, task_name):
        if task_name == "security audit":
            return self.perform_security_audit()

    def perform_security_audit(self):
        """
        Perform a security audit, detect vulnerabilities, and attempt to fix them.
        """
        print("Security AI is performing a security audit...")

        # Example vulnerabilities
        vulnerabilities = ["Insecure default configuration", "Weak encryption algorithm"]
        print("Vulnerabilities detected:\n" + "\n".join(vulnerabilities))

        try:
            # Fix detected vulnerabilities
            self.fix_vulnerabilities(vulnerabilities)

            # Query for improvement suggestions after the security audit
            improvement_suggestions = self.query_improvements("security audit")

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store("security_audit_improvements", improvement_suggestions)

            return "success"
        except Exception as e:
            print(f"Failed to fix vulnerabilities: {str(e)}")
            return "failure"

    def fix_vulnerabilities(self, vulnerabilities):
        """
        Fixes known vulnerabilities. For example, updates configurations and replaces weak algorithms.
        """
        for vulnerability in vulnerabilities:
            if "Insecure default configuration" in vulnerability:
                config_file = os.path.join(self.knowledge_base.get("project_path", "./real_project"), "config.yml")
                if os.path.exists(config_file):
                    with open(config_file, 'a') as f:
                        f.write("secure: true\n")
                    print("Insecure default configuration fixed.")
            elif "Weak encryption algorithm" in vulnerability:
                code_file = os.path.join(self.knowledge_base.get("project_path", "./real_project/src"), "encryption.py")
                if os.path.exists(code_file):
                    with open(code_file, 'r') as f:
                        content = f.read()
                    updated_content = content.replace("AES256", "AES512")
                    with open(code_file, 'w') as f:
                        f.write(updated_content)
                    print("Weak encryption algorithm fixed.")

class DatabaseAI(EnhancedAgent):
    def __init__(self, knowledge_base):
        super().__init__("Database AI", knowledge_base)

    def can_handle(self, task):
        return task == "database setup"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Adjust behavior based on previous task outcomes
        print(f"{self.name} is setting up the database...")

        try:
            # Database setup logic goes here
            db_path = "./real_project/db/project.db"
            os.makedirs(os.path.dirname(db_path), exist_ok=True)

            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY,
                username TEXT NOT NULL,
                email TEXT NOT NULL UNIQUE
            )
            ''')
            conn.commit()
            conn.close()

            print(f"Database created by {self.name}.")

            # Query for improvement suggestions after database setup
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except sqlite3.Error as e:
            print(f"Database setup failed: {e}")
            self.learn(task, "failure")
            return "failure"

class LoggingAI(EnhancedAgent):
    def __init__(self, knowledge_base):
        super().__init__("Logging AI", knowledge_base)

    def can_handle(self, task):
        return task == "logging setup"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Adjust behavior based on past task outcomes
        print(f"{self.name} is setting up logging for the project...")

        try:
            # Logging setup logic goes here
            logging_config = '''
import logging
logging.basicConfig(filename='./real_project/logs/app.log', level=logging.INFO,
                    format='%(asctime)s %(levelname)s: %(message)s')
logging.info("Logging is set up.")
'''
            log_file_path = "./real_project/src/logging_setup.py"
            os.makedirs(os.path.dirname(log_file_path), exist_ok=True)
            with open(log_file_path, 'w') as f:
                f.write(logging_config)

            print(f"Logging setup complete by {self.name}.")

            # Query for improvement suggestions after setting up logging
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except Exception as e:
            print(f"Error during logging setup: {e}")
            self.learn(task, "failure")
            return "failure"

class VersionControlAI(EnhancedAgent):
    def __init__(self, knowledge_base):
        super().__init__("Version Control AI", knowledge_base)

    def can_handle(self, task):
        return task == "version control setup"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Adjust behavior based on past task outcomes
        print(f"{self.name} is setting up version control for the project...")

        try:
            # Initialize a new Git repository
            repo_path = self.knowledge_base.get("project_path", "./real_project")
            os.makedirs(repo_path, exist_ok=True)
            subprocess.run(["git", "init", repo_path], check=True)

            # Create a .gitignore file
            gitignore_content = '''
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
*.egg-info/
.installed.cfg
*.egg
*.log

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# Pyre type checker
.pyre/
'''
            with open(os.path.join(repo_path, ".gitignore"), 'w') as f:
                f.write(gitignore_content)

            print(f"Git repository initialized and .gitignore file created by {self.name}.")

            # Query for improvement suggestions after setting up version control
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except subprocess.CalledProcessError as e:
            print(f"Failed to initialize Git repository: {e}")
            self.learn(task, "failure")
            return "failure"

class FrontendGeneratorAI(EnhancedAgent):
    def __init__(self, knowledge_base):
        super().__init__("Frontend Generator AI", knowledge_base)

    def can_handle(self, task):
        return task == "frontend generation"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Adjust behavior based on past task outcomes
        print(f"{self.name} is generating the frontend for the project...")

        try:
            # Frontend generation logic goes here
            project_path = self.knowledge_base.get("project_path", "./real_project/frontend")
            os.makedirs(project_path, exist_ok=True)

            # Example HTML and CSS files
            index_html = '''
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Frontend</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Welcome to the Project Frontend</h1>
    <p>This is a sample frontend generated by Frontend Generator AI.</p>
</body>
</html>
'''
            styles_css = '''
body {
    font-family: Arial, sans-serif;
    background-color: #f4f4f4;
    color: #333;
    text-align: center;
    margin: 0;
    padding: 0;
}
h1 {
    color: #555;
}
'''

            # Write files to the project directory
            with open(os.path.join(project_path, "index.html"), 'w') as f:
                f.write(index_html)
            with open(os.path.join(project_path, "styles.css"), 'w') as f:
                f.write(styles_css)

            print(f"Frontend generated successfully by {self.name}.")

            # Query for improvement suggestions after generating the frontend
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except Exception as e:
            print(f"Error during frontend generation: {e}")
            self.learn(task, "failure")
            return "failure"



--- File: test_health_check_manager.py ---

# test_health_check_manager.py
import unittest
from health_check_manager import HealthCheckManager
from agents import BaseAgent
class TestHealthCheckManager(unittest.TestCase):
    def setUp(self):
        self.mock_agents = [BaseAgent("Agent1", {}), BaseAgent("Agent2", {})]
        self.health_check_manager = HealthCheckManager(self.mock_agents)
    def test_health_check(self):
        results = self.health_check_manager.check_health()
        self.assertIsInstance(results, dict)
        self.assertIn("Agent1", results)
        self.assertIn("Agent2", results)
    def test_health_status(self):
        for agent in self.mock_agents:
            status = self.health_check_manager.get_health_status(agent.name)
            self.assertIn(status, ["healthy", "unhealthy"])
    def test_recover_unhealthy_agents(self):
        # Assuming there is logic to mark an agent as unhealthy
        unhealthy_agents = self.health_check_manager.recover_unhealthy_agents()
        self.assertIsInstance(unhealthy_agents, list)
if __name__ == '__main__':
    unittest.main()



--- File: Dockerfile ---

FROM python:3.9-slim
WORKDIR /usr/src/app
COPY . .
RUN pip install --no-cache-dir -r requirements.txt
CMD ["python", "main.py"]



--- File: test_knowledge_base.py ---

# test_knowledge_base.py
import unittest
from knowledge_base import SharedKnowledgeBase
class TestSharedKnowledgeBase(unittest.TestCase):
    def setUp(self):
        self.knowledge_base = SharedKnowledgeBase()
    def test_store_and_retrieve_knowledge(self):
        self.knowledge_base.store("test_key", "test_value")
        retrieved_value = self.knowledge_base.retrieve("test_key")
        self.assertEqual(retrieved_value, "test_value")
    def test_retrieve_non_existent_key(self):
        result = self.knowledge_base.retrieve("non_existent_key")
        self.assertIsNone(result)
    def test_remove_knowledge(self):
        self.knowledge_base.store("temp_key", "temp_value")
        self.knowledge_base.remove("temp_key")
        result = self.knowledge_base.retrieve("temp_key")
        self.assertIsNone(result)
if __name__ == '__main__':
    unittest.main()



--- File: test_main.py ---

# test_main.py
import unittest
from unittest.mock import patch
import main
class TestMain(unittest.TestCase):
    @patch('main.TeamLeaderAI')
    def test_main_flow_create_project(self, MockTeamLeaderAI):
        mock_team_leader = MockTeamLeaderAI.return_value
        mock_team_leader.create_project.return_value = "Project created successfully"
        with patch('builtins.input', side_effect=["1", "web app"]):
            result = main.run_program()
            self.assertEqual(result, "Project created successfully")
            mock_team_leader.create_project.assert_called_once()
    @patch('main.TeamLeaderAI')
    def test_main_flow_debug_project(self, MockTeamLeaderAI):
        mock_team_leader = MockTeamLeaderAI.return_value
        mock_team_leader.debug_project.return_value = "Debugging completed"
        with patch('builtins.input', side_effect=["3"]):
            result = main.run_program()
            self.assertEqual(result, "Debugging completed")
            mock_team_leader.debug_project.assert_called_once()
    # Add additional tests for other options (Enhance, Add Features, Test)
if __name__ == '__main__':
    unittest.main()



--- File: task_priority_queue.py ---

import heapq
class TaskPriorityQueue:
    def __init__(self, system_monitor):
        self.queue = []
        self.system_monitor = system_monitor  # Allow access to system resource data
        self.tasks = []  # This will hold our priority queue (min-heap)
        self.task_dependencies = {}  # Track task dependencies

    def add_task(self, priority, task_name, priority_level, dependencies=[]):
        """
        Adds a task to the priority queue with the given priority and optional dependencies.
        
        Args:
            priority (int): The priority of the task (lower number = higher priority).
            task_name (str): The name of the task to add.
            priority_level (str): Task priority level, like 'high', 'medium', or 'low'.
            dependencies (list): List of task names that must be completed before this task starts.
        """
        heapq.heappush(self.tasks, (priority, task_name, priority_level))
        if dependencies:
            self.task_dependencies[task_name] = set(dependencies)
        print(f"Task '{task_name}' added with priority {priority} and dependencies: {dependencies}")

    def get_next_task(self):
        """
        Retrieves the next available task based on priority and dependencies.
        """
        for i, (priority, task_name, priority_level) in enumerate(self.tasks):
            if task_name not in self.task_dependencies:
                return heapq.heappop(self.tasks)[1]  # Return task name without dependencies

            # Check if dependencies are completed
            if all(dep not in self.task_dependencies for dep in self.task_dependencies[task_name]):
                # Remove dependencies and task from queue
                del self.task_dependencies[task_name]
                return heapq.heappop(self.tasks)[1]

        print("No tasks available due to unresolved dependencies.")
        return None
    
    def display_pending_tasks(self):
        """
        Display tasks currently pending in the queue, sorted by priority.
        """
        if not self.queue:
            print("No pending tasks.")
            return
        print("Pending tasks:")
        for priority, task_name, resource_intensity in sorted(self.queue):
            print(f"Priority {priority}: Task '{task_name}' (Resource Intensity: {resource_intensity})")

    def update_task_priority(self, task_name, new_priority):
        """
        Updates the priority of a specific task.
        """
        # Find and remove the task to update its priority
        for i, (priority, name, level) in enumerate(self.tasks):
            if name == task_name:
                self.tasks.pop(i)
                heapq.heapify(self.tasks)  # Rebalance the heap
                self.add_task(new_priority, task_name, level)
                print(f"Updated priority for task '{task_name}' to {new_priority}.")
                return
        print(f"Task '{task_name}' not found in the queue.")

    def mark_task_complete(self, task_name):
        """
        Removes a completed task from the dependencies of other tasks.
        """
        for task, dependencies in self.task_dependencies.items():
            if task_name in dependencies:
                dependencies.remove(task_name)
                print(f"Task '{task_name}' dependency removed from '{task}'.")
        # Remove the task if it's no longer a dependency
        if task_name in self.task_dependencies:
            del self.task_dependencies[task_name]
        print(f"Marked task '{task_name}' as complete and resolved dependencies.")



--- File: createOverview.py ---

import os
def combine_files_in_directory(directory, output_file):
    with open(output_file, 'w') as outfile:
        # Traverse the directory recursively
        for root, dirs, files in os.walk(directory):
            # Ignore directories that start with '__' or are hidden (dot directories)
            dirs[:] = [d for d in dirs if not d.startswith('__') and not d.startswith('.') and not d.startswith('real')]
            for file in files:
                # Ignore dot files (hidden files)
                if file.startswith('.'):
                    continue
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, directory)
                try:
                    with open(file_path, 'r') as infile:
                        # Write the relative file path as a header
                        outfile.write(f"\n\n--- File: {relative_path} ---\n\n")
                        outfile.write(infile.read())
                        outfile.write("\n")  # Add a newline after file content
                except Exception as e:
                    print(f"Could not read {file_path}: {e}")
if __name__ == "__main__":
    directory = input("Enter the directory to combine files from: ")
    output_file = "Project_Overview.txt"
    combine_files_in_directory(directory, output_file)
    print(f"All files have been combined into {output_file}.")



--- File: load_balancer.py ---

from sklearn.tree import DecisionTreeRegressor
import numpy as np
import psutil
from knowledge_base import SharedKnowledgeBase
import knowledge_base

class LoadBalancer:
    def __init__(self, agents, knowledge_base):
        self.agents = agents
        self.knowledge_base = knowledge_base
        self.agent_loads = {agent.name: 0 for agent in agents}
        self.agent_expertises = {
            "architecture design": "Project Architect AI",
            "code generation": "Code Generator AI",
            "debugging": "Debugging AI",
            "testing": "Test AI",
            "enhancement": "Enhancer AI",
            "documentation": "Documentation AI",
            "deployment": "Deployment AI",
            "security audit": "Security AI",
            "database setup": "Database AI",
            "logging setup": "Logging AI",
            "version control": "Version Control AI",
            "frontend generation": "Frontend Generator AI"
        }

    def assign_task(self, task_name):
        """
        Assigns a task to the least busy or most specialized agent.
        
        Args:
            task_name (str): The name of the task to assign.
        
        Returns:
            The selected agent for the task.
        """
        expert_agent_name = self.agent_expertises.get(task_name)
        if expert_agent_name:
            least_busy_agent = min(self.agent_loads, key=self.agent_loads.get)
            assigned_agent = next((agent for agent in self.agents if agent.name == expert_agent_name), None)
            if assigned_agent:
                print(f"Assigned {task_name} to specialized agent: {assigned_agent.name}")
            else:
                assigned_agent = next(agent for agent in self.agents if agent.name == least_busy_agent)
                print(f"Assigned {task_name} to least busy agent: {assigned_agent.name}")
        else:
            assigned_agent = next(agent for agent in self.agents if agent.name == min(self.agent_loads, key=self.agent_loads.get))
            print(f"Assigned {task_name} to least busy agent: {assigned_agent.name}")
        
        self.agent_loads[assigned_agent.name] += 1
        return assigned_agent

    def estimate_task_duration(self, task_name):
        """
        Estimates the duration of a task based on past task completion times.
        
        Args:
            task_name (str): The name of the task to estimate.
        
        Returns:
            float: The estimated duration in seconds, or None if there is no data.
        """
        task_metadata = self.knowledge_base.get_task_metadata(task_name)
        
        if task_metadata:
            total_time = sum(entry['duration'] for entry in task_metadata)
            average_duration = total_time / len(task_metadata)
            print(f"Estimated duration for task '{task_name}': {average_duration:.2f} seconds.")
            return average_duration
        else:
            print(f"No historical data available to estimate duration for task '{task_name}'.")
            return None

    def task_completed(self, agent_name):
        """
        Marks a task as completed for an agent, reducing their current load.
        
        Args:
            agent_name (str): The name of the agent who completed a task.
        """
        if agent_name in self.agent_loads:
            self.agent_loads[agent_name] = max(0, self.agent_loads[agent_name] - 1)
            print(f"Marked task completed for agent: {agent_name}")

# Example agents list to simulate load balancer functioning:
"""
agents = {
    "Project Architect AI": ProjectArchitectAI(knowledge_base),
    "Code Generator AI": CodeGeneratorAI(knowledge_base),
    "Debugging AI": DebuggingAI(knowledge_base),
    "Test AI": TestAI(knowledge_base),
    "Enhancer AI": EnhancerAI(knowledge_base),
    "Documentation AI": DocumentationAI(knowledge_base),
    "Deployment AI": DeploymentAI(knowledge_base),
    "Security AI": SecurityAI(knowledge_base),
    "Database AI": DatabaseAI(knowledge_base),
    "Logging AI": LoggingAI(knowledge_base),
    "Version Control AI": VersionControlAI(knowledge_base),
    "Frontend Generator AI": FrontendGeneratorAI(knowledge_base)
}
"""

class AILoadBalancer(LoadBalancer):
    def __init__(self, agents, knowledge_base):
        super().__init__(agents)
        self.data_log = []  # Collect data for training
        self.model = DecisionTreeRegressor()  # Initialize a simple predictive model        
        knowledge_base_instance = SharedKnowledgeBase()

    def monitor_resource_usage(self):
        # Use psutil to get system resource usage
        cpu_usage = psutil.cpu_percent(interval=1)
        memory_usage = psutil.virtual_memory().percent
        disk_usage = psutil.disk_usage('/').percent
        net_io = psutil.net_io_counters()
        network_outgoing = net_io.bytes_sent / 1024 / 1024  # Convert to MB
        return cpu_usage, memory_usage, disk_usage, network_outgoing
    
    def collect_data(self, task_name, agent_name, cpu_usage, memory_usage, task_duration, success):
        # Log data points for training
        self.data_log.append([cpu_usage, memory_usage, task_duration, int(success)])
        # Keep log size manageable
        if len(self.data_log) > 1000:
            self.data_log.pop(0)

    def train_model(self):
        # Train model with collected data if there are enough samples
        if len(self.data_log) >= 50:
            X = np.array(self.data_log)[:, :3]  # cpu, memory, task duration
            y = np.array(self.data_log)[:, 3]  # success rate
            self.model.fit(X, y)

    def estimate_task_duration(self, task_name):
        """
        Estimates the duration of a task based on past task completion times.

        Args:
            task_name (str): The name of the task to estimate. This parameter is a string representing the name of the task.

        Returns:
            float: The estimated duration in seconds, or None if there is no data. The function returns a float value representing the estimated duration of the task in seconds. If no historical data is available, it returns None.
        """
        # Retrieve task metadata from the knowledge base
        task_metadata = self.knowledge_base.get_task_metadata(task_name)

        # Calculate average duration if metadata is available
        if task_metadata:
            total_time = sum(entry['duration'] for entry in task_metadata)
            average_duration = total_time / len(task_metadata)
            print(f"Estimated duration for task '{task_name}': {average_duration:.2f} seconds.")
            return average_duration
        else:
            print(f"No historical data available to estimate duration for task '{task_name}'.")
            return None

    def assign_task(self, task):
        # Monitor system and predict optimal assignment
        cpu_usage, memory_usage, _, _ = self.monitor_resource_usage()
        task_duration = self.estimate_task_duration(task)  # Placeholder function
        self.train_model()
        
        prediction = self.model.predict([[cpu_usage, memory_usage, task_duration]])
        optimal_agent_name = self.find_optimal_agent(prediction)  # Placeholder for finding agent based on model
        
        # Use prediction to assign task
        if optimal_agent_name:
            assigned_agent = next(agent for agent in self.agents if agent.name == optimal_agent_name)
            print(f"AI LoadBalancer assigned task '{task}' to agent '{optimal_agent_name}'")
            return assigned_agent
        else:
            return super().assign_task(task)  # Fallback to standard method if no optimal agent is found




--- File: health_check_manager.py ---

class HealthCheckManager:
    def __init__(self, system_monitor, agent_health_monitor):
        self.system_monitor = system_monitor
        self.agent_health_monitor = agent_health_monitor
    def perform_health_check(self, agent_name):
        cpu_usage, memory_usage = self.system_monitor.monitor_resources()
        self.agent_health_monitor.monitor_agent_health(agent_name)
        if cpu_usage > 85 or memory_usage > 85:
            print(f"System overload detected. Rebalancing tasks.")



--- File: test_agent_health_monitor.py ---

# test_agent_health_monitor.py
import unittest
from agent_health_monitor import AgentHealthMonitor, LoadBalancer
from agents import BaseAgent
class TestAgentHealthMonitor(unittest.TestCase):
    def setUp(self):
        self.mock_agents = [BaseAgent("TestAgent", {})]
        self.load_balancer = LoadBalancer(self.mock_agents)
        self.agent_health_monitor = AgentHealthMonitor(self.mock_agents, self.load_balancer)
    def test_record_task_success(self):
        self.agent_health_monitor.record_task("TestAgent", "success")
        health = self.agent_health_monitor.agent_health["TestAgent"]
        self.assertEqual(health["successes"], 1)
    def test_record_task_failure(self):
        self.agent_health_monitor.record_task("TestAgent", "failure")
        health = self.agent_health_monitor.agent_health["TestAgent"]
        self.assertEqual(health["failures"], 1)
    def test_trigger_rebalance_on_failure(self):
        self.agent_health_monitor.record_task("TestAgent", "failure")
        self.agent_health_monitor.record_task("TestAgent", "failure")
        self.agent_health_monitor.record_task("TestAgent", "failure")
        # Test rebalance logic as needed
        # Add mock or print statements to confirm behavior
if __name__ == '__main__':
    unittest.main()



--- File: test_task_monitor.py ---

# test_task_monitor.py
import unittest
from task_monitor import TaskMonitor
from agents import BaseAgent
class TestTaskMonitor(unittest.TestCase):
    def setUp(self):
        self.agent = BaseAgent("TestAgent", {})
        self.task_monitor = TaskMonitor(self.agent)
    def test_start_task(self):
        task_name = "sample_task"
        self.task_monitor.start_task(task_name)
        self.assertEqual(self.task_monitor.current_task, task_name)
    def test_complete_task(self):
        task_name = "sample_task"
        self.task_monitor.start_task(task_name)
        self.task_monitor.complete_task("success")
        self.assertIsNone(self.task_monitor.current_task)
        self.assertIn("success", self.task_monitor.task_history)
    def test_task_failure(self):
        task_name = "sample_task"
        self.task_monitor.start_task(task_name)
        self.task_monitor.complete_task("failure")
        self.assertIn("failure", self.task_monitor.task_history)
if __name__ == '__main__':
    unittest.main()



--- File: test_dynamic_thread_pool.py ---

# test_dynamic_thread_pool.py
import unittest
from dynamic_thread_pool import DynamicThreadPoolExecutor
import time
class TestDynamicThreadPoolExecutor(unittest.TestCase):
    def setUp(self):
        self.pool = DynamicThreadPoolExecutor(max_workers=3)
    def tearDown(self):
        self.pool.shutdown()
    def test_submit_task(self):
        def sample_task(x):
            return x * 2
        future = self.pool.submit(sample_task, 5)
        result = future.result()
        self.assertEqual(result, 10)
    def test_adjust_worker_count(self):
        initial_count = self.pool._max_workers
        self.pool.adjust_worker_count(5)
        self.assertEqual(self.pool._max_workers, 5)
    def test_task_execution_with_delay(self):
        def delayed_task():
            time.sleep(1)
            return "completed"
        future = self.pool.submit(delayed_task)
        result = future.result()
        self.assertEqual(result, "completed")
if __name__ == '__main__':
    unittest.main()



--- File: test_system.py ---

# test_system.py
import unittest
from system import System
class TestSystem(unittest.TestCase):
    def setUp(self):
        self.system = System()
    def test_get_cpu_usage(self):
        cpu_usage = self.system.get_cpu_usage()
        self.assertIsInstance(cpu_usage, float)
        self.assertGreaterEqual(cpu_usage, 0.0)
    def test_get_memory_usage(self):
        memory_usage = self.system.get_memory_usage()
        self.assertIsInstance(memory_usage, float)
        self.assertGreaterEqual(memory_usage, 0.0)
    def test_get_disk_usage(self):
        disk_usage = self.system.get_disk_usage()
        self.assertIsInstance(disk_usage, float)
        self.assertGreaterEqual(disk_usage, 0.0)
    def test_get_network_usage(self):
        network_usage = self.system.get_network_usage()
        self.assertIsInstance(network_usage, float)
        self.assertGreaterEqual(network_usage, 0.0)
if __name__ == '__main__':
    unittest.main()



--- File: task_monitor.py ---

import time
class TaskMonitor:
    def __init__(self):
        self.task_times = {}
        self.task_history = {}  # New dictionary to track task completion times
    def start_task(self, task_name):
        """
        Starts tracking the task's start time.
        """
        self.task_times[task_name] = time.time()
        print(f"Started task '{task_name}' at {self.task_times[task_name]}")
    def end_task(self, task_name):
        """
        Stops tracking the task's time and records the duration for analytics.
        """
        if task_name in self.task_times:
            elapsed_time = time.time() - self.task_times[task_name]
            print(f"Task '{task_name}' completed in {elapsed_time:.2f} seconds.")
            # Store the elapsed time in task history for tracking multiple runs
            if task_name not in self.task_history:
                self.task_history[task_name] = []
            self.task_history[task_name].append(elapsed_time)
            del self.task_times[task_name]
            return elapsed_time
        return None
    def get_average_time(self, task_name):
        """
        Calculates the average completion time for a given task, based on historical data.
        """
        if task_name in self.task_history and self.task_history[task_name]:
            avg_time = sum(self.task_history[task_name]) / len(self.task_history[task_name])
            print(f"Average time for task '{task_name}': {avg_time:.2f} seconds.")
            return avg_time
        else:
            print(f"No historical data for task '{task_name}'.")
            return None
    def display_task_statistics(self):
        """
        Displays a summary of task performance statistics, including average and total run times.
        """
        if self.task_history:
            print("\nTask Performance Summary:")
            for task_name, times in self.task_history.items():
                total_runs = len(times)
                total_time = sum(times)
                average_time = total_time / total_runs if total_runs > 0 else 0
                print(f"Task: {task_name}, Total Runs: {total_runs}, Average Time: {average_time:.2f} seconds, Total Time: {total_time:.2f} seconds.")
        else:
            print("No tasks have been completed yet to show statistics.")



--- File: test_agents.py ---

# test_agents.py
import unittest
from agents import ProjectArchitectAI, CodeGeneratorAI, TestAI, DebuggingAI, EnhancerAI, DocumentationAI, DeploymentAI, SecurityAI, DatabaseAI, LoggingAI, VersionControlAI, FrontendGeneratorAI
from knowledge_base import SharedKnowledgeBase
class TestAgents(unittest.TestCase):
    def setUp(self):
        self.knowledge_base = SharedKnowledgeBase()
        self.agents = [
            ProjectArchitectAI(self.knowledge_base),
            CodeGeneratorAI(self.knowledge_base),
            TestAI(self.knowledge_base),
            DebuggingAI(self.knowledge_base),
            EnhancerAI(self.knowledge_base),
            DocumentationAI(self.knowledge_base),
            DeploymentAI(self.knowledge_base),
            SecurityAI(self.knowledge_base),
            DatabaseAI(self.knowledge_base),
            LoggingAI(self.knowledge_base),
            VersionControlAI(self.knowledge_base),
            FrontendGeneratorAI(self.knowledge_base)
        ]
    def test_agents_can_handle(self):
        for agent in self.agents:
            self.assertTrue(hasattr(agent, 'can_handle'))
    def test_agents_execute_task(self):
        for agent in self.agents:
            with self.assertRaises(NotImplementedError):
                agent.execute_task('any_task')
    # Add additional tests specific to each agent type
if __name__ == '__main__':
    unittest.main()



--- File: system_monitor.py ---

import psutil
class SystemMonitor:
    def __init__(self):
        self.alert_thresholds = {
            'cpu': 85,  # Alert if CPU usage exceeds 85%
            'memory': 85,  # Alert if memory usage exceeds 85%
            'disk': 80,  # Alert if disk usage exceeds 80%
            'network_sent': 75,  # Alert if network outgoing exceeds 75% of bandwidth (mock)
        }
    def monitor_resources(self):
        """
        Monitors the system's resource usage.
        """
        cpu_usage = psutil.cpu_percent(interval=1)
        memory_usage = psutil.virtual_memory().percent
        disk_usage = psutil.disk_usage('/').percent
        network_usage_sent = self.get_network_sent_usage()
        print(f"CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage}%, Disk Usage: {disk_usage}%, Network Outgoing: {network_usage_sent}%")
        # Trigger alerts if any usage exceeds pre-defined thresholds
        self.check_alerts(cpu_usage, memory_usage, disk_usage, network_usage_sent)
        return cpu_usage, memory_usage, disk_usage, network_usage_sent
    def check_alerts(self, cpu_usage, memory_usage, disk_usage, network_usage_sent):
        """
        Checks system metrics against pre-defined threshold limits and issues alerts if exceeded.
        """
        if cpu_usage > self.alert_thresholds['cpu']:
            print(f"ALERT: CPU Usage exceeds {self.alert_thresholds['cpu']}% (Current: {cpu_usage}%)")
        if memory_usage > self.alert_thresholds['memory']:
            print(f"ALERT: Memory Usage exceeds {self.alert_thresholds['memory']}% (Current: {memory_usage}%)")
        if disk_usage > self.alert_thresholds['disk']:
            print(f"ALERT: Disk Usage exceeds {self.alert_thresholds['disk']}% (Current: {disk_usage}%)")
        if network_usage_sent > self.alert_thresholds['network_sent']:
            print(f"ALERT: Network Outgoing exceeds {self.alert_thresholds['network_sent']}% (Current: {network_usage_sent}%)")
    def get_network_sent_usage(self):
        """
        Simulate network usage monitoring. You could modify this part to reflect real network usage.
        """
        net_io = psutil.net_io_counters()
        sent = net_io.bytes_sent / (1024 * 1024)  # Convert the sent bytes to megabytes
        # For now, we'll return a mock "percentage", just scale bytes sent arbitrarily
        return min(100, (sent / 5) * 10)  # This is a mock calculation assuming 5MB threshold.
    def trigger_alert(self, alert_message):
        """
        Optional: Hook this up with a notification/alerting system (e.g., email, logging, etc.).
        """
        # Notifies via print for now; can change as needed (e.g., hook with logging service).
        print(f"Triggering Alert: {alert_message}")



--- File: dynamic_thread_pool.py ---

import psutil
from concurrent.futures import ThreadPoolExecutor
class DynamicThreadPoolExecutor:
    def __init__(self, max_workers):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
    def adjust_workers(self, cpu_usage, memory_usage, io_usage, network_usage):
        """
        Adjust worker count based on system's resource usage, including disk I/O and network bandwidth.
        """
        # Reduce the number of workers if CPU, memory, disk I/O, or network usage is too high
        if cpu_usage > 80 or memory_usage > 80 or io_usage > 80 or network_usage > 75:
            new_worker_count = max(1, self.max_workers // 2)  # Reduce workers to alleviate load
            self.executor = ThreadPoolExecutor(max_workers=new_worker_count)
            print(f"Reducing worker count to {new_worker_count} due to high resource usage: CPU({cpu_usage}%), Memory({memory_usage}%), IO({io_usage}%), Network({network_usage}%)")
        # Increase workers if the system is underutilized
        elif cpu_usage < 40 and memory_usage < 40 and io_usage < 40 and network_usage < 30:
            new_worker_count = min(self.max_workers * 2, 10)  # Increase workers to better utilize capacity
            self.executor = ThreadPoolExecutor(max_workers=new_worker_count)
            print(f"Increasing worker count to {new_worker_count} due to low resource usage: CPU({cpu_usage}%), Memory({memory_usage}%), IO({io_usage}%), Network({network_usage}%)")
    def monitor_resource_usage(self):
        """
        Fetch system resource usage: CPU, memory, disk I/O, and network IO.
        """
        cpu_usage = psutil.cpu_percent(interval=1)
        memory_usage = psutil.virtual_memory().percent
        io_usage = psutil.disk_io_counters().write_time   # Monitoring disk write time in milliseconds
        network_usage = psutil.net_io_counters().bytes_sent  # Monitoring network bytes sent
        # Normalize IO and network data
        normalized_io_usage = min(100, (io_usage / 1000) * 10)  # Simple normalization (adjust as necessary)
        normalized_network_usage = min(100, (network_usage / (1024 * 1024)) * 10)  # Convert bytes to MB and normalize
        return cpu_usage, memory_usage, normalized_io_usage, normalized_network_usage
    def submit_task(self, fn, *args, **kwargs):
        """
        Submit a task to the executor, dynamically adjusting the worker count based on system resources.
        """
        cpu_usage, memory_usage, io_usage, network_usage = self.monitor_resource_usage()
        self.adjust_workers(cpu_usage, memory_usage, io_usage, network_usage)
        return self.executor.submit(fn, *args, **kwargs)



--- File: main.py ---

from system import TeamLeaderAI
from knowledge_base import SharedKnowledgeBase
from agents import (
    ProjectArchitectAI, CodeGeneratorAI, TestAI, EnhancerAI, DocumentationAI,
    DeploymentAI, SecurityAI, DatabaseAI, LoggingAI, VersionControlAI, 
    FrontendGeneratorAI, DebuggingAI
)

# Initialize the shared knowledge base
knowledge_base = SharedKnowledgeBase()

# Define the collaborative agents and pass the shared knowledge base
agents = {
    "Project Architect AI": ProjectArchitectAI(knowledge_base),
    "Code Generator AI": CodeGeneratorAI(knowledge_base),
    "Test AI": TestAI(knowledge_base),
    "Enhancer AI": EnhancerAI(knowledge_base),
    "Documentation AI": DocumentationAI(knowledge_base),
    "Deployment AI": DeploymentAI(knowledge_base),
    "Security AI": SecurityAI(knowledge_base),
    "Database AI": DatabaseAI(knowledge_base),
    "Logging AI": LoggingAI(knowledge_base),
    "Version Control AI": VersionControlAI(knowledge_base),
    "Frontend Generator AI": FrontendGeneratorAI(knowledge_base),
    "Debugging AI": DebuggingAI(knowledge_base)
}

# Initialize the Team Leader AI
team_leader = TeamLeaderAI(agents, knowledge_base)

# Ask the user what they want the team to do
team_leader.receive_user_input()

# Display the progress of task assignments and completions
team_leader.report_progress()

# Example usage of the knowledge base
knowledge_base.store("example_key", "Example knowledge")
print("Knowledge base contents:")
knowledge_base.list_contents()

# Initialize the AI-based Load Balancer with the agent objects only
##load_balancer = AILoadBalancer(agents.values(), knowledge_base)

# Initialize the shared knowledge base instance
#knowledge_base_instance = SharedKnowledgeBase()

