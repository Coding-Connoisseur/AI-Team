

--- File: Project_Overview.txt ---




--- File: test_task_priority_queue.py ---

# test_task_priority_queue.py
import unittest
from task_priority_queue import TaskPriorityQueue
class TestTaskPriorityQueue(unittest.TestCase):
    def setUp(self):
        self.priority_queue = TaskPriorityQueue()
    def test_enqueue_task(self):
        self.priority_queue.enqueue("task1", priority=1)
        self.priority_queue.enqueue("task2", priority=3)
        self.priority_queue.enqueue("task3", priority=2)
        self.assertEqual(len(self.priority_queue.queue), 3)
    def test_dequeue_task(self):
        self.priority_queue.enqueue("task1", priority=1)
        self.priority_queue.enqueue("task2", priority=3)
        task = self.priority_queue.dequeue()
        self.assertEqual(task, "task1")
    def test_queue_emptiness(self):
        self.priority_queue.enqueue("task1", priority=1)
        self.priority_queue.dequeue()
        self.assertTrue(self.priority_queue.is_empty())
    def test_peek_task(self):
        self.priority_queue.enqueue("task1", priority=1)
        self.priority_queue.enqueue("task2", priority=3)
        task = self.priority_queue.peek()
        self.assertEqual(task, "task1")
if __name__ == '__main__':
    unittest.main()



--- File: system.py ---

from task_priority_queue import TaskPriorityQueue
from task_monitor import TaskMonitor
from agent_health_monitor import AgentHealthMonitor
from system_monitor import SystemMonitor
from health_check_manager import HealthCheckManager
from dynamic_thread_pool import DynamicThreadPoolExecutor
from load_balancer import LoadBalancer
import os
import time

class TeamLeaderAI:
    def __init__(self, agents, retry_limit=3):
        self.agents = agents
        self.task_priority_queue = TaskPriorityQueue(SystemMonitor())  # Using SystemMonitor to help with task scheduling
        self.task_progress = {}  # Track task states: {'task_name': {'status': 'queued/active/completed', 'agent': <agent_name>, 'start_time': <timestamp>}}
        self.task_completion_data = {}  # Track the details of completed tasks
        self.retry_limit = retry_limit
        self.task_retries = {}
        self.thread_pool = DynamicThreadPoolExecutor(max_workers=3)
        self.load_balancer = LoadBalancer(self.agents.values())  # Reference to LoadBalancer
        self.task_monitor = TaskMonitor()  # Task monitor for tracking task execution time
        self.agent_health_monitor = AgentHealthMonitor(self.agents.values(), self.load_balancer)
        self.system_monitor = SystemMonitor()  # Monitor system resources
        self.health_check_manager = HealthCheckManager(self.system_monitor, self.agent_health_monitor)
        self.project_path = None
        self.active_tasks = {}
        self.completed_tasks = []
        self.project_type = []

    def get_user_input(self):
        """
        Asks the user what they want the AI team to do.
        """
        print("What do you want the AI team to do? Choose from the following options:")
        print("1. Create a whole project")
        print("2. Enhance an existing project")
        print("3. Debug a project")
        print("4. Add new features and capabilities to a project")
        print("5. Test a project")
        choice = input("Enter the number of your choice: ")
        return int(choice)
    
    def ask_for_project_path(self):
        """
        Ask the user for the project path and ensure it exists.
        """
        self.project_path = input("Please enter the path to the project you want to work on: ")
        if not os.path.exists(self.project_path):
            print(f"Error: The specified path {self.project_path} does not exist.")
            return False
        return True
    
    def receive_user_input(self):
        """
        Determines what the user wants based on input.
        """
        choice = self.get_user_input()
        if choice == 1:
            print("You selected to create a whole project.")
            self.project_type= input("Enter the type of project (e.g., web app, API, machine learning, etc.): ")
            self.decompose_project(f"Create a {self.project_type}")
        elif choice in [2, 3, 4, 5]:
            if not self.ask_for_project_path():
                return
            if choice == 2:
                print("You selected to enhance an existing project.")
                self.decompose_project("Enhance project")
            elif choice == 3:
                print("You selected to debug a project.")
                self.decompose_project("Debug project")
            elif choice == 4:
                print("You selected to add new features and capabilities.")
                self.decompose_project("Add features and capabilities")
            elif choice == 5:
                print("You selected to test a project.")
                self.decompose_project("Test project")
        else:
            print("Invalid choice.")

    def decompose_project(self, overview):
        tasks = [
            (1, "architecture design"),
            (2, "code generation"),
            (3, "debugging"),
            (4, "testing"),
            (5, "enhancement"),
            (6, "documentation"),
            (7, "deployment"),
            (8, "security audit"),
            (9, "database setup"),
            (10, "logging setup"),
            (11, "version control"),
            (12, "frontend generation")
        ]
        for priority, task in tasks:
            self.task_priority_queue.add_task(priority, task, "medium")
        self.assign_tasks()

    def assign_tasks(self):
        """
        Assign tasks from the task priority queue to agents.
        """
        while task_name := self.task_priority_queue.get_next_task():
            agent = self.load_balancer.assign_task(task_name)
            self.thread_pool.submit_task(self.execute_task, agent, task_name)
            self.update_task_status(task_name, 'active', agent.name)  # Mark task as active
    
    def find_agent_for_task(self, task_name):
        for agent in self.agents.values():
            if agent.can_handle(task_name):
                return agent
        return None
    
    def execute_task(self, agent, task_name):
        """
        Executes the task using the assigned agent.
        """
        try:
            start_time = time.time()  # Track the starting time of the task
            self.task_monitor.start_task(task_name)
            # Execute the task and record its outcome
            outcome = agent.execute_task(task_name)
            elapsed_time = self.task_monitor.end_task(task_name)  # Track task completion time
            self.task_completion_data[task_name] = {
                'status': 'completed',
                'agent': agent.name,
                'duration': elapsed_time,
                'outcome': outcome
            }
            print(f"Task '{task_name}' completed by {agent.name} with outcome: {outcome}")
        except Exception as e:
            print(f"Error in executing task '{task_name}' by {agent.name}: {e}")
            self.record_failure(task_name, agent)

    def handle_agent_feedback(self, task_name, result):
        if result == "success":
            self.task_progress[task_name] = "completed"
        else:
            self.recover_from_failure(task_name)

    def recover_from_failure(self, task):
        if self.task_retries[task] < self.retry_limit:
            self.task_retries[task] += 1
            agent = self.find_agent_for_task(task)
            if agent:
                self.execute_task(agent, task)
        else:
            print(f"Task {task} has exceeded the retry limit.")

    def update_task_status(self, task_name, status, agent_name):
        """
        Updates the task progress status (active, completed, etc.) and records the agent assigned to the task.
        """
        self.task_progress[task_name] = {
            'status': status,
            'agent': agent_name
        }

    def mark_task_completed(self, task_name, agent):
        # Remove from active tasks
        if task_name in self.active_tasks:
            del self.active_tasks[task_name]

        # Add to completed tasks
        self.completed_tasks.append({
            'task': task_name,
            'agent': agent.name,
            'status': 'completed'
        })
        
        # Update dashboard
        self.update_dashboard()

    def report_progress(self):
        """
        Displays a real-time dashboard showing task progress.
        """
        print("\n--- Task Progress Dashboard ---")
        print("Queued Tasks:")
        print("  No queued tasks.")
        print("\nActive Tasks:")
        for task, agent in self.active_tasks.items():
            print(f"  {task} (Agent: {agent.name})")
        
        print("\nCompleted Tasks:")
        if not self.completed_tasks:
            print("  No completed tasks.")
        else:
            for task in self.completed_tasks:
                print(f"  {task['task']} completed by {task['agent']} with status: {task['status']}")
        
        print("--- End of Dashboard Report ---")

    def report_overall_progress(self):
        """
        Summarizes overall task progress, including completion rates.
        """
        total_tasks = len(self.task_progress)
        completed_tasks = len([task for task in self.task_progress if self.task_progress[task]['status'] == 'completed'])
        success_tasks = len([task for task in self.task_completion_data if self.task_completion_data[task]['outcome'] == 'success'])
        print("\n--- Overall Task Completion Summary ---")
        print(f"Total Tasks: {total_tasks}")
        print(f"Completed Tasks: {completed_tasks}")
        print(f"Successful Tasks: {success_tasks}")
        print(f"Completion Rate: {(completed_tasks / total_tasks) * 100:.2f}%")
        print(f"Success Rate: {(success_tasks / completed_tasks) * 100:.2f}% (for completed tasks)")
        print("\n--- End of Summary ---")

    def retry_task(self, task_name, agent_name):
        """
        Attempts to retry a failed task a limited number of times.
        """
        retries = self.task_retries.get(task_name, 0)
        if retries < self.retry_limit:
            print(f"Retrying task '{task_name}' (Attempt {retries + 1}/{self.retry_limit})...")
            self.task_retries[task_name] = retries + 1
            self.assign_tasks()
        else:
            print(f"Task '{task_name}' failed after {self.retry_limit} retries.")

    def record_failure(self, task_name, agent):
        """
        Record task failure and decide whether to retry based on retry limit.
        """
        if task_name not in self.task_retries:
            self.task_retries[task_name] = 0
        if self.task_retries[task_name] < self.retry_limit:
            print(f"Task '{task_name}' failed. Retrying...")
            self.retry_task(task_name, agent.name)
        else:
            print(f"Task '{task_name}' exceeded retry limit. Marked as failed.")



--- File: knowledge_base.py ---

class SharedKnowledgeBase:
    def __init__(self):
        self.data = {}
        self.task_metadata = {}  # Ensure task_metadata attribute is defined
    
    def store(self, key, value):
        self.data[key] = value
    
    def get(self, key, default=None):
        return self.data.get(key, default)
    
    def delete(self, key):
        if key in self.data:
            del self.data[key]
    
    def list_contents(self):
        """
        Lists all content currently stored in the knowledge base.
        """
        if not self.data:
            print("Shared knowledge base is empty.")
        else:
            print("Shared Knowledge Base Contents:")
            for key, value in self.data.items():
                print(f"  - {key}: {value}")
        return self.data
    
    def store_task_metadata(self, task_name, metadata):
        """
        Stores metadata for a specific task. Metadata can include details such as task difficulty,
        execution time, and success rate.
        """
        if task_name not in self.task_metadata:
            self.task_metadata[task_name] = []
        self.task_metadata[task_name].append(metadata)
        print(f"Stored metadata for task '{task_name}': {metadata}")

    def get_task_metadata(self, task_name):
        """
        Retrieves metadata for a specific task. Returns a list of metadata entries.
        """
        return self.task_metadata.get(task_name, [])

    def list_all_task_metadata(self):
        """
        Lists all metadata stored for tasks.
        """
        if not self.task_metadata:
            print("No task metadata stored.")
        else:
            print("Task Metadata Contents:")
            for task_name, metadata_list in self.task_metadata.items():
                print(f"Task '{task_name}':")
                for metadata in metadata_list:
                    print(f"  - {metadata}")
        return self.task_metadata



--- File: test_load_balancer.py ---

# test_load_balancer.py
import unittest
from load_balancer import LoadBalancer
from agents import BaseAgent
class TestLoadBalancer(unittest.TestCase):
    def setUp(self):
        self.mock_agents = [BaseAgent("Agent1", {}), BaseAgent("Agent2", {})]
        self.load_balancer = LoadBalancer(self.mock_agents)
    def test_distribute_task_evenly(self):
        tasks = ["task1", "task2", "task3", "task4"]
        assignments = self.load_balancer.distribute_tasks(tasks)
        self.assertEqual(len(assignments), len(tasks))
    def test_assign_task_to_least_loaded_agent(self):
        task = "new_task"
        agent = self.load_balancer.assign_task(task)
        self.assertIn(agent, self.mock_agents)
    def test_update_agent_load(self):
        self.load_balancer.update_agent_load("Agent1", 5)
        self.assertEqual(self.load_balancer.agent_load["Agent1"], 5)
if __name__ == '__main__':
    unittest.main()



--- File: requirements.txt ---

psutil



--- File: unpackStructure.py ---

import os

# Function to parse the Project_Overview.txt file and extract the structure
def parse_project_overview(file_path):
    project_structure = {}
    current_path = []
    
    with open(file_path, 'r') as file:
        for line in file:
            # Skip empty lines
            if line.strip() == "":
                continue
            
            # Detect file header and extract file name correctly
            if line.startswith("--- File: "):
                # Extract and clean file name, removing extra spaces and dashes
                file_name = line.split("--- File: ")[1].strip().strip("-").strip()
                file_parts = file_name.split("/")
                current_path = file_parts[:-1]
                current_file = file_parts[-1].strip()  # Strip any trailing whitespace
                
                # Traverse into the path and initialize structure
                current_dir = project_structure
                for folder in current_path:
                    current_dir = current_dir.setdefault(folder, {})
                current_dir[current_file] = ""
            
            # Otherwise, it's content of the current file
            else:
                # Append content to the current file
                current_dir[current_file] += line

    return project_structure

# Function to create directories and files based on the parsed structure
def create_project_structure(base_path, structure):
    for name, content in structure.items():
        path = os.path.join(base_path, name.strip())  # Ensure the name is stripped of whitespace
        if isinstance(content, dict):
            # Create directory if it's a dictionary
            os.makedirs(path, exist_ok=True)
            create_project_structure(path, content)
        else:
            # Create and write to file if it's not a dictionary
            os.makedirs(os.path.dirname(path), exist_ok=True)
            with open(path, 'w') as f:
                f.write(content)

# Main function to process the Project_Overview.txt and create the project
def main(project_overview_path, base_path="./project"):
    # Parse the project structure from Project_Overview.txt
    project_structure = parse_project_overview(project_overview_path)
    
    # Create directories and files according to the parsed structure
    create_project_structure(base_path, project_structure)
    
    print(f"Project structure created at '{base_path}' based on '{project_overview_path}'.")

# Example usage
main("Project_Overview.txt", ".")



--- File: agent_health_monitor.py ---

class AgentHealthMonitor:
    """
    Monitors the health and performance of agents.
    """
    def __init__(self, agents, load_balancer):
        self.agent_health = {agent.name: {"tasks_handled": 0, "successes": 0, "failures": 0} for agent in agents}
        self.load_balancer = load_balancer  # Adding load balancer reference to rebalance tasks
    def record_task(self, agent_name, outcome):
        """
        Records the outcome of a task handled by an agent.
        Expects 'outcome' to be either 'success' or 'failure' and updates the agent's health accordingly.
        """
        self.agent_health[agent_name]["tasks_handled"] += 1
        if outcome == "success":
            self.agent_health[agent_name]["successes"] += 1
        elif outcome == "failure":
            self.agent_health[agent_name]["failures"] += 1
        else:
            raise ValueError(f"Unknown task outcome: {outcome}")
        self.display_health(agent_name)    # Displaying health after every record.
        self.monitor_agent_health(agent_name)   # Triggering health monitoring after each task
    def display_health(self, agent_name):
        """
        Displays the current health of an agent.
        """
        health = self.agent_health[agent_name]
        print(f"{agent_name} Health: Tasks Handled: {health['tasks_handled']}, Successes: {health['successes']}, Failures: {health['failures']}")
    def monitor_agent_health(self, agent_name):
        """
        Checks if the agent is failing too often and triggers rebalancing if necessary.
        """
        health = self.agent_health[agent_name]
        if health['failures'] > health['successes']:
            print(f"Warning: {agent_name} is experiencing frequent failures.")
            self.trigger_rebalance(agent_name)   # Automatically rebalance if failure rate exceeds success rate.
    def trigger_rebalance(self, failing_agent_name):
        """
        Automatically reassigns tasks if an agent is failing too often.
        """
        print(f"Reassigning tasks from {failing_agent_name} due to frequent failures.")
        # Rebalance logic: Transfer some tasks away from the failing agent to the least busy agent.
        rebalanced_agent = self.load_balancer.assign_task("Rebalance Task")  
        print(f"Tasks reassigned from {failing_agent_name} to {rebalanced_agent.name}.")
class LoadBalancer:
    """
    Distributes tasks evenly across available agents to avoid bottlenecks.
    """
    def __init__(self, agents):
        self.agents = agents
        self.agent_loads = {agent.name: 0 for agent in agents}
    def assign_task(self, task):
        """
        Assigns the task to the least busy agent.
        """
        least_busy_agent = min(self.agent_loads, key=self.agent_loads.get)
        print(f"Assigning task '{task}' to {least_busy_agent}.")
        return [agent for agent in self.agents if agent.name == least_busy_agent][0]
    def task_completed(self, agent_name):
        """
        Marks a task as completed by the given agent.
        """
        self.agent_loads[agent_name] -= 1
class HealthCheckManager:
    def __init__(self, system_monitor, agent_health_monitor):
        self.system_monitor = system_monitor
        self.agent_health_monitor = agent_health_monitor
    def perform_health_check(self, agent_name):
        cpu_usage, memory_usage = self.system_monitor.monitor_resources()
        self.agent_health_monitor.monitor_agent_health(agent_name)
        if cpu_usage > 85 or memory_usage > 85:
            print(f"System overload detected. Rebalancing tasks.")
            self.agent_health_monitor.trigger_rebalance(agent_name)



--- File: agents.py ---

import os
import subprocess
import sqlite3
import ast
import inspect
import openai
from openai import OpenAI
from system import TeamLeaderAI

class BaseAgent:
    def __init__(self, name, knowledge_base):
        self.name = name
        self.knowledge_base = knowledge_base
        self.memory = {}
        self.success_rate = 0.0  # Track the success rate for self-learning
          # Replace with your actual OpenAI API key

    def can_handle(self, task_name):
        raise NotImplementedError("Subclasses should implement this method.")

    def execute_task(self, task_name):
        raise NotImplementedError("Subclasses should implement this method.")

    def learn(self, task, outcome):
        """
        Records the task outcome and adjusts the agent's success rate.
        """
        if task not in self.memory:
            self.memory[task] = {"successes": 0, "failures": 0}

        # Update memory based on task outcome
        if outcome == "success":
            self.memory[task]["successes"] += 1
        else:
            self.memory[task]["failures"] += 1

        # Calculate success rate
        total_attempts = self.memory[task]["successes"] + self.memory[task]["failures"]
        self.success_rate = self.memory[task]["successes"] / total_attempts

        # Log the learning outcome
        print(f"{self.name} has learned from task '{task}'. Success Rate: {self.success_rate:.2%}")

        # Store the metadata in the knowledge base
        metadata = {
            "task": task,
            "outcome": outcome,
            "success_rate": self.success_rate,
            "total_attempts": total_attempts
        }
        self.knowledge_base.store_task_metadata(task, metadata)

    def query_improvements(self, task_name):
        """
        Queries an AI model for suggestions on how to improve the task handling process.
        """
        prompt = f"{self.name} just completed a task: {task_name}. How can I improve my approach for this type of task?"

        try:
            response = client.chat.completions.create(model="gpt-4",
            messages=[
                {"role": "system", "content": "You are an AI assistant helping to improve task handling processes."},
                {"role": "user", "content": prompt}
            ])
            improvement_suggestions = response.choices[0].message.content.strip()
            print(f"Improvement suggestions for {task_name}: {improvement_suggestions}")
            return improvement_suggestions
        except Exception as e:
            print(f"Error querying AI for improvements: {e}")
            return None
    def adjust_behavior(self, task):
        """
        Adjusts the agent's behavior based on its success rate for the given task.
        """
        # If the success rate is low, try to adjust behavior
        if task in self.memory and self.memory[task]["failures"] > self.memory[task]["successes"]:
            print(f"{self.name} adjusting behavior for task '{task}' due to low success rate.")
            # Example adjustment: change task strategy (e.g., increase resource allocation)
            self.change_strategy(task)

    def change_strategy(self, task):
        """
        Implement a strategy change, such as increasing resource allocation or modifying the task approach.
        This function can be customized per agent's requirements.
        """
        print(f"{self.name} is changing strategy for task '{task}' to improve performance.")

class ProjectArchitectAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Project Architect AI", knowledge_base)

    def can_handle(self, task):
        return task == "architecture design"

    def execute_task(self, task):
        self.adjust_behavior(task)
        print(f"{self.name} is creating the project architecture...")

        # Use AI to dynamically generate the project architecture
        project_structure = self.generate_project_structure()

        # Base path for project
        base_path = "./real_project"
        os.makedirs(base_path, exist_ok=True)

        # Create directories and files based on AI suggestions
        self.create_structure(base_path, project_structure)

        print(f"Real-world project structure created by {self.name}.")
        outcome = "success"
        self.learn(task, outcome)
        return outcome

    def generate_project_structure(self):
        """
        Generates a project structure using AI.
        """
        # Prompt AI to design a comprehensive project architecture
        prompt = "Generate a project architecture for a complex {TeamLeaderAI.project_type}, including directories and essential files for code, tests, documentation, configuration, and deployment."

        try:
            response = client.chat.completions.create(model="gpt-4",
            messages=[
                {"role": "system", "content": "You are an AI assistant helping to generate a project architecture for a complex web application, including directories and essential files for code, tests, documentation, configuration, and deployment."},
                {"role": "user", "content": prompt}
            ])
            # Extract structure as a dictionary
            ai_structure = eval(response.choices[0].text.strip())  # Caution: Only use eval with trusted sources
            return ai_structure

        except openai.OpenAIError as e:
            print(f"Error querying OpenAI for project structure: {e}")
            # Default fallback structure if AI call fails
            return {
                "src": {
                    "main.py": "# Main entry point",
                    "utils.py": "# Utility functions",
                    "tests": {
                        "test_main.py": "# Test cases for main"
                    }
                },
                "docs": {
                    "README.md": "# Project documentation"
                },
                "db": {},
                "logs": {},
            }

    def create_structure(self, base_path, structure):
        """
        Recursively creates directories and files based on the provided structure.
        """
        for folder, contents in structure.items():
            folder_path = os.path.join(base_path, folder)
            os.makedirs(folder_path, exist_ok=True)
            for file_name, file_content in contents.items():
                if isinstance(file_content, dict):
                    # Recursively create subdirectories and files
                    self.create_structure(folder_path, {file_name: file_content})
                else:
                    # Create files with content
                    with open(os.path.join(folder_path, file_name), 'w') as f:
                        f.write(file_content)

class CodeGeneratorAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Code Generator AI", knowledge_base)

    def can_handle(self, task):
        return task == "code generation"

    def execute_task(self, task, project_details=None):
        """
        Executes the code generation task with a dynamic, advanced prompt based on project details.
        
        Args:
            task (str): The task to be performed.
            project_details (dict, optional): Specific details for the project, such as the type of app, features, or required technologies.
        """
        # Ensure project_details has default values if not provided
        if project_details is None:
            project_details = {
                "type": "web app",
                "architecture": "microservices",
                "features": ["authentication", "data processing", "API handling"],
                "technologies": ["Flask", "Redis", "Docker"]
            }

        self.adjust_behavior(task)
        print(f"{self.name} is generating an extremely advanced real-world code...")

        try:
            # Generate advanced code based on detailed project requirements
            code_content = self.generate_advanced_code(project_details)

            # Define the path for the generated code
            base_path = "./real_project/src/"
            os.makedirs(base_path, exist_ok=True)
            file_path = os.path.join(base_path, "main.py")

            # Write the AI-generated code to a file
            with open(file_path, 'w') as f:
                f.write(code_content)

            print(f"Extremely advanced code generation completed for task: {task}")

            # Query for improvement suggestions after completing the task
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except Exception as e:
            print(f"Error during code generation: {e}")
            self.learn(task, "failure")
            return "failure"

    def generate_advanced_code(self, project_details):
        """
        Generates highly advanced, AI-driven code for a real-world application.
        
        Args:
            project_details (dict): Specific requirements or features for the project.
        
        Returns:
            str: Generated code content.
        """
        # Dynamic prompt generation for an extremely advanced implementation
        project_type = project_details.get("type", "distributed web application")
        architecture_style = project_details.get("architecture", "microservices with event-driven communication")
        main_features = project_details.get("features", ["authentication", "real-time data streaming", "state management"])
        technologies = project_details.get("technologies", ["Flask", "Redis", "GraphQL", "Kafka", "Docker"])

        prompt = f"""
Design and implement a sophisticated {TeamLeaderAI.project_type} with an {architecture_style} architecture.
The application should include:
1. {main_features[0]} using JWT and OAuth for secure user authentication.
2. {main_features[1]} leveraging Kafka for data streaming and Redis for caching.
3. {main_features[2]} managed via Redux or a similar state management tool for complex UI interactions.
4. Use advanced programming patterns such as Dependency Injection, Factory Pattern, and Repository Pattern.
5. Implement with {', '.join(technologies)}, and ensure the application is containerized with Docker.
6. Code should follow modular design principles, support scalability, and include error handling, logging, and monitoring.
7. Include comprehensive comments, structured documentation, and necessary tests for all modules.
        """
        try:
            response = client.chat.completions.create(model="gpt-4",
            messages=[
                {"role": "system", "content": "You are an AI assistant helping to generate advanced code for a real-world application."},
                {"role": "user", "content": prompt}
            ])
            advanced_code = response.choices[0].text.strip()
            return advanced_code

        except openai.OpenAIError as e:
            print(f"Error querying OpenAI for advanced code generation: {e}")
            # Provide fallback code if API fails
            return '''
# Fallback advanced API setup with Microservices and Kafka for data streaming

import logging
import os
from flask import Flask, jsonify, request
from kafka import KafkaProducer
import redis
import jwt

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your_secret_key'
producer = KafkaProducer(bootstrap_servers='localhost:9092')
cache = redis.StrictRedis(host='localhost', port=6379, db=0)

# Dependency Injection example
class ServiceInjector:
    def __init__(self, service):
        self._service = service

    def perform_action(self):
        self._service.execute()

@app.route('/data', methods=['POST'])
def send_data():
    data = request.json
    producer.send('data-topic', bytes(str(data), 'utf-8'))
    logging.info("Data sent to Kafka")
    return jsonify({"status": "Data sent successfully"})

@app.route('/cache', methods=['GET'])
def get_cache():
    value = cache.get('key')
    return jsonify({"cached_value": value})

if __name__ == '__main__':
    app.run(debug=True)
            '''

class TestAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Test AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "testing"

    def execute_task(self, task_name):
        if task_name == "testing":
            return self.run_tests()

    def run_tests(self):
        """
        Attempt to run tests. Logs detailed test output and retries up to 3 times if tests fail.
        """
        test_dir = os.path.join(self.knowledge_base.get("project_path", "./real_project/src"), "tests")
        if not os.path.exists(test_dir):
            print(f"No tests directory found at {test_dir}.")
            return "failure"

        try:
            result = subprocess.run(["pytest", test_dir], capture_output=True, text=True)
            print(result.stdout)

            if result.returncode == 0:
                print("All tests passed successfully.")

                # Query for improvement suggestions after successful testing
                improvement_suggestions = self.query_improvements("testing")

                # Optionally store the suggestions in the knowledge base
                if improvement_suggestions:
                    self.knowledge_base.store("testing_improvements", improvement_suggestions)

                return "success"
            else:
                print("Some tests failed.")
                return "failure"

        except Exception as e:
            print(f"Error while running tests: {str(e)}")
            return "failure"

class DebuggingAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Debugging AI", knowledge_base)

    def can_handle(self, task):
        return task == "debugging"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Apply any behavior adjustments before debugging
        print(f"{self.name} is performing debugging on the project...")

        try:
            # Debugging logic goes here
            # Example debugging process
            print(f"Debugging task performed by {self.name}.")

            # After debugging, query for improvement suggestions
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except Exception as e:
            print(f"Error during debugging: {e}")
            self.learn(task, "failure")
            return "failure"

class EnhancerAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Enhancer AI", knowledge_base)

    def can_handle(self, task):
        return task == "enhancement"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Adjust behavior based on prior success/failure rates
        print(f"{self.name} is enhancing the project...")

        try:
            # Enhancement logic goes here
            enhancement_code = '''
def advanced_feature():
    print("Advanced feature implemented.")
'''
            base_path = "./real_project/src/utils.py"
            with open(base_path, 'a') as f:
                f.write(enhancement_code)

            print(f"Enhancement added to utils.py by {self.name}.")

            # Query for improvement suggestions after enhancement
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except Exception as e:
            print(f"Error during enhancement: {e}")
            self.learn(task, "failure")
            return "failure"

class DocumentationAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Documentation AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "documentation"

    def execute_task(self, task_name):
        if task_name == "documentation":
            return self.generate_detailed_documentation()

    def generate_detailed_documentation(self):
        """
        Generates detailed documentation including:
        1. API Documentation (function signatures)
        2. Code Annotations (detailed explanations of code blocks)
        3. Workflow Diagrams (general flow of the project components)
        """
        print(f"{self.name} is generating detailed documentation...")

        # Step 1: Generate API Documentation
        self.generate_api_docs()

        # Step 2: Generate Code Annotations
        self.generate_code_annotations()

        # Step 3: Generate Workflow Diagrams (Simplified as textual representation for now)
        self.generate_workflow_diagrams()

        # Query for improvement suggestions after generating documentation
        improvement_suggestions = self.query_improvements("documentation")

        # Optionally store the suggestions in the knowledge base
        if improvement_suggestions:
            self.knowledge_base.store("documentation_improvements", improvement_suggestions)

        self.learn("documentation", "success")
        return "success"

    def generate_api_docs(self):
        """
        Generate API documentation for all Python files by extracting function definitions and signatures.
        """
        print("Generating API documentation...")
        for module_name, module_ref in self.knowledge_base.get("modules", {}).items():
            print(f"\nModule: {module_name}")
            functions = inspect.getmembers(module_ref, inspect.isfunction)
            for function_name, function_ref in functions:
                signature = inspect.signature(function_ref)
                print(f"  Function: {function_name}{signature}")

    def generate_code_annotations(self):
        """
        Generate code annotations by analyzing the AST (Abstract Syntax Tree) and adding comments where appropriate.
        """
        print("Generating code annotations using AST...")
        for module_name, module_ref in self.knowledge_base.get("modules", {}).items():
            source_code = inspect.getsource(module_ref)
            root = ast.parse(source_code)
            print(f"\nAnnotations for {module_name}:")
            for node in ast.walk(root):
                if isinstance(node, ast.FunctionDef):
                    print(f"  Function {node.name} is defined at line {node.lineno}.")
                elif isinstance(node, ast.ClassDef):
                    print(f"  Class {node.name} found at line {node.lineno}.")

    def generate_workflow_diagrams(self):
        """
        Generate a simplified diagram of workflow/processes in the system.
        """
        print("Generating workflow diagram...\n")
        workflow = """
        [Team Leader AI] --> Assign Tasks
        [Load Balancer] --> Distribute Tasks to Agents
        [Agents] --> Perform Tasks (e.g., Code Generation, Testing, Debugging)
        [Documentation AI] --> Generate Reports on Project State
        """
        print(workflow)

class DeploymentAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Deployment AI", knowledge_base)

    def can_handle(self, task):
        return task == "deployment"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Adjust behavior based on previous task outcomes
        print(f"{self.name} is deploying the project...")

        try:
            # Deployment logic goes here
            dockerfile_content = '''
FROM python:3.9-slim
WORKDIR /app
COPY . /app
RUN pip install -r requirements.txt
CMD ["python", "main.py"]
'''
            with open("./real_project/Dockerfile", 'w') as f:
                f.write(dockerfile_content)

            print(f"Dockerfile created by {self.name}.")

            # Query for improvement suggestions after deployment
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except Exception as e:
            print(f"Error during deployment: {e}")
            self.learn(task, "failure")
            return "failure"

class SecurityAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Security AI", knowledge_base)

    def can_handle(self, task_name):
        return task_name == "security audit"

    def execute_task(self, task_name):
        if task_name == "security audit":
            return self.perform_security_audit()

    def perform_security_audit(self):
        """
        Perform a security audit, detect vulnerabilities, and attempt to fix them.
        """
        print("Security AI is performing a security audit...")

        # Example vulnerabilities
        vulnerabilities = ["Insecure default configuration", "Weak encryption algorithm"]
        print("Vulnerabilities detected:\n" + "\n".join(vulnerabilities))

        try:
            # Fix detected vulnerabilities
            self.fix_vulnerabilities(vulnerabilities)

            # Query for improvement suggestions after the security audit
            improvement_suggestions = self.query_improvements("security audit")

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store("security_audit_improvements", improvement_suggestions)

            return "success"
        except Exception as e:
            print(f"Failed to fix vulnerabilities: {str(e)}")
            return "failure"

    def fix_vulnerabilities(self, vulnerabilities):
        """
        Fixes known vulnerabilities. For example, updates configurations and replaces weak algorithms.
        """
        for vulnerability in vulnerabilities:
            if "Insecure default configuration" in vulnerability:
                config_file = os.path.join(self.knowledge_base.get("project_path", "./real_project"), "config.yml")
                if os.path.exists(config_file):
                    with open(config_file, 'a') as f:
                        f.write("secure: true\n")
                    print("Insecure default configuration fixed.")
            elif "Weak encryption algorithm" in vulnerability:
                code_file = os.path.join(self.knowledge_base.get("project_path", "./real_project/src"), "encryption.py")
                if os.path.exists(code_file):
                    with open(code_file, 'r') as f:
                        content = f.read()
                    updated_content = content.replace("AES256", "AES512")
                    with open(code_file, 'w') as f:
                        f.write(updated_content)
                    print("Weak encryption algorithm fixed.")

class DatabaseAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Database AI", knowledge_base)

    def can_handle(self, task):
        return task == "database setup"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Adjust behavior based on previous task outcomes
        print(f"{self.name} is setting up the database...")

        try:
            # Database setup logic goes here
            db_path = "./real_project/db/project.db"
            os.makedirs(os.path.dirname(db_path), exist_ok=True)

            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY,
                username TEXT NOT NULL,
                email TEXT NOT NULL UNIQUE
            )
            ''')
            conn.commit()
            conn.close()

            print(f"Database created by {self.name}.")

            # Query for improvement suggestions after database setup
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except sqlite3.Error as e:
            print(f"Database setup failed: {e}")
            self.learn(task, "failure")
            return "failure"

class LoggingAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Logging AI", knowledge_base)

    def can_handle(self, task):
        return task == "logging setup"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Adjust behavior based on past task outcomes
        print(f"{self.name} is setting up logging for the project...")

        try:
            # Logging setup logic goes here
            logging_config = '''
import logging
logging.basicConfig(filename='./real_project/logs/app.log', level=logging.INFO,
                    format='%(asctime)s %(levelname)s: %(message)s')
logging.info("Logging is set up.")
'''
            log_file_path = "./real_project/src/logging_setup.py"
            os.makedirs(os.path.dirname(log_file_path), exist_ok=True)
            with open(log_file_path, 'w') as f:
                f.write(logging_config)

            print(f"Logging setup complete by {self.name}.")

            # Query for improvement suggestions after setting up logging
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except Exception as e:
            print(f"Error during logging setup: {e}")
            self.learn(task, "failure")
            return "failure"

class VersionControlAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Version Control AI", knowledge_base)

    def can_handle(self, task):
        return task == "version control setup"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Adjust behavior based on past task outcomes
        print(f"{self.name} is setting up version control for the project...")

        try:
            # Initialize a new Git repository
            repo_path = self.knowledge_base.get("project_path", "./real_project")
            os.makedirs(repo_path, exist_ok=True)
            subprocess.run(["git", "init", repo_path], check=True)

            # Create a .gitignore file
            gitignore_content = '''
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
*.egg-info/
.installed.cfg
*.egg
*.log

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# Pyre type checker
.pyre/
'''
            with open(os.path.join(repo_path, ".gitignore"), 'w') as f:
                f.write(gitignore_content)

            print(f"Git repository initialized and .gitignore file created by {self.name}.")

            # Query for improvement suggestions after setting up version control
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except subprocess.CalledProcessError as e:
            print(f"Failed to initialize Git repository: {e}")
            self.learn(task, "failure")
            return "failure"

class FrontendGeneratorAI(BaseAgent):
    def __init__(self, knowledge_base):
        super().__init__("Frontend Generator AI", knowledge_base)

    def can_handle(self, task):
        return task == "frontend generation"

    def execute_task(self, task):
        self.adjust_behavior(task)  # Adjust behavior based on past task outcomes
        print(f"{self.name} is generating the frontend for the project...")

        try:
            # Frontend generation logic goes here
            project_path = self.knowledge_base.get("project_path", "./real_project/frontend")
            os.makedirs(project_path, exist_ok=True)

            # Example HTML and CSS files
            index_html = '''
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Frontend</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Welcome to the Project Frontend</h1>
    <p>This is a sample frontend generated by Frontend Generator AI.</p>
</body>
</html>
'''
            styles_css = '''
body {
    font-family: Arial, sans-serif;
    background-color: #f4f4f4;
    color: #333;
    text-align: center;
    margin: 0;
    padding: 0;
}
h1 {
    color: #555;
}
'''

            # Write files to the project directory
            with open(os.path.join(project_path, "index.html"), 'w') as f:
                f.write(index_html)
            with open(os.path.join(project_path, "styles.css"), 'w') as f:
                f.write(styles_css)

            print(f"Frontend generated successfully by {self.name}.")

            # Query for improvement suggestions after generating the frontend
            improvement_suggestions = self.query_improvements(task)

            # Optionally store the suggestions in the knowledge base
            if improvement_suggestions:
                self.knowledge_base.store(f"{task}_improvements", improvement_suggestions)

            self.learn(task, "success")
            return "success"

        except Exception as e:
            print(f"Error during frontend generation: {e}")
            self.learn(task, "failure")
            return "failure"



--- File: test_health_check_manager.py ---

# test_health_check_manager.py
import unittest
from health_check_manager import HealthCheckManager
from agents import BaseAgent
class TestHealthCheckManager(unittest.TestCase):
    def setUp(self):
        self.mock_agents = [BaseAgent("Agent1", {}), BaseAgent("Agent2", {})]
        self.health_check_manager = HealthCheckManager(self.mock_agents)
    def test_health_check(self):
        results = self.health_check_manager.check_health()
        self.assertIsInstance(results, dict)
        self.assertIn("Agent1", results)
        self.assertIn("Agent2", results)
    def test_health_status(self):
        for agent in self.mock_agents:
            status = self.health_check_manager.get_health_status(agent.name)
            self.assertIn(status, ["healthy", "unhealthy"])
    def test_recover_unhealthy_agents(self):
        # Assuming there is logic to mark an agent as unhealthy
        unhealthy_agents = self.health_check_manager.recover_unhealthy_agents()
        self.assertIsInstance(unhealthy_agents, list)
if __name__ == '__main__':
    unittest.main()



--- File: Dockerfile ---

FROM python:3.9-slim
WORKDIR /usr/src/app
COPY . .
RUN pip install --no-cache-dir -r requirements.txt
CMD ["python", "main.py"]



--- File: test_knowledge_base.py ---

# test_knowledge_base.py
import unittest
from knowledge_base import SharedKnowledgeBase
class TestSharedKnowledgeBase(unittest.TestCase):
    def setUp(self):
        self.knowledge_base = SharedKnowledgeBase()
    def test_store_and_retrieve_knowledge(self):
        self.knowledge_base.store("test_key", "test_value")
        retrieved_value = self.knowledge_base.retrieve("test_key")
        self.assertEqual(retrieved_value, "test_value")
    def test_retrieve_non_existent_key(self):
        result = self.knowledge_base.retrieve("non_existent_key")
        self.assertIsNone(result)
    def test_remove_knowledge(self):
        self.knowledge_base.store("temp_key", "temp_value")
        self.knowledge_base.remove("temp_key")
        result = self.knowledge_base.retrieve("temp_key")
        self.assertIsNone(result)
if __name__ == '__main__':
    unittest.main()



--- File: test_main.py ---

# test_main.py
import unittest
from unittest.mock import patch
import main
class TestMain(unittest.TestCase):
    @patch('main.TeamLeaderAI')
    def test_main_flow_create_project(self, MockTeamLeaderAI):
        mock_team_leader = MockTeamLeaderAI.return_value
        mock_team_leader.create_project.return_value = "Project created successfully"
        with patch('builtins.input', side_effect=["1", "web app"]):
            result = main.run_program()
            self.assertEqual(result, "Project created successfully")
            mock_team_leader.create_project.assert_called_once()
    @patch('main.TeamLeaderAI')
    def test_main_flow_debug_project(self, MockTeamLeaderAI):
        mock_team_leader = MockTeamLeaderAI.return_value
        mock_team_leader.debug_project.return_value = "Debugging completed"
        with patch('builtins.input', side_effect=["3"]):
            result = main.run_program()
            self.assertEqual(result, "Debugging completed")
            mock_team_leader.debug_project.assert_called_once()
    # Add additional tests for other options (Enhance, Add Features, Test)
if __name__ == '__main__':
    unittest.main()



--- File: task_priority_queue.py ---

import heapq
class TaskPriorityQueue:
    def __init__(self, system_monitor):
        self.queue = []
        self.system_monitor = system_monitor  # Allow access to system resource data
    def add_task(self, priority, task_name, resource_intensity):
        """
        Add task to priority queue with priority and an estimated resource intensity (e.g., high, medium, low).
        """
        heapq.heappush(self.queue, (priority, task_name, resource_intensity))
    def get_next_task(self):
        """
        Fetch the next task, prioritizing based on system resource availability.
        """
        if not self.queue:
            return None
        # Get system's current resources utilization
        cpu_usage, memory_usage, _, _ = self.system_monitor.monitor_resources()
        # Try to prioritize tasks that match the current system conditions
        best_match = None
        for i in range(len(self.queue)):
            priority, task_name, resource_intensity = self.queue[i]
            if resource_intensity == 'low' or (cpu_usage < 50 and memory_usage < 50):
                best_match = heapq.heappop(self.queue)
                break
            elif resource_intensity == 'medium' and (cpu_usage < 70 and memory_usage < 70):
                best_match = heapq.heappop(self.queue)
                break
            elif resource_intensity == 'high' and (cpu_usage < 90 and memory_usage < 90):
                best_match = heapq.heappop(self.queue)
                break
        if best_match:
            return best_match[1]  # Return the task_name after finding the best match
        else:
            print("System is too overloaded; delaying resource-heavy tasks.")
            return None
    def display_pending_tasks(self):
        """
        Display tasks currently pending in the queue, sorted by priority.
        """
        if not self.queue:
            print("No pending tasks.")
            return
        print("Pending tasks:")
        for priority, task_name, resource_intensity in sorted(self.queue):
            print(f"Priority {priority}: Task '{task_name}' (Resource Intensity: {resource_intensity})")



--- File: createOverview.py ---

import os
def combine_files_in_directory(directory, output_file):
    with open(output_file, 'w') as outfile:
        # Traverse the directory recursively
        for root, dirs, files in os.walk(directory):
            # Ignore directories that start with '__' or are hidden (dot directories)
            dirs[:] = [d for d in dirs if not d.startswith('__') and not d.startswith('.')]
            for file in files:
                # Ignore dot files (hidden files)
                if file.startswith('.'):
                    continue
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, directory)
                try:
                    with open(file_path, 'r') as infile:
                        # Write the relative file path as a header
                        outfile.write(f"\n\n--- File: {relative_path} ---\n\n")
                        outfile.write(infile.read())
                        outfile.write("\n")  # Add a newline after file content
                except Exception as e:
                    print(f"Could not read {file_path}: {e}")
if __name__ == "__main__":
    directory = input("Enter the directory to combine files from: ")
    output_file = "Project_Overview.txt"
    combine_files_in_directory(directory, output_file)
    print(f"All files have been combined into {output_file}.")



--- File: load_balancer.py ---

class LoadBalancer:
    """
    Distributes tasks evenly across available agents to avoid bottlenecks.
    Now considers agent expertise when assigning tasks.
    """
    def __init__(self, agents):
        self.agents = agents
        self.agent_loads = {agent.name: 0 for agent in agents}
        self.agent_expertises = {  # Identifying the best agent for each type of task
            "architecture design": "Project Architect AI",
            "code generation": "Code Generator AI",
            "debugging": "Debugging AI",
            "testing": "Test AI",
            "enhancement": "Enhancer AI",
            "documentation": "Documentation AI",
            "deployment": "Deployment AI",
            "security audit": "Security AI",
            "database setup": "Database AI",
            "logging setup": "Logging AI",
            "version control": "Version Control AI",
            "frontend generation": "Frontend Generator AI"
        }
    def assign_task(self, task):
        """
        Assigns the task to the least busy agent, while also prioritizing agents who are experts at this task.
        """
        # Identify the expert agent for the task
        expert_agent_name = self.agent_expertises.get(task)
        if expert_agent_name:
            # Ensure the expert agent still exists in the system
            if expert_agent_name in self.agent_loads:
                least_busy_expert = expert_agent_name
            else:
                # Fallback to least busy agent if expertise agent is not found
                least_busy_expert = min(self.agent_loads, key=self.agent_loads.get)
            print(f"Assigning task '{task}' to the expert agent: {least_busy_expert}.")
        else:
            # No specific expertise available, assign to the least busy agent
            least_busy_expert = min(self.agent_loads, key=self.agent_loads.get)
            print(f"Assigning task '{task}' to {least_busy_expert}, no specific expertise required.")
        assigned_agent = next(agent for agent in self.agents if agent.name == least_busy_expert)
        self.agent_loads[least_busy_expert] += 1
        return assigned_agent
    def task_completed(self, agent_name):
        """
        Marks a task as completed by the given agent, reducing their current load.
        """
        if agent_name in self.agent_loads:
            self.agent_loads[agent_name] = max(0, self.agent_loads[agent_name] - 1)
# Example agents list to simulate load balancer functioning:
"""
agents = {
    "Project Architect AI": ProjectArchitectAI(knowledge_base),
    "Code Generator AI": CodeGeneratorAI(knowledge_base),
    "Debugging AI": DebuggingAI(knowledge_base),
    "Test AI": TestAI(knowledge_base),
    "Enhancer AI": EnhancerAI(knowledge_base),
    "Documentation AI": DocumentationAI(knowledge_base),
    "Deployment AI": DeploymentAI(knowledge_base),
    "Security AI": SecurityAI(knowledge_base),
    "Database AI": DatabaseAI(knowledge_base),
    "Logging AI": LoggingAI(knowledge_base),
    "Version Control AI": VersionControlAI(knowledge_base),
    "Frontend Generator AI": FrontendGeneratorAI(knowledge_base)
}
"""



--- File: health_check_manager.py ---

class HealthCheckManager:
    def __init__(self, system_monitor, agent_health_monitor):
        self.system_monitor = system_monitor
        self.agent_health_monitor = agent_health_monitor
    def perform_health_check(self, agent_name):
        cpu_usage, memory_usage = self.system_monitor.monitor_resources()
        self.agent_health_monitor.monitor_agent_health(agent_name)
        if cpu_usage > 85 or memory_usage > 85:
            print(f"System overload detected. Rebalancing tasks.")



--- File: test_agent_health_monitor.py ---

# test_agent_health_monitor.py
import unittest
from agent_health_monitor import AgentHealthMonitor, LoadBalancer
from agents import BaseAgent
class TestAgentHealthMonitor(unittest.TestCase):
    def setUp(self):
        self.mock_agents = [BaseAgent("TestAgent", {})]
        self.load_balancer = LoadBalancer(self.mock_agents)
        self.agent_health_monitor = AgentHealthMonitor(self.mock_agents, self.load_balancer)
    def test_record_task_success(self):
        self.agent_health_monitor.record_task("TestAgent", "success")
        health = self.agent_health_monitor.agent_health["TestAgent"]
        self.assertEqual(health["successes"], 1)
    def test_record_task_failure(self):
        self.agent_health_monitor.record_task("TestAgent", "failure")
        health = self.agent_health_monitor.agent_health["TestAgent"]
        self.assertEqual(health["failures"], 1)
    def test_trigger_rebalance_on_failure(self):
        self.agent_health_monitor.record_task("TestAgent", "failure")
        self.agent_health_monitor.record_task("TestAgent", "failure")
        self.agent_health_monitor.record_task("TestAgent", "failure")
        # Test rebalance logic as needed
        # Add mock or print statements to confirm behavior
if __name__ == '__main__':
    unittest.main()



--- File: test_task_monitor.py ---

# test_task_monitor.py
import unittest
from task_monitor import TaskMonitor
from agents import BaseAgent
class TestTaskMonitor(unittest.TestCase):
    def setUp(self):
        self.agent = BaseAgent("TestAgent", {})
        self.task_monitor = TaskMonitor(self.agent)
    def test_start_task(self):
        task_name = "sample_task"
        self.task_monitor.start_task(task_name)
        self.assertEqual(self.task_monitor.current_task, task_name)
    def test_complete_task(self):
        task_name = "sample_task"
        self.task_monitor.start_task(task_name)
        self.task_monitor.complete_task("success")
        self.assertIsNone(self.task_monitor.current_task)
        self.assertIn("success", self.task_monitor.task_history)
    def test_task_failure(self):
        task_name = "sample_task"
        self.task_monitor.start_task(task_name)
        self.task_monitor.complete_task("failure")
        self.assertIn("failure", self.task_monitor.task_history)
if __name__ == '__main__':
    unittest.main()



--- File: test_dynamic_thread_pool.py ---

# test_dynamic_thread_pool.py
import unittest
from dynamic_thread_pool import DynamicThreadPoolExecutor
import time
class TestDynamicThreadPoolExecutor(unittest.TestCase):
    def setUp(self):
        self.pool = DynamicThreadPoolExecutor(max_workers=3)
    def tearDown(self):
        self.pool.shutdown()
    def test_submit_task(self):
        def sample_task(x):
            return x * 2
        future = self.pool.submit(sample_task, 5)
        result = future.result()
        self.assertEqual(result, 10)
    def test_adjust_worker_count(self):
        initial_count = self.pool._max_workers
        self.pool.adjust_worker_count(5)
        self.assertEqual(self.pool._max_workers, 5)
    def test_task_execution_with_delay(self):
        def delayed_task():
            time.sleep(1)
            return "completed"
        future = self.pool.submit(delayed_task)
        result = future.result()
        self.assertEqual(result, "completed")
if __name__ == '__main__':
    unittest.main()



--- File: test_system.py ---

# test_system.py
import unittest
from system import System
class TestSystem(unittest.TestCase):
    def setUp(self):
        self.system = System()
    def test_get_cpu_usage(self):
        cpu_usage = self.system.get_cpu_usage()
        self.assertIsInstance(cpu_usage, float)
        self.assertGreaterEqual(cpu_usage, 0.0)
    def test_get_memory_usage(self):
        memory_usage = self.system.get_memory_usage()
        self.assertIsInstance(memory_usage, float)
        self.assertGreaterEqual(memory_usage, 0.0)
    def test_get_disk_usage(self):
        disk_usage = self.system.get_disk_usage()
        self.assertIsInstance(disk_usage, float)
        self.assertGreaterEqual(disk_usage, 0.0)
    def test_get_network_usage(self):
        network_usage = self.system.get_network_usage()
        self.assertIsInstance(network_usage, float)
        self.assertGreaterEqual(network_usage, 0.0)
if __name__ == '__main__':
    unittest.main()



--- File: task_monitor.py ---

import time
class TaskMonitor:
    def __init__(self):
        self.task_times = {}
        self.task_history = {}  # New dictionary to track task completion times
    def start_task(self, task_name):
        """
        Starts tracking the task's start time.
        """
        self.task_times[task_name] = time.time()
        print(f"Started task '{task_name}' at {self.task_times[task_name]}")
    def end_task(self, task_name):
        """
        Stops tracking the task's time and records the duration for analytics.
        """
        if task_name in self.task_times:
            elapsed_time = time.time() - self.task_times[task_name]
            print(f"Task '{task_name}' completed in {elapsed_time:.2f} seconds.")
            # Store the elapsed time in task history for tracking multiple runs
            if task_name not in self.task_history:
                self.task_history[task_name] = []
            self.task_history[task_name].append(elapsed_time)
            del self.task_times[task_name]
            return elapsed_time
        return None
    def get_average_time(self, task_name):
        """
        Calculates the average completion time for a given task, based on historical data.
        """
        if task_name in self.task_history and self.task_history[task_name]:
            avg_time = sum(self.task_history[task_name]) / len(self.task_history[task_name])
            print(f"Average time for task '{task_name}': {avg_time:.2f} seconds.")
            return avg_time
        else:
            print(f"No historical data for task '{task_name}'.")
            return None
    def display_task_statistics(self):
        """
        Displays a summary of task performance statistics, including average and total run times.
        """
        if self.task_history:
            print("\nTask Performance Summary:")
            for task_name, times in self.task_history.items():
                total_runs = len(times)
                total_time = sum(times)
                average_time = total_time / total_runs if total_runs > 0 else 0
                print(f"Task: {task_name}, Total Runs: {total_runs}, Average Time: {average_time:.2f} seconds, Total Time: {total_time:.2f} seconds.")
        else:
            print("No tasks have been completed yet to show statistics.")



--- File: test_agents.py ---

# test_agents.py
import unittest
from agents import ProjectArchitectAI, CodeGeneratorAI, TestAI, DebuggingAI, EnhancerAI, DocumentationAI, DeploymentAI, SecurityAI, DatabaseAI, LoggingAI, VersionControlAI, FrontendGeneratorAI
from knowledge_base import SharedKnowledgeBase
class TestAgents(unittest.TestCase):
    def setUp(self):
        self.knowledge_base = SharedKnowledgeBase()
        self.agents = [
            ProjectArchitectAI(self.knowledge_base),
            CodeGeneratorAI(self.knowledge_base),
            TestAI(self.knowledge_base),
            DebuggingAI(self.knowledge_base),
            EnhancerAI(self.knowledge_base),
            DocumentationAI(self.knowledge_base),
            DeploymentAI(self.knowledge_base),
            SecurityAI(self.knowledge_base),
            DatabaseAI(self.knowledge_base),
            LoggingAI(self.knowledge_base),
            VersionControlAI(self.knowledge_base),
            FrontendGeneratorAI(self.knowledge_base)
        ]
    def test_agents_can_handle(self):
        for agent in self.agents:
            self.assertTrue(hasattr(agent, 'can_handle'))
    def test_agents_execute_task(self):
        for agent in self.agents:
            with self.assertRaises(NotImplementedError):
                agent.execute_task('any_task')
    # Add additional tests specific to each agent type
if __name__ == '__main__':
    unittest.main()



--- File: system_monitor.py ---

import psutil
class SystemMonitor:
    def __init__(self):
        self.alert_thresholds = {
            'cpu': 85,  # Alert if CPU usage exceeds 85%
            'memory': 85,  # Alert if memory usage exceeds 85%
            'disk': 80,  # Alert if disk usage exceeds 80%
            'network_sent': 75,  # Alert if network outgoing exceeds 75% of bandwidth (mock)
        }
    def monitor_resources(self):
        """
        Monitors the system's resource usage.
        """
        cpu_usage = psutil.cpu_percent(interval=1)
        memory_usage = psutil.virtual_memory().percent
        disk_usage = psutil.disk_usage('/').percent
        network_usage_sent = self.get_network_sent_usage()
        print(f"CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage}%, Disk Usage: {disk_usage}%, Network Outgoing: {network_usage_sent}%")
        # Trigger alerts if any usage exceeds pre-defined thresholds
        self.check_alerts(cpu_usage, memory_usage, disk_usage, network_usage_sent)
        return cpu_usage, memory_usage, disk_usage, network_usage_sent
    def check_alerts(self, cpu_usage, memory_usage, disk_usage, network_usage_sent):
        """
        Checks system metrics against pre-defined threshold limits and issues alerts if exceeded.
        """
        if cpu_usage > self.alert_thresholds['cpu']:
            print(f"ALERT: CPU Usage exceeds {self.alert_thresholds['cpu']}% (Current: {cpu_usage}%)")
        if memory_usage > self.alert_thresholds['memory']:
            print(f"ALERT: Memory Usage exceeds {self.alert_thresholds['memory']}% (Current: {memory_usage}%)")
        if disk_usage > self.alert_thresholds['disk']:
            print(f"ALERT: Disk Usage exceeds {self.alert_thresholds['disk']}% (Current: {disk_usage}%)")
        if network_usage_sent > self.alert_thresholds['network_sent']:
            print(f"ALERT: Network Outgoing exceeds {self.alert_thresholds['network_sent']}% (Current: {network_usage_sent}%)")
    def get_network_sent_usage(self):
        """
        Simulate network usage monitoring. You could modify this part to reflect real network usage.
        """
        net_io = psutil.net_io_counters()
        sent = net_io.bytes_sent / (1024 * 1024)  # Convert the sent bytes to megabytes
        # For now, we'll return a mock "percentage", just scale bytes sent arbitrarily
        return min(100, (sent / 5) * 10)  # This is a mock calculation assuming 5MB threshold.
    def trigger_alert(self, alert_message):
        """
        Optional: Hook this up with a notification/alerting system (e.g., email, logging, etc.).
        """
        # Notifies via print for now; can change as needed (e.g., hook with logging service).
        print(f"Triggering Alert: {alert_message}")



--- File: dynamic_thread_pool.py ---

import psutil
from concurrent.futures import ThreadPoolExecutor
class DynamicThreadPoolExecutor:
    def __init__(self, max_workers):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
    def adjust_workers(self, cpu_usage, memory_usage, io_usage, network_usage):
        """
        Adjust worker count based on system's resource usage, including disk I/O and network bandwidth.
        """
        # Reduce the number of workers if CPU, memory, disk I/O, or network usage is too high
        if cpu_usage > 80 or memory_usage > 80 or io_usage > 80 or network_usage > 75:
            new_worker_count = max(1, self.max_workers // 2)  # Reduce workers to alleviate load
            self.executor = ThreadPoolExecutor(max_workers=new_worker_count)
            print(f"Reducing worker count to {new_worker_count} due to high resource usage: CPU({cpu_usage}%), Memory({memory_usage}%), IO({io_usage}%), Network({network_usage}%)")
        # Increase workers if the system is underutilized
        elif cpu_usage < 40 and memory_usage < 40 and io_usage < 40 and network_usage < 30:
            new_worker_count = min(self.max_workers * 2, 10)  # Increase workers to better utilize capacity
            self.executor = ThreadPoolExecutor(max_workers=new_worker_count)
            print(f"Increasing worker count to {new_worker_count} due to low resource usage: CPU({cpu_usage}%), Memory({memory_usage}%), IO({io_usage}%), Network({network_usage}%)")
    def monitor_resource_usage(self):
        """
        Fetch system resource usage: CPU, memory, disk I/O, and network IO.
        """
        cpu_usage = psutil.cpu_percent(interval=1)
        memory_usage = psutil.virtual_memory().percent
        io_usage = psutil.disk_io_counters().write_time   # Monitoring disk write time in milliseconds
        network_usage = psutil.net_io_counters().bytes_sent  # Monitoring network bytes sent
        # Normalize IO and network data
        normalized_io_usage = min(100, (io_usage / 1000) * 10)  # Simple normalization (adjust as necessary)
        normalized_network_usage = min(100, (network_usage / (1024 * 1024)) * 10)  # Convert bytes to MB and normalize
        return cpu_usage, memory_usage, normalized_io_usage, normalized_network_usage
    def submit_task(self, fn, *args, **kwargs):
        """
        Submit a task to the executor, dynamically adjusting the worker count based on system resources.
        """
        cpu_usage, memory_usage, io_usage, network_usage = self.monitor_resource_usage()
        self.adjust_workers(cpu_usage, memory_usage, io_usage, network_usage)
        return self.executor.submit(fn, *args, **kwargs)



--- File: main.py ---

from system import TeamLeaderAI
from knowledge_base import SharedKnowledgeBase
from agents import ProjectArchitectAI, CodeGeneratorAI, TestAI, EnhancerAI, DocumentationAI, DeploymentAI, SecurityAI, DatabaseAI, LoggingAI, VersionControlAI, FrontendGeneratorAI, DebuggingAI

# Initialize the shared knowledge base
knowledge_base = SharedKnowledgeBase()

# Define collaborative agents and pass the shared knowledge base
agents = {
    "Project Architect AI": ProjectArchitectAI(knowledge_base),
    "Code Generator AI": CodeGeneratorAI(knowledge_base),
    "Test AI": TestAI(knowledge_base),
    "Enhancer AI": EnhancerAI(knowledge_base),
    "Documentation AI": DocumentationAI(knowledge_base),
    "Deployment AI": DeploymentAI(knowledge_base),
    "Security AI": SecurityAI(knowledge_base),
    "Database AI": DatabaseAI(knowledge_base),
    "Logging AI": LoggingAI(knowledge_base),
    "Version Control AI": VersionControlAI(knowledge_base),
    "Frontend Generator AI": FrontendGeneratorAI(knowledge_base),
    "Debugging AI": DebuggingAI(knowledge_base)
}
# Initialize the Team Leader AI
team_leader = TeamLeaderAI(agents)
# Ask the user what they want the team to do
team_leader.receive_user_input()
# Print the task progress
team_leader.report_progress()
# Store some knowledge in the knowledge base
knowledge_base.store("key1", "This is some knowledge about task1.")
knowledge_base.store("key2", "This is some knowledge about task2.")
# List the shared knowledge base contents:
knowledge_base.list_contents()
# Retrieve specific knowledge
task1_knowledge = knowledge_base.get("key1")
print(f"Retrieved knowledge for task1: {task1_knowledge}")
task2_knowledge = knowledge_base.get("key2")
print(f"Retrieved knowledge for task2: {task2_knowledge}")

